Using TensorFlow backend.
24.02.2018 00:01:57 INFO    Hi! How are you today?
24.02.2018 00:01:57 INFO    Startup options:
24.02.2018 00:01:57 INFO      Algorithm:                     scoreregression
24.02.2018 00:01:57 INFO      Point by point:                False
24.02.2018 00:01:57 INFO      Morphing-aware mode:           False
24.02.2018 00:01:57 INFO      Smeared data:                  False
24.02.2018 00:01:57 INFO      Training sample:               baseline
24.02.2018 00:01:57 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
24.02.2018 00:01:57 INFO      alpha:                         None
24.02.2018 00:01:57 INFO      AFC epsilon:                   None
24.02.2018 00:01:57 INFO      Neyman construction toys:      True
24.02.2018 00:01:57 INFO      Other options:                 
24.02.2018 00:01:57 INFO      Base directory:                /home/jb6504/higgs_inference
24.02.2018 00:01:57 INFO      ML-based strategies available: True
24.02.2018 00:01:57 INFO    Starting score regression inference
24.02.2018 00:01:57 INFO    Options:
24.02.2018 00:01:57 INFO      Number of hidden layers: 3
24.02.2018 00:01:57 INFO      Batch size:              128
24.02.2018 00:01:57 INFO      Learning rate:           0.001
24.02.2018 00:01:57 INFO      Learning rate decay:     0.0921034037198
24.02.2018 00:01:57 INFO      Number of epochs:        50
24.02.2018 00:02:18 INFO    Starting training of score regression
Train on 7999812 samples, validate on 1999953 samples
2018-02-24 00:02:19.262053: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 00:02:19.263743: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 00:02:19.263754: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 00:02:19.263758: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 00:02:19.263763: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-24 00:02:19.576926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-24 00:02:19.576964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-24 00:02:19.576971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-24 00:02:19.576981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 1/50
278s - loss: 0.0302 - val_loss: 0.0167
Epoch 2/50
277s - loss: 0.0147 - val_loss: 0.0131
Epoch 3/50
277s - loss: 0.0123 - val_loss: 0.0080
Epoch 4/50
278s - loss: 0.0100 - val_loss: 0.0099
Epoch 5/50
278s - loss: 0.0092 - val_loss: 0.0125
Epoch 6/50
278s - loss: 0.0082 - val_loss: 0.0076
Epoch 7/50
278s - loss: 0.0072 - val_loss: 0.0073
Epoch 8/50
277s - loss: 0.0063 - val_loss: 0.0065
Epoch 9/50
278s - loss: 0.0052 - val_loss: 0.0045
Epoch 10/50
278s - loss: 0.0046 - val_loss: 0.0037
Epoch 11/50
278s - loss: 0.0039 - val_loss: 0.0034
Epoch 12/50
278s - loss: 0.0034 - val_loss: 0.0037
Epoch 13/50
278s - loss: 0.0032 - val_loss: 0.0036
Epoch 14/50
278s - loss: 0.0027 - val_loss: 0.0025
Epoch 15/50
278s - loss: 0.0024 - val_loss: 0.0027
Epoch 16/50
278s - loss: 0.0022 - val_loss: 0.0026
Epoch 17/50
278s - loss: 0.0020 - val_loss: 0.0024
Epoch 18/50
278s - loss: 0.0019 - val_loss: 0.0017
Epoch 19/50
278s - loss: 0.0017 - val_loss: 0.0016
Epoch 20/50
278s - loss: 0.0016 - val_loss: 0.0013
Epoch 21/50
278s - loss: 0.0015 - val_loss: 0.0014
Epoch 22/50
278s - loss: 0.0014 - val_loss: 0.0013
Epoch 23/50
278s - loss: 0.0013 - val_loss: 0.0013
Epoch 24/50
278s - loss: 0.0012 - val_loss: 0.0012
Epoch 25/50
278s - loss: 0.0012 - val_loss: 0.0012
Epoch 26/50
278s - loss: 0.0011 - val_loss: 0.0013
Epoch 27/50
278s - loss: 0.0011 - val_loss: 0.0011
Epoch 28/50
278s - loss: 0.0010 - val_loss: 0.0011
Epoch 29/50
278s - loss: 0.0010 - val_loss: 0.0010
Epoch 30/50
278s - loss: 9.8221e-04 - val_loss: 9.7111e-04
Epoch 31/50
278s - loss: 9.5471e-04 - val_loss: 9.5688e-04
Epoch 32/50
278s - loss: 9.3382e-04 - val_loss: 9.3964e-04
Epoch 33/50
278s - loss: 9.1260e-04 - val_loss: 9.3322e-04
Epoch 34/50
278s - loss: 8.9874e-04 - val_loss: 9.3946e-04
Epoch 35/50
278s - loss: 8.8300e-04 - val_loss: 9.2511e-04
Epoch 36/50
278s - loss: 8.6914e-04 - val_loss: 8.7251e-04
Epoch 37/50
278s - loss: 8.5457e-04 - val_loss: 8.6551e-04
Epoch 38/50
278s - loss: 8.4599e-04 - val_loss: 8.7229e-04
Epoch 39/50
278s - loss: 8.3958e-04 - val_loss: 8.5722e-04
Epoch 40/50
278s - loss: 8.3002e-04 - val_loss: 8.5215e-04
Epoch 41/50
278s - loss: 8.1941e-04 - val_loss: 8.4171e-04
Epoch 42/50
278s - loss: 8.1095e-04 - val_loss: 8.2961e-04
Epoch 43/50
278s - loss: 8.0647e-04 - val_loss: 8.3180e-04
Epoch 44/50
278s - loss: 7.9850e-04 - val_loss: 8.3384e-04
Epoch 45/50
278s - loss: 7.9326e-04 - val_loss: 8.2009e-04
Epoch 46/50
278s - loss: 7.8864e-04 - val_loss: 8.1753e-04
Epoch 47/50
278s - loss: 7.8454e-04 - val_loss: 8.1364e-04
Epoch 48/50
278s - loss: 7.8097e-04 - val_loss: 8.0161e-04
Epoch 49/50
278s - loss: 7.7643e-04 - val_loss: 8.0928e-04
Epoch 50/50
278s - loss: 7.7281e-04 - val_loss: 8.0370e-04
24.02.2018 03:54:26 INFO    Starting evaluation
24.02.2018 03:54:31 INFO    Starting density estimation
25.02.2018 16:11:40 INFO    That's it -- have a great day!
slurmstepd: error: Exceeded step memory limit at some point.
