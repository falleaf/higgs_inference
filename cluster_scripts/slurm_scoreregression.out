Using TensorFlow backend.
20.02.2018 06:20:30 INFO    Hi! How are you today?
20.02.2018 06:20:30 INFO    Startup options:
20.02.2018 06:20:30 INFO      Algorithm:                     scoreregression
20.02.2018 06:20:30 INFO      Point by point:                False
20.02.2018 06:20:30 INFO      Morphing-aware mode:           False
20.02.2018 06:20:30 INFO      Smeared data:                  False
20.02.2018 06:20:30 INFO      Training sample:               baseline
20.02.2018 06:20:30 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
20.02.2018 06:20:30 INFO      alpha:                         None
20.02.2018 06:20:30 INFO      AFC epsilon:                   None
20.02.2018 06:20:30 INFO      Neyman construction toys:      False
20.02.2018 06:20:30 INFO      Other options:                 
20.02.2018 06:20:30 INFO      Base directory:                /home/jb6504/higgs_inference
20.02.2018 06:20:30 INFO      ML-based strategies available: True
20.02.2018 06:20:30 INFO    Starting score regression inference
20.02.2018 06:20:30 INFO    Options:
20.02.2018 06:20:30 INFO      Number of hidden layers: 3
20.02.2018 06:20:30 INFO      Batch size:              128
20.02.2018 06:20:30 INFO      Learning rate:           0.001
20.02.2018 06:20:30 INFO      Learning rate decay:     0.0921034037198
20.02.2018 06:20:30 INFO      Number of epochs:        50
20.02.2018 06:20:50 INFO    Starting training of score regression
Train on 7999812 samples, validate on 1999953 samples
2018-02-20 06:20:50.920448: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-20 06:20:50.920759: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-20 06:20:50.920767: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-20 06:20:50.920770: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-20 06:20:50.920773: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-20 06:20:51.221143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:85:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-20 06:20:51.221180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-20 06:20:51.221186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-20 06:20:51.221194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:85:00.0)
Epoch 1/50
281s - loss: 0.0290 - val_loss: 0.0233
Epoch 2/50
280s - loss: 0.0143 - val_loss: 0.0137
Epoch 3/50
280s - loss: 0.0118 - val_loss: 0.0099
Epoch 4/50
280s - loss: 0.0101 - val_loss: 0.0111
Epoch 5/50
280s - loss: 0.0093 - val_loss: 0.0074
Epoch 6/50
280s - loss: 0.0087 - val_loss: 0.0077
Epoch 7/50
280s - loss: 0.0072 - val_loss: 0.0064
Epoch 8/50
280s - loss: 0.0059 - val_loss: 0.0048
Epoch 9/50
280s - loss: 0.0055 - val_loss: 0.0054
Epoch 10/50
280s - loss: 0.0048 - val_loss: 0.0055
Epoch 11/50
280s - loss: 0.0041 - val_loss: 0.0048
Epoch 12/50
280s - loss: 0.0036 - val_loss: 0.0033
Epoch 13/50
280s - loss: 0.0031 - val_loss: 0.0032
Epoch 14/50
280s - loss: 0.0028 - val_loss: 0.0025
Epoch 15/50
280s - loss: 0.0024 - val_loss: 0.0030
Epoch 16/50
280s - loss: 0.0021 - val_loss: 0.0021
Epoch 17/50
280s - loss: 0.0020 - val_loss: 0.0017
Epoch 18/50
280s - loss: 0.0018 - val_loss: 0.0020
Epoch 19/50
280s - loss: 0.0017 - val_loss: 0.0019
Epoch 20/50
280s - loss: 0.0015 - val_loss: 0.0013
Epoch 21/50
280s - loss: 0.0014 - val_loss: 0.0013
Epoch 22/50
280s - loss: 0.0013 - val_loss: 0.0014
Epoch 23/50
280s - loss: 0.0012 - val_loss: 0.0012
Epoch 24/50
280s - loss: 0.0012 - val_loss: 0.0012
Epoch 25/50
280s - loss: 0.0011 - val_loss: 0.0012
Epoch 26/50
280s - loss: 0.0011 - val_loss: 0.0011
Epoch 27/50
281s - loss: 0.0010 - val_loss: 0.0010
Epoch 28/50
281s - loss: 9.8968e-04 - val_loss: 9.9380e-04
Epoch 29/50
281s - loss: 9.6911e-04 - val_loss: 9.4341e-04
Epoch 30/50
281s - loss: 9.3396e-04 - val_loss: 9.4723e-04
Epoch 31/50
279s - loss: 9.0923e-04 - val_loss: 9.3115e-04
Epoch 32/50
270s - loss: 8.8746e-04 - val_loss: 8.7269e-04
Epoch 33/50
270s - loss: 8.7604e-04 - val_loss: 8.8839e-04
Epoch 34/50
270s - loss: 8.5186e-04 - val_loss: 8.4984e-04
Epoch 35/50
270s - loss: 8.3573e-04 - val_loss: 8.6160e-04
Epoch 36/50
270s - loss: 8.2700e-04 - val_loss: 8.3601e-04
Epoch 37/50
270s - loss: 8.1505e-04 - val_loss: 8.2531e-04
Epoch 38/50
271s - loss: 8.0241e-04 - val_loss: 8.1973e-04
Epoch 39/50
278s - loss: 7.9517e-04 - val_loss: 7.8976e-04
Epoch 40/50
274s - loss: 7.8636e-04 - val_loss: 7.8305e-04
Epoch 41/50
270s - loss: 7.7814e-04 - val_loss: 7.8824e-04
Epoch 42/50
270s - loss: 7.7179e-04 - val_loss: 7.8931e-04
Epoch 43/50
270s - loss: 7.6519e-04 - val_loss: 7.6299e-04
Epoch 44/50
270s - loss: 7.5713e-04 - val_loss: 7.6879e-04
Epoch 45/50
270s - loss: 7.5317e-04 - val_loss: 7.5631e-04
Epoch 46/50
270s - loss: 7.4903e-04 - val_loss: 7.5658e-04
Epoch 47/50
272s - loss: 7.4432e-04 - val_loss: 7.4665e-04
Epoch 48/50
279s - loss: 7.4069e-04 - val_loss: 7.5079e-04
Epoch 49/50
279s - loss: 7.3554e-04 - val_loss: 7.4413e-04
Epoch 50/50
274s - loss: 7.3316e-04 - val_loss: 7.4332e-04
20.02.2018 10:12:00 INFO    Starting evaluation
20.02.2018 10:12:06 INFO    Starting density estimation
20.02.2018 10:14:36 INFO    That's it -- have a great day!
