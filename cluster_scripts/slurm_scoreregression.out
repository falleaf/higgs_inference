Using TensorFlow backend.
09.04.2018 18:13:14 INFO    Hi! How are you today?
09.04.2018 18:13:14 INFO    Startup options:
09.04.2018 18:13:14 INFO      Algorithm:                     scoreregression
09.04.2018 18:13:14 INFO      Point by point:                False
09.04.2018 18:13:14 INFO      Morphing-aware mode:           False
09.04.2018 18:13:14 INFO      Smeared data:                  False
09.04.2018 18:13:14 INFO      Training sample:               baseline
09.04.2018 18:13:14 INFO      alpha:                         None
09.04.2018 18:13:14 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
09.04.2018 18:13:14 INFO      AFC epsilon:                   None
09.04.2018 18:13:14 INFO      Denominator theta:             True
09.04.2018 18:13:14 INFO      Neyman construction toys:      0
09.04.2018 18:13:14 INFO      Other options:                 ['deep', 'neyman2']
09.04.2018 18:13:14 INFO      Base directory:                /home/jb6504/higgs_inference
09.04.2018 18:13:14 INFO      ML-based strategies available: True
09.04.2018 18:13:14 INFO    Starting score regression inference
09.04.2018 18:13:14 INFO    Options:
09.04.2018 18:13:14 INFO      Denominator theta:       denominator 0 = theta 708 = [ 0.39293227  0.43229216]
09.04.2018 18:13:14 INFO      Number of hidden layers: 5
09.04.2018 18:13:14 INFO      Batch size:              128
09.04.2018 18:13:14 INFO      Learning rate:           0.001
09.04.2018 18:13:14 INFO      Learning rate decay:     0.0921034037198
09.04.2018 18:13:14 INFO      Number of epochs:        50
09.04.2018 18:13:14 INFO      NC experiments:          (10000 alternate + 10000 null) experiments with 1 alternate events each
09.04.2018 18:13:50 INFO    Starting training of score regression
Train on 8000000 samples, validate on 2000000 samples
2018-04-09 18:13:51.182863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-09 18:13:51.183216: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-09 18:13:51.183224: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-09 18:13:51.183229: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-09 18:13:51.183233: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-09 18:13:51.499691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-09 18:13:51.499724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-09 18:13:51.499729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-09 18:13:51.499737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 1/50
335s - loss: 0.0648 - val_loss: 0.0454
Epoch 2/50
335s - loss: 0.0438 - val_loss: 0.0324
Epoch 3/50
334s - loss: 0.0368 - val_loss: 0.0337
Epoch 4/50
334s - loss: 0.0320 - val_loss: 0.0316
Epoch 5/50
334s - loss: 0.0250 - val_loss: 0.0175
Epoch 6/50
334s - loss: 0.0221 - val_loss: 0.0165
Epoch 7/50
334s - loss: 0.0201 - val_loss: 0.0203
Epoch 8/50
334s - loss: 0.0174 - val_loss: 0.0105
Epoch 9/50
334s - loss: 0.0162 - val_loss: 0.0119
Epoch 10/50
334s - loss: 0.0144 - val_loss: 0.0088
Epoch 11/50
330s - loss: 0.0134 - val_loss: 0.0122
Epoch 12/50
339s - loss: 0.0121 - val_loss: 0.0102
Epoch 13/50
340s - loss: 0.0112 - val_loss: 0.0086
Epoch 14/50
328s - loss: 0.0104 - val_loss: 0.0074
Epoch 15/50
329s - loss: 0.0098 - val_loss: 0.0058
Epoch 16/50
328s - loss: 0.0089 - val_loss: 0.0063
Epoch 17/50
328s - loss: 0.0084 - val_loss: 0.0050
Epoch 18/50
329s - loss: 0.0079 - val_loss: 0.0045
Epoch 19/50
329s - loss: 0.0076 - val_loss: 0.0071
Epoch 20/50
328s - loss: 0.0072 - val_loss: 0.0049
Epoch 21/50
329s - loss: 0.0070 - val_loss: 0.0048
Epoch 22/50
328s - loss: 0.0067 - val_loss: 0.0043
Epoch 23/50
328s - loss: 0.0064 - val_loss: 0.0042
Epoch 24/50
328s - loss: 0.0062 - val_loss: 0.0040
Epoch 25/50
328s - loss: 0.0061 - val_loss: 0.0038
Epoch 26/50
329s - loss: 0.0059 - val_loss: 0.0038
Epoch 27/50
329s - loss: 0.0058 - val_loss: 0.0035
Epoch 28/50
329s - loss: 0.0057 - val_loss: 0.0038
Epoch 29/50
329s - loss: 0.0055 - val_loss: 0.0034
Epoch 30/50
328s - loss: 0.0054 - val_loss: 0.0036
Epoch 31/50
329s - loss: 0.0053 - val_loss: 0.0037
Epoch 32/50
329s - loss: 0.0052 - val_loss: 0.0038
Epoch 33/50
329s - loss: 0.0051 - val_loss: 0.0040
Epoch 34/50
328s - loss: 0.0051 - val_loss: 0.0037
Epoch 35/50
329s - loss: 0.0050 - val_loss: 0.0037
Epoch 36/50
328s - loss: 0.0049 - val_loss: 0.0035
Epoch 37/50
328s - loss: 0.0049 - val_loss: 0.0034
Epoch 38/50
328s - loss: 0.0048 - val_loss: 0.0035
Epoch 39/50
328s - loss: 0.0048 - val_loss: 0.0043
Epoch 40/50
328s - loss: 0.0047 - val_loss: 0.0038
Epoch 00039: early stopping
09.04.2018 21:54:33 INFO    Starting evaluation
09.04.2018 21:55:14 INFO    Score regression evaluation timing: 0.917432069778 s
09.04.2018 21:55:14 INFO    Starting density estimation
Traceback (most recent call last):
  File "experiments.py", line 131, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/score_regression.py", line 288, in score_regression_inference
    or (np.linspace(np.percentile(_tthat_calibration, 2.5) - np.percentile(_tthat_calibration, 97.5)))**2
TypeError: linspace() takes at least 2 arguments (1 given)
