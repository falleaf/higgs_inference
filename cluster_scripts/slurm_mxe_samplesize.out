Using TensorFlow backend.
02.07.2018 08:11:27 INFO    Hi! How are you today?
02.07.2018 08:11:27 INFO    Startup options:
02.07.2018 08:11:27 INFO      Algorithm:                     mxe
02.07.2018 08:11:27 INFO      Point by point:                False
02.07.2018 08:11:27 INFO      Morphing-aware mode:           False
02.07.2018 08:11:27 INFO      Smeared data:                  False
02.07.2018 08:11:27 INFO      Training sample:               baseline
02.07.2018 08:11:27 INFO      alpha:                         None
02.07.2018 08:11:27 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
02.07.2018 08:11:27 INFO      AFC epsilon:                   None
02.07.2018 08:11:27 INFO      Denominator theta:             False
02.07.2018 08:11:27 INFO      Neyman construction toys:      0
02.07.2018 08:11:27 INFO      Training sample size limit:    1000
02.07.2018 08:11:27 INFO      Other options:                 ['deep']
02.07.2018 08:11:27 INFO      Base directory:                /home/jb6504/higgs_inference
02.07.2018 08:11:27 INFO      ML-based strategies available: True
02.07.2018 08:11:27 INFO    Starting parameterized inference
02.07.2018 08:11:27 INFO    Main settings:
02.07.2018 08:11:27 INFO      Algorithm:                mxe
02.07.2018 08:11:27 INFO      Morphing-aware:           False
02.07.2018 08:11:27 INFO      Training sample:          baseline
02.07.2018 08:11:27 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
02.07.2018 08:11:27 INFO    Options:
02.07.2018 08:11:27 INFO      Number of hidden layers:  5
02.07.2018 08:11:27 INFO      Batch size:               128
02.07.2018 08:11:27 INFO      Learning rate:            0.001
02.07.2018 08:11:27 INFO      Learning rate decay:      9.21034037198e-06
02.07.2018 08:11:27 INFO      Number of epochs:         500000
02.07.2018 08:11:27 INFO      Training samples:         1000
02.07.2018 08:11:27 INFO      NC experiments:           False
02.07.2018 08:11:27 INFO      Debug mode:               False
02.07.2018 08:11:33 INFO    Reduced training sample size from 9999997 to 1000 (factor 10000)
02.07.2018 08:11:48 INFO    Starting training
2018-07-02 08:11:49.160182: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:11:49.160230: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:11:49.160236: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:11:49.160241: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:11:49.160245: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:11:49.377688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:84:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-02 08:11:49.377730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-02 08:11:49.377737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-02 08:11:49.377747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0)
Epoch 101015: early stopping
02.07.2018 10:08:10 INFO    Starting evaluation
02.07.2018 10:10:27 INFO    Starting theta 100 / 1017
02.07.2018 10:12:40 INFO    Starting theta 200 / 1017
02.07.2018 10:14:54 INFO    Starting theta 300 / 1017
02.07.2018 10:17:07 INFO    Starting theta 400 / 1017
02.07.2018 10:19:20 INFO    Starting theta 500 / 1017
02.07.2018 10:21:33 INFO    Starting theta 600 / 1017
02.07.2018 10:23:46 INFO    Starting theta 700 / 1017
02.07.2018 10:25:59 INFO    Starting theta 800 / 1017
02.07.2018 10:28:12 INFO    Starting theta 900 / 1017
02.07.2018 10:30:26 INFO    Starting theta 1000 / 1017
02.07.2018 10:30:50 INFO    Evaluation timing: median 1.3193218708 s, mean 1.32033523369 s
02.07.2018 10:30:50 INFO    Starting roaming
02.07.2018 10:31:17 INFO    Starting calibrated evaluation and roaming
02.07.2018 12:03:13 INFO    Starting theta 100 / 1017
02.07.2018 13:35:46 INFO    Starting theta 200 / 1017
02.07.2018 15:08:14 INFO    Starting theta 300 / 1017
02.07.2018 16:37:25 INFO    Starting theta 400 / 1017
02.07.2018 18:04:26 INFO    Starting theta 500 / 1017
02.07.2018 19:31:21 INFO    Starting theta 600 / 1017
02.07.2018 20:57:54 INFO    Starting theta 700 / 1017
02.07.2018 22:24:11 INFO    Starting theta 800 / 1017
02.07.2018 23:50:34 INFO    Starting theta 900 / 1017
03.07.2018 01:16:48 INFO    Starting theta 1000 / 1017
03.07.2018 01:32:20 INFO    Calibrated evaluation timing: median 1.24172902107 s, mean 1.26401195836 s
03.07.2018 01:32:20 INFO    Interpolating calibrated roaming
03.07.2018 01:36:49 INFO    That's it -- have a great day!
Using TensorFlow backend.
03.07.2018 01:36:51 INFO    Hi! How are you today?
03.07.2018 01:36:51 INFO    Startup options:
03.07.2018 01:36:51 INFO      Algorithm:                     mxe
03.07.2018 01:36:51 INFO      Point by point:                False
03.07.2018 01:36:51 INFO      Morphing-aware mode:           False
03.07.2018 01:36:51 INFO      Smeared data:                  False
03.07.2018 01:36:51 INFO      Training sample:               baseline
03.07.2018 01:36:51 INFO      alpha:                         None
03.07.2018 01:36:51 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
03.07.2018 01:36:51 INFO      AFC epsilon:                   None
03.07.2018 01:36:51 INFO      Denominator theta:             False
03.07.2018 01:36:51 INFO      Neyman construction toys:      0
03.07.2018 01:36:51 INFO      Training sample size limit:    2000
03.07.2018 01:36:51 INFO      Other options:                 ['deep']
03.07.2018 01:36:51 INFO      Base directory:                /home/jb6504/higgs_inference
03.07.2018 01:36:51 INFO      ML-based strategies available: True
03.07.2018 01:36:51 INFO    Starting parameterized inference
03.07.2018 01:36:51 INFO    Main settings:
03.07.2018 01:36:51 INFO      Algorithm:                mxe
03.07.2018 01:36:51 INFO      Morphing-aware:           False
03.07.2018 01:36:51 INFO      Training sample:          baseline
03.07.2018 01:36:51 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
03.07.2018 01:36:51 INFO    Options:
03.07.2018 01:36:51 INFO      Number of hidden layers:  5
03.07.2018 01:36:51 INFO      Batch size:               128
03.07.2018 01:36:51 INFO      Learning rate:            0.001
03.07.2018 01:36:51 INFO      Learning rate decay:      1.8420680744e-05
03.07.2018 01:36:51 INFO      Number of epochs:         250000
03.07.2018 01:36:51 INFO      Training samples:         2000
03.07.2018 01:36:51 INFO      NC experiments:           False
03.07.2018 01:36:51 INFO      Debug mode:               False
03.07.2018 01:37:12 INFO    Reduced training sample size from 9999997 to 2000 (factor 5000)
03.07.2018 01:37:26 INFO    Starting training
2018-07-03 01:37:27.217272: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 01:37:27.217308: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 01:37:27.217313: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 01:37:27.217322: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 01:37:27.217326: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 01:37:27.429067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:84:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-03 01:37:27.429106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-03 01:37:27.429113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-03 01:37:27.429122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0)
Epoch 50705: early stopping
03.07.2018 03:17:44 INFO    Starting evaluation
03.07.2018 03:19:51 INFO    Starting theta 100 / 1017
03.07.2018 03:21:54 INFO    Starting theta 200 / 1017
03.07.2018 03:23:57 INFO    Starting theta 300 / 1017
03.07.2018 03:26:01 INFO    Starting theta 400 / 1017
03.07.2018 03:28:04 INFO    Starting theta 500 / 1017
03.07.2018 03:30:07 INFO    Starting theta 600 / 1017
03.07.2018 03:32:10 INFO    Starting theta 700 / 1017
03.07.2018 03:34:14 INFO    Starting theta 800 / 1017
03.07.2018 03:36:17 INFO    Starting theta 900 / 1017
03.07.2018 03:38:20 INFO    Starting theta 1000 / 1017
03.07.2018 03:38:42 INFO    Evaluation timing: median 1.2193479538 s, mean 1.22332509077 s
03.07.2018 03:38:42 INFO    Starting roaming
03.07.2018 03:39:08 INFO    Starting calibrated evaluation and roaming
03.07.2018 05:04:09 INFO    Starting theta 100 / 1017
03.07.2018 06:29:42 INFO    Starting theta 200 / 1017
03.07.2018 07:55:22 INFO    Starting theta 300 / 1017
03.07.2018 09:23:28 INFO    Starting theta 400 / 1017
03.07.2018 10:51:07 INFO    Starting theta 500 / 1017
03.07.2018 12:20:50 INFO    Starting theta 600 / 1017
03.07.2018 13:47:58 INFO    Starting theta 700 / 1017
03.07.2018 15:13:33 INFO    Starting theta 800 / 1017
03.07.2018 16:39:08 INFO    Starting theta 900 / 1017
03.07.2018 18:04:41 INFO    Starting theta 1000 / 1017
03.07.2018 18:20:06 INFO    Calibrated evaluation timing: median 1.22257590294 s, mean 1.23749463865 s
03.07.2018 18:20:06 INFO    Interpolating calibrated roaming
03.07.2018 18:24:49 INFO    That's it -- have a great day!
Using TensorFlow backend.
03.07.2018 18:24:52 INFO    Hi! How are you today?
03.07.2018 18:24:52 INFO    Startup options:
03.07.2018 18:24:52 INFO      Algorithm:                     mxe
03.07.2018 18:24:52 INFO      Point by point:                False
03.07.2018 18:24:52 INFO      Morphing-aware mode:           False
03.07.2018 18:24:52 INFO      Smeared data:                  False
03.07.2018 18:24:52 INFO      Training sample:               baseline
03.07.2018 18:24:52 INFO      alpha:                         None
03.07.2018 18:24:52 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
03.07.2018 18:24:52 INFO      AFC epsilon:                   None
03.07.2018 18:24:52 INFO      Denominator theta:             False
03.07.2018 18:24:52 INFO      Neyman construction toys:      0
03.07.2018 18:24:52 INFO      Training sample size limit:    5000
03.07.2018 18:24:52 INFO      Other options:                 ['deep']
03.07.2018 18:24:52 INFO      Base directory:                /home/jb6504/higgs_inference
03.07.2018 18:24:52 INFO      ML-based strategies available: True
03.07.2018 18:24:52 INFO    Starting parameterized inference
03.07.2018 18:24:52 INFO    Main settings:
03.07.2018 18:24:52 INFO      Algorithm:                mxe
03.07.2018 18:24:52 INFO      Morphing-aware:           False
03.07.2018 18:24:52 INFO      Training sample:          baseline
03.07.2018 18:24:52 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
03.07.2018 18:24:52 INFO    Options:
03.07.2018 18:24:52 INFO      Number of hidden layers:  5
03.07.2018 18:24:52 INFO      Batch size:               128
03.07.2018 18:24:52 INFO      Learning rate:            0.001
03.07.2018 18:24:52 INFO      Learning rate decay:      4.60517018599e-05
03.07.2018 18:24:52 INFO      Number of epochs:         100000
03.07.2018 18:24:52 INFO      Training samples:         5000
03.07.2018 18:24:52 INFO      NC experiments:           False
03.07.2018 18:24:52 INFO      Debug mode:               False
03.07.2018 18:25:12 INFO    Reduced training sample size from 9999997 to 5000 (factor 2000)
03.07.2018 18:25:26 INFO    Starting training
2018-07-03 18:25:27.261990: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 18:25:27.262029: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 18:25:27.262034: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 18:25:27.262038: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 18:25:27.262042: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 18:25:27.475648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:84:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-03 18:25:27.475945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-03 18:25:27.475966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-03 18:25:27.475987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0)
Epoch 23263: early stopping
03.07.2018 20:16:31 INFO    Starting evaluation
03.07.2018 20:18:39 INFO    Starting theta 100 / 1017
03.07.2018 20:20:42 INFO    Starting theta 200 / 1017
03.07.2018 20:22:46 INFO    Starting theta 300 / 1017
03.07.2018 20:24:49 INFO    Starting theta 400 / 1017
03.07.2018 20:26:53 INFO    Starting theta 500 / 1017
03.07.2018 20:28:56 INFO    Starting theta 600 / 1017
03.07.2018 20:31:00 INFO    Starting theta 700 / 1017
03.07.2018 20:33:03 INFO    Starting theta 800 / 1017
03.07.2018 20:35:07 INFO    Starting theta 900 / 1017
03.07.2018 20:37:10 INFO    Starting theta 1000 / 1017
03.07.2018 20:37:33 INFO    Evaluation timing: median 1.22270202637 s, mean 1.22627933656 s
03.07.2018 20:37:33 INFO    Starting roaming
03.07.2018 20:37:58 INFO    Starting calibrated evaluation and roaming
03.07.2018 22:03:09 INFO    Starting theta 100 / 1017
03.07.2018 23:29:05 INFO    Starting theta 200 / 1017
04.07.2018 00:55:03 INFO    Starting theta 300 / 1017
04.07.2018 02:21:02 INFO    Starting theta 400 / 1017
04.07.2018 03:47:01 INFO    Starting theta 500 / 1017
04.07.2018 05:13:00 INFO    Starting theta 600 / 1017
04.07.2018 06:39:26 INFO    Starting theta 700 / 1017
04.07.2018 08:07:48 INFO    Starting theta 800 / 1017
04.07.2018 09:33:50 INFO    Starting theta 900 / 1017
04.07.2018 10:59:54 INFO    Starting theta 1000 / 1017
04.07.2018 11:15:24 INFO    Calibrated evaluation timing: median 1.22677206993 s, mean 1.23302700362 s
04.07.2018 11:15:24 INFO    Interpolating calibrated roaming
04.07.2018 11:21:16 INFO    That's it -- have a great day!
Using TensorFlow backend.
04.07.2018 11:21:19 INFO    Hi! How are you today?
04.07.2018 11:21:19 INFO    Startup options:
04.07.2018 11:21:19 INFO      Algorithm:                     mxe
04.07.2018 11:21:19 INFO      Point by point:                False
04.07.2018 11:21:19 INFO      Morphing-aware mode:           False
04.07.2018 11:21:19 INFO      Smeared data:                  False
04.07.2018 11:21:19 INFO      Training sample:               baseline
04.07.2018 11:21:19 INFO      alpha:                         None
04.07.2018 11:21:19 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
04.07.2018 11:21:19 INFO      AFC epsilon:                   None
04.07.2018 11:21:19 INFO      Denominator theta:             False
04.07.2018 11:21:19 INFO      Neyman construction toys:      0
04.07.2018 11:21:19 INFO      Training sample size limit:    10000
04.07.2018 11:21:19 INFO      Other options:                 ['deep']
04.07.2018 11:21:19 INFO      Base directory:                /home/jb6504/higgs_inference
04.07.2018 11:21:19 INFO      ML-based strategies available: True
04.07.2018 11:21:19 INFO    Starting parameterized inference
04.07.2018 11:21:19 INFO    Main settings:
04.07.2018 11:21:19 INFO      Algorithm:                mxe
04.07.2018 11:21:19 INFO      Morphing-aware:           False
04.07.2018 11:21:19 INFO      Training sample:          baseline
04.07.2018 11:21:19 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
04.07.2018 11:21:19 INFO    Options:
04.07.2018 11:21:19 INFO      Number of hidden layers:  5
04.07.2018 11:21:19 INFO      Batch size:               128
04.07.2018 11:21:19 INFO      Learning rate:            0.001
04.07.2018 11:21:19 INFO      Learning rate decay:      9.21034037198e-05
04.07.2018 11:21:19 INFO      Number of epochs:         50000
04.07.2018 11:21:19 INFO      Training samples:         10000
04.07.2018 11:21:19 INFO      NC experiments:           False
04.07.2018 11:21:19 INFO      Debug mode:               False
04.07.2018 11:21:46 INFO    Reduced training sample size from 9999997 to 10000 (factor 1000)
04.07.2018 11:22:00 INFO    Starting training
2018-07-04 11:22:01.128258: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-04 11:22:01.128296: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-04 11:22:01.128301: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-04 11:22:01.128305: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-04 11:22:01.128310: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-04 11:22:01.343899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:84:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-04 11:22:01.343939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-04 11:22:01.343946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-04 11:22:01.343956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0)
Epoch 10073: early stopping
04.07.2018 12:56:03 INFO    Starting evaluation
04.07.2018 12:58:09 INFO    Starting theta 100 / 1017
04.07.2018 13:00:11 INFO    Starting theta 200 / 1017
04.07.2018 13:02:13 INFO    Starting theta 300 / 1017
04.07.2018 13:04:15 INFO    Starting theta 400 / 1017
04.07.2018 13:06:18 INFO    Starting theta 500 / 1017
04.07.2018 13:08:20 INFO    Starting theta 600 / 1017
04.07.2018 13:10:22 INFO    Starting theta 700 / 1017
04.07.2018 13:12:25 INFO    Starting theta 800 / 1017
04.07.2018 13:14:27 INFO    Starting theta 900 / 1017
04.07.2018 13:16:29 INFO    Starting theta 1000 / 1017
04.07.2018 13:16:51 INFO    Evaluation timing: median 1.20935106277 s, mean 1.21356950045 s
04.07.2018 13:16:51 INFO    Starting roaming
04.07.2018 13:17:16 INFO    Starting calibrated evaluation and roaming
04.07.2018 14:41:45 INFO    Starting theta 100 / 1017
04.07.2018 16:07:03 INFO    Starting theta 200 / 1017
04.07.2018 17:32:30 INFO    Starting theta 300 / 1017
04.07.2018 18:57:47 INFO    Starting theta 400 / 1017
04.07.2018 20:22:55 INFO    Starting theta 500 / 1017
04.07.2018 21:48:03 INFO    Starting theta 600 / 1017
04.07.2018 23:13:11 INFO    Starting theta 700 / 1017
05.07.2018 00:38:17 INFO    Starting theta 800 / 1017
05.07.2018 02:03:19 INFO    Starting theta 900 / 1017
05.07.2018 03:28:24 INFO    Starting theta 1000 / 1017
05.07.2018 03:43:43 INFO    Calibrated evaluation timing: median 1.21514797211 s, mean 1.21747482749 s
05.07.2018 03:43:43 INFO    Interpolating calibrated roaming
05.07.2018 03:48:31 INFO    That's it -- have a great day!
Using TensorFlow backend.
05.07.2018 03:48:33 INFO    Hi! How are you today?
05.07.2018 03:48:33 INFO    Startup options:
05.07.2018 03:48:33 INFO      Algorithm:                     mxe
05.07.2018 03:48:33 INFO      Point by point:                False
05.07.2018 03:48:33 INFO      Morphing-aware mode:           False
05.07.2018 03:48:33 INFO      Smeared data:                  False
05.07.2018 03:48:33 INFO      Training sample:               baseline
05.07.2018 03:48:33 INFO      alpha:                         None
05.07.2018 03:48:33 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
05.07.2018 03:48:33 INFO      AFC epsilon:                   None
05.07.2018 03:48:33 INFO      Denominator theta:             False
05.07.2018 03:48:33 INFO      Neyman construction toys:      0
05.07.2018 03:48:33 INFO      Training sample size limit:    20000
05.07.2018 03:48:33 INFO      Other options:                 ['deep']
05.07.2018 03:48:33 INFO      Base directory:                /home/jb6504/higgs_inference
05.07.2018 03:48:33 INFO      ML-based strategies available: True
05.07.2018 03:48:33 INFO    Starting parameterized inference
05.07.2018 03:48:33 INFO    Main settings:
05.07.2018 03:48:33 INFO      Algorithm:                mxe
05.07.2018 03:48:33 INFO      Morphing-aware:           False
05.07.2018 03:48:33 INFO      Training sample:          baseline
05.07.2018 03:48:33 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
05.07.2018 03:48:33 INFO    Options:
05.07.2018 03:48:33 INFO      Number of hidden layers:  5
05.07.2018 03:48:33 INFO      Batch size:               128
05.07.2018 03:48:33 INFO      Learning rate:            0.001
05.07.2018 03:48:33 INFO      Learning rate decay:      0.00018420680744
05.07.2018 03:48:33 INFO      Number of epochs:         25000
05.07.2018 03:48:33 INFO      Training samples:         20000
05.07.2018 03:48:33 INFO      NC experiments:           False
05.07.2018 03:48:33 INFO      Debug mode:               False
05.07.2018 03:48:55 INFO    Reduced training sample size from 9999997 to 20000 (factor 500)
05.07.2018 03:49:08 INFO    Starting training
2018-07-05 03:49:09.579675: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-05 03:49:09.579712: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-05 03:49:09.579717: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-05 03:49:09.579726: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-05 03:49:09.579730: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-05 03:49:09.815743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:84:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-05 03:49:09.815783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-05 03:49:09.815790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-05 03:49:09.815800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:84:00.0)
Epoch 05104: early stopping
05.07.2018 05:23:37 INFO    Starting evaluation
05.07.2018 05:25:43 INFO    Starting theta 100 / 1017
05.07.2018 05:27:46 INFO    Starting theta 200 / 1017
05.07.2018 05:29:49 INFO    Starting theta 300 / 1017
05.07.2018 05:31:52 INFO    Starting theta 400 / 1017
05.07.2018 05:33:55 INFO    Starting theta 500 / 1017
05.07.2018 05:35:59 INFO    Starting theta 600 / 1017
05.07.2018 05:38:02 INFO    Starting theta 700 / 1017
05.07.2018 05:40:05 INFO    Starting theta 800 / 1017
05.07.2018 05:42:08 INFO    Starting theta 900 / 1017
05.07.2018 05:44:11 INFO    Starting theta 1000 / 1017
05.07.2018 05:44:33 INFO    Evaluation timing: median 1.21915102005 s, mean 1.22151562996 s
05.07.2018 05:44:33 INFO    Starting roaming
05.07.2018 05:44:58 INFO    Starting calibrated evaluation and roaming
05.07.2018 07:10:01 INFO    Starting theta 100 / 1017
05.07.2018 08:35:48 INFO    Starting theta 200 / 1017
05.07.2018 10:01:36 INFO    Starting theta 300 / 1017
