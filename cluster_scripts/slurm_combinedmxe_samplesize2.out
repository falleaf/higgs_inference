Using TensorFlow backend.
28.06.2018 11:19:59 INFO    Hi! How are you today?
28.06.2018 11:19:59 INFO    Startup options:
28.06.2018 11:19:59 INFO      Algorithm:                     combinedmxe
28.06.2018 11:19:59 INFO      Point by point:                False
28.06.2018 11:19:59 INFO      Morphing-aware mode:           False
28.06.2018 11:19:59 INFO      Smeared data:                  False
28.06.2018 11:19:59 INFO      Training sample:               baseline
28.06.2018 11:19:59 INFO      alpha:                         None
28.06.2018 11:19:59 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
28.06.2018 11:19:59 INFO      AFC epsilon:                   None
28.06.2018 11:19:59 INFO      Denominator theta:             False
28.06.2018 11:19:59 INFO      Neyman construction toys:      0
28.06.2018 11:19:59 INFO      Training sample size limit:    100000
28.06.2018 11:19:59 INFO      Other options:                 ['deep']
28.06.2018 11:19:59 INFO      Base directory:                /home/jb6504/higgs_inference
28.06.2018 11:19:59 INFO      ML-based strategies available: True
28.06.2018 11:19:59 INFO    Starting parameterized inference
28.06.2018 11:19:59 INFO    Main settings:
28.06.2018 11:19:59 INFO      Algorithm:                combinedmxe
28.06.2018 11:19:59 INFO      Morphing-aware:           False
28.06.2018 11:19:59 INFO      Training sample:          baseline
28.06.2018 11:19:59 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
28.06.2018 11:19:59 INFO    Options:
28.06.2018 11:19:59 INFO      Number of hidden layers:  5
28.06.2018 11:19:59 INFO      alpha:                    5.0
28.06.2018 11:19:59 INFO      Batch size:               128
28.06.2018 11:19:59 INFO      Learning rate:            0.001
28.06.2018 11:19:59 INFO      Learning rate decay:      0.000921034037198
28.06.2018 11:19:59 INFO      Number of epochs:         5000
28.06.2018 11:19:59 INFO      Training samples:         100000
28.06.2018 11:19:59 INFO      NC experiments:           False
28.06.2018 11:19:59 INFO      Debug mode:               False
28.06.2018 11:20:08 INFO    Reduced training sample size from 9999997 to 100000 (factor 100)
28.06.2018 11:20:22 INFO    Starting training
2018-06-28 11:20:23.261832: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-28 11:20:23.261863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-28 11:20:23.261868: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-06-28 11:20:23.261872: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-28 11:20:23.261876: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-06-28 11:20:23.471860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-06-28 11:20:23.471895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-06-28 11:20:23.471900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-06-28 11:20:23.471908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 04018: early stopping
28.06.2018 16:55:35 INFO    Starting evaluation
28.06.2018 16:57:25 INFO    Starting theta 100 / 1017
28.06.2018 16:59:12 INFO    Starting theta 200 / 1017
28.06.2018 17:00:59 INFO    Starting theta 300 / 1017
28.06.2018 17:02:46 INFO    Starting theta 400 / 1017
28.06.2018 17:04:33 INFO    Starting theta 500 / 1017
28.06.2018 17:06:20 INFO    Starting theta 600 / 1017
28.06.2018 17:08:07 INFO    Starting theta 700 / 1017
28.06.2018 17:09:54 INFO    Starting theta 800 / 1017
28.06.2018 17:11:41 INFO    Starting theta 900 / 1017
28.06.2018 17:13:28 INFO    Starting theta 1000 / 1017
28.06.2018 17:13:47 INFO    Evaluation timing: median 1.05776500702 s, mean 1.06128889809 s
28.06.2018 17:13:47 INFO    Starting roaming
28.06.2018 17:14:09 INFO    Starting calibrated evaluation and roaming
28.06.2018 18:28:08 INFO    Starting theta 100 / 1017
28.06.2018 19:42:43 INFO    Starting theta 200 / 1017
28.06.2018 20:57:19 INFO    Starting theta 300 / 1017
28.06.2018 22:11:56 INFO    Starting theta 400 / 1017
28.06.2018 23:26:33 INFO    Starting theta 500 / 1017
29.06.2018 00:41:11 INFO    Starting theta 600 / 1017
29.06.2018 01:55:48 INFO    Starting theta 700 / 1017
29.06.2018 03:10:30 INFO    Starting theta 800 / 1017
29.06.2018 04:25:05 INFO    Starting theta 900 / 1017
29.06.2018 05:39:40 INFO    Starting theta 1000 / 1017
29.06.2018 05:53:05 INFO    Calibrated evaluation timing: median 1.06395483017 s, mean 1.06599260807 s
29.06.2018 05:53:05 INFO    Interpolating calibrated roaming
29.06.2018 05:57:42 INFO    That's it -- have a great day!
Using TensorFlow backend.
29.06.2018 05:57:45 INFO    Hi! How are you today?
29.06.2018 05:57:45 INFO    Startup options:
29.06.2018 05:57:45 INFO      Algorithm:                     combinedmxe
29.06.2018 05:57:45 INFO      Point by point:                False
29.06.2018 05:57:45 INFO      Morphing-aware mode:           False
29.06.2018 05:57:45 INFO      Smeared data:                  False
29.06.2018 05:57:45 INFO      Training sample:               baseline
29.06.2018 05:57:45 INFO      alpha:                         None
29.06.2018 05:57:45 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
29.06.2018 05:57:45 INFO      AFC epsilon:                   None
29.06.2018 05:57:45 INFO      Denominator theta:             False
29.06.2018 05:57:45 INFO      Neyman construction toys:      0
29.06.2018 05:57:45 INFO      Training sample size limit:    200000
29.06.2018 05:57:45 INFO      Other options:                 ['deep']
29.06.2018 05:57:45 INFO      Base directory:                /home/jb6504/higgs_inference
29.06.2018 05:57:45 INFO      ML-based strategies available: True
29.06.2018 05:57:45 INFO    Starting parameterized inference
29.06.2018 05:57:45 INFO    Main settings:
29.06.2018 05:57:45 INFO      Algorithm:                combinedmxe
29.06.2018 05:57:45 INFO      Morphing-aware:           False
29.06.2018 05:57:45 INFO      Training sample:          baseline
29.06.2018 05:57:45 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
29.06.2018 05:57:45 INFO    Options:
29.06.2018 05:57:45 INFO      Number of hidden layers:  5
29.06.2018 05:57:45 INFO      alpha:                    5.0
29.06.2018 05:57:45 INFO      Batch size:               128
29.06.2018 05:57:45 INFO      Learning rate:            0.001
29.06.2018 05:57:45 INFO      Learning rate decay:      0.0018420680744
29.06.2018 05:57:45 INFO      Number of epochs:         2500
29.06.2018 05:57:45 INFO      Training samples:         200000
29.06.2018 05:57:45 INFO      NC experiments:           False
29.06.2018 05:57:45 INFO      Debug mode:               False
29.06.2018 05:58:17 INFO    Reduced training sample size from 9999997 to 200000 (factor 50)
29.06.2018 05:58:31 INFO    Starting training
2018-06-29 05:58:32.145323: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-29 05:58:32.145358: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-29 05:58:32.145366: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-06-29 05:58:32.145371: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-29 05:58:32.145374: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-06-29 05:58:32.355107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-06-29 05:58:32.355140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-06-29 05:58:32.355146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-06-29 05:58:32.355154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
29.06.2018 12:54:01 INFO    Starting evaluation
29.06.2018 12:55:51 INFO    Starting theta 100 / 1017
29.06.2018 12:57:38 INFO    Starting theta 200 / 1017
29.06.2018 12:59:25 INFO    Starting theta 300 / 1017
29.06.2018 13:01:12 INFO    Starting theta 400 / 1017
29.06.2018 13:02:59 INFO    Starting theta 500 / 1017
29.06.2018 13:04:45 INFO    Starting theta 600 / 1017
29.06.2018 13:06:32 INFO    Starting theta 700 / 1017
29.06.2018 13:08:19 INFO    Starting theta 800 / 1017
29.06.2018 13:10:06 INFO    Starting theta 900 / 1017
29.06.2018 13:11:53 INFO    Starting theta 1000 / 1017
29.06.2018 13:12:12 INFO    Evaluation timing: median 1.05768895149 s, mean 1.0598427246 s
29.06.2018 13:12:12 INFO    Starting roaming
29.06.2018 13:12:34 INFO    Starting calibrated evaluation and roaming
29.06.2018 14:27:21 INFO    Starting theta 100 / 1017
29.06.2018 15:43:29 INFO    Starting theta 200 / 1017
29.06.2018 16:58:44 INFO    Starting theta 300 / 1017
29.06.2018 18:13:41 INFO    Starting theta 400 / 1017
29.06.2018 19:28:25 INFO    Starting theta 500 / 1017
29.06.2018 20:43:36 INFO    Starting theta 600 / 1017
29.06.2018 21:58:45 INFO    Starting theta 700 / 1017
29.06.2018 23:13:53 INFO    Starting theta 800 / 1017
30.06.2018 00:28:33 INFO    Starting theta 900 / 1017
30.06.2018 01:43:10 INFO    Starting theta 1000 / 1017
30.06.2018 01:56:36 INFO    Calibrated evaluation timing: median 1.07032203674 s, mean 1.07405724591 s
30.06.2018 01:56:36 INFO    Interpolating calibrated roaming
30.06.2018 02:02:27 INFO    That's it -- have a great day!
Using TensorFlow backend.
30.06.2018 02:02:30 INFO    Hi! How are you today?
30.06.2018 02:02:30 INFO    Startup options:
30.06.2018 02:02:30 INFO      Algorithm:                     combinedmxe
30.06.2018 02:02:30 INFO      Point by point:                False
30.06.2018 02:02:30 INFO      Morphing-aware mode:           False
30.06.2018 02:02:30 INFO      Smeared data:                  False
30.06.2018 02:02:30 INFO      Training sample:               baseline
30.06.2018 02:02:30 INFO      alpha:                         None
30.06.2018 02:02:30 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
30.06.2018 02:02:30 INFO      AFC epsilon:                   None
30.06.2018 02:02:30 INFO      Denominator theta:             False
30.06.2018 02:02:30 INFO      Neyman construction toys:      0
30.06.2018 02:02:30 INFO      Training sample size limit:    500000
30.06.2018 02:02:30 INFO      Other options:                 ['deep']
30.06.2018 02:02:30 INFO      Base directory:                /home/jb6504/higgs_inference
30.06.2018 02:02:30 INFO      ML-based strategies available: True
30.06.2018 02:02:30 INFO    Starting parameterized inference
30.06.2018 02:02:30 INFO    Main settings:
30.06.2018 02:02:30 INFO      Algorithm:                combinedmxe
30.06.2018 02:02:30 INFO      Morphing-aware:           False
30.06.2018 02:02:30 INFO      Training sample:          baseline
30.06.2018 02:02:30 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
30.06.2018 02:02:30 INFO    Options:
30.06.2018 02:02:30 INFO      Number of hidden layers:  5
30.06.2018 02:02:30 INFO      alpha:                    5.0
30.06.2018 02:02:30 INFO      Batch size:               128
30.06.2018 02:02:30 INFO      Learning rate:            0.001
30.06.2018 02:02:30 INFO      Learning rate decay:      0.00460517018599
30.06.2018 02:02:30 INFO      Number of epochs:         1000
30.06.2018 02:02:30 INFO      Training samples:         500000
30.06.2018 02:02:30 INFO      NC experiments:           False
30.06.2018 02:02:30 INFO      Debug mode:               False
30.06.2018 02:02:52 INFO    Reduced training sample size from 9999997 to 500000 (factor 20)
30.06.2018 02:03:07 INFO    Starting training
2018-06-30 02:03:08.222766: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 02:03:08.222798: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 02:03:08.222803: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 02:03:08.222807: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 02:03:08.222811: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 02:03:08.431754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-06-30 02:03:08.431789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-06-30 02:03:08.431795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-06-30 02:03:08.431803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
30.06.2018 08:57:02 INFO    Starting evaluation
30.06.2018 08:58:52 INFO    Starting theta 100 / 1017
30.06.2018 09:00:40 INFO    Starting theta 200 / 1017
30.06.2018 09:02:28 INFO    Starting theta 300 / 1017
30.06.2018 09:04:15 INFO    Starting theta 400 / 1017
30.06.2018 09:06:02 INFO    Starting theta 500 / 1017
30.06.2018 09:07:49 INFO    Starting theta 600 / 1017
30.06.2018 09:09:37 INFO    Starting theta 700 / 1017
30.06.2018 09:11:24 INFO    Starting theta 800 / 1017
30.06.2018 09:13:11 INFO    Starting theta 900 / 1017
30.06.2018 09:14:59 INFO    Starting theta 1000 / 1017
30.06.2018 09:15:18 INFO    Evaluation timing: median 1.06312608719 s, mean 1.06522457719 s
30.06.2018 09:15:18 INFO    Starting roaming
30.06.2018 09:15:40 INFO    Starting calibrated evaluation and roaming
30.06.2018 10:29:56 INFO    Starting theta 100 / 1017
30.06.2018 11:44:50 INFO    Starting theta 200 / 1017
30.06.2018 12:59:46 INFO    Starting theta 300 / 1017
30.06.2018 14:14:44 INFO    Starting theta 400 / 1017
30.06.2018 15:29:38 INFO    Starting theta 500 / 1017
30.06.2018 16:44:32 INFO    Starting theta 600 / 1017
30.06.2018 17:59:28 INFO    Starting theta 700 / 1017
30.06.2018 19:14:22 INFO    Starting theta 800 / 1017
30.06.2018 20:29:17 INFO    Starting theta 900 / 1017
30.06.2018 21:44:13 INFO    Starting theta 1000 / 1017
30.06.2018 21:57:42 INFO    Calibrated evaluation timing: median 1.06917905807 s, mean 1.07010953663 s
30.06.2018 21:57:42 INFO    Interpolating calibrated roaming
30.06.2018 22:03:07 INFO    That's it -- have a great day!
Using TensorFlow backend.
30.06.2018 22:03:09 INFO    Hi! How are you today?
30.06.2018 22:03:09 INFO    Startup options:
30.06.2018 22:03:09 INFO      Algorithm:                     combinedmxe
30.06.2018 22:03:09 INFO      Point by point:                False
30.06.2018 22:03:09 INFO      Morphing-aware mode:           False
30.06.2018 22:03:09 INFO      Smeared data:                  False
30.06.2018 22:03:09 INFO      Training sample:               baseline
30.06.2018 22:03:09 INFO      alpha:                         None
30.06.2018 22:03:09 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
30.06.2018 22:03:09 INFO      AFC epsilon:                   None
30.06.2018 22:03:09 INFO      Denominator theta:             False
30.06.2018 22:03:09 INFO      Neyman construction toys:      0
30.06.2018 22:03:09 INFO      Training sample size limit:    1000000
30.06.2018 22:03:09 INFO      Other options:                 ['deep']
30.06.2018 22:03:09 INFO      Base directory:                /home/jb6504/higgs_inference
30.06.2018 22:03:09 INFO      ML-based strategies available: True
30.06.2018 22:03:09 INFO    Starting parameterized inference
30.06.2018 22:03:09 INFO    Main settings:
30.06.2018 22:03:09 INFO      Algorithm:                combinedmxe
30.06.2018 22:03:09 INFO      Morphing-aware:           False
30.06.2018 22:03:09 INFO      Training sample:          baseline
30.06.2018 22:03:09 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
30.06.2018 22:03:09 INFO    Options:
30.06.2018 22:03:09 INFO      Number of hidden layers:  5
30.06.2018 22:03:09 INFO      alpha:                    5.0
30.06.2018 22:03:09 INFO      Batch size:               128
30.06.2018 22:03:09 INFO      Learning rate:            0.001
30.06.2018 22:03:09 INFO      Learning rate decay:      0.00921034037198
30.06.2018 22:03:09 INFO      Number of epochs:         500
30.06.2018 22:03:09 INFO      Training samples:         1000000
30.06.2018 22:03:09 INFO      NC experiments:           False
30.06.2018 22:03:09 INFO      Debug mode:               False
30.06.2018 22:03:29 INFO    Reduced training sample size from 9999997 to 1000000 (factor 10)
30.06.2018 22:03:44 INFO    Starting training
2018-06-30 22:03:45.574968: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 22:03:45.575258: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 22:03:45.575266: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 22:03:45.575270: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 22:03:45.575274: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-06-30 22:03:45.784921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-06-30 22:03:45.784954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-06-30 22:03:45.784959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-06-30 22:03:45.784967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
01.07.2018 04:57:08 INFO    Starting evaluation
01.07.2018 04:58:57 INFO    Starting theta 100 / 1017
01.07.2018 05:00:43 INFO    Starting theta 200 / 1017
01.07.2018 05:02:29 INFO    Starting theta 300 / 1017
01.07.2018 05:04:15 INFO    Starting theta 400 / 1017
01.07.2018 05:06:01 INFO    Starting theta 500 / 1017
01.07.2018 05:07:47 INFO    Starting theta 600 / 1017
01.07.2018 05:09:32 INFO    Starting theta 700 / 1017
01.07.2018 05:11:18 INFO    Starting theta 800 / 1017
01.07.2018 05:13:04 INFO    Starting theta 900 / 1017
01.07.2018 05:14:50 INFO    Starting theta 1000 / 1017
01.07.2018 05:15:09 INFO    Evaluation timing: median 1.04850387573 s, mean 1.05043330446 s
01.07.2018 05:15:09 INFO    Starting roaming
01.07.2018 05:15:31 INFO    Starting calibrated evaluation and roaming
01.07.2018 06:28:49 INFO    Starting theta 100 / 1017
01.07.2018 07:42:47 INFO    Starting theta 200 / 1017
01.07.2018 08:56:44 INFO    Starting theta 300 / 1017
01.07.2018 10:10:42 INFO    Starting theta 400 / 1017
01.07.2018 11:24:42 INFO    Starting theta 500 / 1017
01.07.2018 12:38:41 INFO    Starting theta 600 / 1017
01.07.2018 13:52:39 INFO    Starting theta 700 / 1017
01.07.2018 15:06:41 INFO    Starting theta 800 / 1017
01.07.2018 16:20:44 INFO    Starting theta 900 / 1017
01.07.2018 17:34:48 INFO    Starting theta 1000 / 1017
01.07.2018 17:48:08 INFO    Calibrated evaluation timing: median 1.05615210533 s, mean 1.05766008503 s
01.07.2018 17:48:08 INFO    Interpolating calibrated roaming
01.07.2018 17:53:33 INFO    That's it -- have a great day!
Using TensorFlow backend.
01.07.2018 17:53:36 INFO    Hi! How are you today?
01.07.2018 17:53:36 INFO    Startup options:
01.07.2018 17:53:36 INFO      Algorithm:                     combinedmxe
01.07.2018 17:53:36 INFO      Point by point:                False
01.07.2018 17:53:36 INFO      Morphing-aware mode:           False
01.07.2018 17:53:36 INFO      Smeared data:                  False
01.07.2018 17:53:36 INFO      Training sample:               baseline
01.07.2018 17:53:36 INFO      alpha:                         None
01.07.2018 17:53:36 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
01.07.2018 17:53:36 INFO      AFC epsilon:                   None
01.07.2018 17:53:36 INFO      Denominator theta:             False
01.07.2018 17:53:36 INFO      Neyman construction toys:      0
01.07.2018 17:53:36 INFO      Training sample size limit:    2000000
01.07.2018 17:53:36 INFO      Other options:                 ['deep']
01.07.2018 17:53:36 INFO      Base directory:                /home/jb6504/higgs_inference
01.07.2018 17:53:36 INFO      ML-based strategies available: True
01.07.2018 17:53:36 INFO    Starting parameterized inference
01.07.2018 17:53:36 INFO    Main settings:
01.07.2018 17:53:36 INFO      Algorithm:                combinedmxe
01.07.2018 17:53:36 INFO      Morphing-aware:           False
01.07.2018 17:53:36 INFO      Training sample:          baseline
01.07.2018 17:53:36 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
01.07.2018 17:53:36 INFO    Options:
01.07.2018 17:53:36 INFO      Number of hidden layers:  5
01.07.2018 17:53:36 INFO      alpha:                    5.0
01.07.2018 17:53:36 INFO      Batch size:               128
01.07.2018 17:53:36 INFO      Learning rate:            0.001
01.07.2018 17:53:36 INFO      Learning rate decay:      0.018420680744
01.07.2018 17:53:36 INFO      Number of epochs:         250
01.07.2018 17:53:36 INFO      Training samples:         2000000
01.07.2018 17:53:36 INFO      NC experiments:           False
01.07.2018 17:53:36 INFO      Debug mode:               False
01.07.2018 17:53:55 INFO    Reduced training sample size from 9999997 to 2000000 (factor 5)
01.07.2018 17:54:13 INFO    Starting training
2018-07-01 17:54:14.056022: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-01 17:54:14.056060: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-01 17:54:14.056065: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-01 17:54:14.056069: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-01 17:54:14.056072: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-01 17:54:14.263803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-01 17:54:14.263838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-01 17:54:14.263843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-01 17:54:14.263851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
02.07.2018 00:56:41 INFO    Starting evaluation
02.07.2018 00:58:32 INFO    Starting theta 100 / 1017
02.07.2018 01:00:19 INFO    Starting theta 200 / 1017
02.07.2018 01:02:07 INFO    Starting theta 300 / 1017
02.07.2018 01:03:54 INFO    Starting theta 400 / 1017
02.07.2018 01:05:42 INFO    Starting theta 500 / 1017
02.07.2018 01:07:30 INFO    Starting theta 600 / 1017
02.07.2018 01:09:17 INFO    Starting theta 700 / 1017
02.07.2018 01:11:04 INFO    Starting theta 800 / 1017
02.07.2018 01:12:52 INFO    Starting theta 900 / 1017
02.07.2018 01:14:40 INFO    Starting theta 1000 / 1017
02.07.2018 01:14:59 INFO    Evaluation timing: median 1.06369781494 s, mean 1.06663831052 s
02.07.2018 01:14:59 INFO    Starting roaming
02.07.2018 01:15:21 INFO    Starting calibrated evaluation and roaming
02.07.2018 02:29:46 INFO    Starting theta 100 / 1017
02.07.2018 03:44:49 INFO    Starting theta 200 / 1017
02.07.2018 04:59:53 INFO    Starting theta 300 / 1017
02.07.2018 06:14:57 INFO    Starting theta 400 / 1017
02.07.2018 07:30:01 INFO    Starting theta 500 / 1017
02.07.2018 08:45:06 INFO    Starting theta 600 / 1017
02.07.2018 10:00:09 INFO    Starting theta 700 / 1017
02.07.2018 11:15:17 INFO    Starting theta 800 / 1017
02.07.2018 12:31:44 INFO    Starting theta 900 / 1017
02.07.2018 13:47:58 INFO    Starting theta 1000 / 1017
02.07.2018 14:01:45 INFO    Calibrated evaluation timing: median 1.07107806206 s, mean 1.07641846545 s
02.07.2018 14:01:45 INFO    Interpolating calibrated roaming
02.07.2018 14:07:29 INFO    That's it -- have a great day!
Using TensorFlow backend.
02.07.2018 14:07:31 INFO    Hi! How are you today?
02.07.2018 14:07:31 INFO    Startup options:
02.07.2018 14:07:31 INFO      Algorithm:                     combinedmxe
02.07.2018 14:07:31 INFO      Point by point:                False
02.07.2018 14:07:31 INFO      Morphing-aware mode:           False
02.07.2018 14:07:31 INFO      Smeared data:                  False
02.07.2018 14:07:31 INFO      Training sample:               baseline
02.07.2018 14:07:31 INFO      alpha:                         None
02.07.2018 14:07:31 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
02.07.2018 14:07:31 INFO      AFC epsilon:                   None
02.07.2018 14:07:31 INFO      Denominator theta:             False
02.07.2018 14:07:31 INFO      Neyman construction toys:      0
02.07.2018 14:07:31 INFO      Training sample size limit:    5000000
02.07.2018 14:07:31 INFO      Other options:                 ['deep']
02.07.2018 14:07:31 INFO      Base directory:                /home/jb6504/higgs_inference
02.07.2018 14:07:31 INFO      ML-based strategies available: True
02.07.2018 14:07:31 INFO    Starting parameterized inference
02.07.2018 14:07:31 INFO    Main settings:
02.07.2018 14:07:31 INFO      Algorithm:                combinedmxe
02.07.2018 14:07:31 INFO      Morphing-aware:           False
02.07.2018 14:07:31 INFO      Training sample:          baseline
02.07.2018 14:07:31 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
02.07.2018 14:07:31 INFO    Options:
02.07.2018 14:07:31 INFO      Number of hidden layers:  5
02.07.2018 14:07:31 INFO      alpha:                    5.0
02.07.2018 14:07:31 INFO      Batch size:               128
02.07.2018 14:07:31 INFO      Learning rate:            0.001
02.07.2018 14:07:31 INFO      Learning rate decay:      0.0460517018599
02.07.2018 14:07:31 INFO      Number of epochs:         100
02.07.2018 14:07:31 INFO      Training samples:         5000000
02.07.2018 14:07:31 INFO      NC experiments:           False
02.07.2018 14:07:31 INFO      Debug mode:               False
02.07.2018 14:07:52 INFO    Reduced training sample size from 9999997 to 5000000 (factor 2)
02.07.2018 14:08:16 INFO    Starting training
2018-07-02 14:08:17.425920: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 14:08:17.425953: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 14:08:17.425959: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 14:08:17.425963: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 14:08:17.425968: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 14:08:17.642784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-02 14:08:17.642818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-02 14:08:17.642824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-02 14:08:17.642832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
02.07.2018 21:10:11 INFO    Starting evaluation
02.07.2018 21:12:03 INFO    Starting theta 100 / 1017
02.07.2018 21:13:50 INFO    Starting theta 200 / 1017
02.07.2018 21:15:36 INFO    Starting theta 300 / 1017
02.07.2018 21:17:23 INFO    Starting theta 400 / 1017
02.07.2018 21:19:09 INFO    Starting theta 500 / 1017
02.07.2018 21:20:56 INFO    Starting theta 600 / 1017
02.07.2018 21:22:42 INFO    Starting theta 700 / 1017
02.07.2018 21:24:29 INFO    Starting theta 800 / 1017
02.07.2018 21:26:15 INFO    Starting theta 900 / 1017
02.07.2018 21:28:02 INFO    Starting theta 1000 / 1017
02.07.2018 21:28:21 INFO    Evaluation timing: median 1.05454111099 s, mean 1.05834207657 s
02.07.2018 21:28:21 INFO    Starting roaming
02.07.2018 21:28:43 INFO    Starting calibrated evaluation and roaming
02.07.2018 22:43:50 INFO    Starting theta 100 / 1017
02.07.2018 23:59:42 INFO    Starting theta 200 / 1017
03.07.2018 01:15:39 INFO    Starting theta 300 / 1017
03.07.2018 02:31:26 INFO    Starting theta 400 / 1017
03.07.2018 03:47:14 INFO    Starting theta 500 / 1017
03.07.2018 05:02:15 INFO    Starting theta 600 / 1017
03.07.2018 06:16:44 INFO    Starting theta 700 / 1017
03.07.2018 07:31:11 INFO    Starting theta 800 / 1017
03.07.2018 08:45:40 INFO    Starting theta 900 / 1017
03.07.2018 10:00:09 INFO    Starting theta 1000 / 1017
03.07.2018 10:13:34 INFO    Calibrated evaluation timing: median 1.06888794899 s, mean 1.07247834993 s
03.07.2018 10:13:34 INFO    Interpolating calibrated roaming
03.07.2018 10:18:07 INFO    That's it -- have a great day!
