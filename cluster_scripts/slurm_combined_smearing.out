Using TensorFlow backend.
07.02.2018 12:38:32 INFO    Hi! How are you today?
07.02.2018 12:38:32 INFO    Startup options:
07.02.2018 12:38:32 INFO      Algorithm:                     combined
07.02.2018 12:38:32 INFO      Point by point:                False
07.02.2018 12:38:32 INFO      Morphing-aware mode:           False
07.02.2018 12:38:32 INFO      Smeared data:                  True
07.02.2018 12:38:32 INFO      Training sample:               baseline
07.02.2018 12:38:32 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
07.02.2018 12:38:32 INFO      Neyman construction toys:      False
07.02.2018 12:38:32 INFO      Other options:                 
07.02.2018 12:38:32 INFO      Base directory:                /home/jb6504/higgs_inference
07.02.2018 12:38:32 INFO      ML-based strategies available: True
07.02.2018 12:38:32 INFO    Starting parameterized inference
07.02.2018 12:38:32 INFO    Main settings:
07.02.2018 12:38:32 INFO      Algorithm:                combined
07.02.2018 12:38:32 INFO      Morphing-aware:           False
07.02.2018 12:38:32 INFO      Training sample:          baseline
07.02.2018 12:38:32 INFO    Options:
07.02.2018 12:38:32 INFO      Number of epochs:         20
07.02.2018 12:38:32 INFO      Number of hidden layers:  2
07.02.2018 12:38:32 INFO      alpha carl:               0.35
07.02.2018 12:38:32 INFO      alpha regression:         0.011
07.02.2018 12:38:32 INFO      Debug mode:               False
07.02.2018 12:39:01 INFO    Starting training
Train on 7995920 samples, validate on 1998980 samples
Epoch 1/20
2018-02-07 12:39:02.157963: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 12:39:02.158289: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 12:39:02.158297: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 12:39:02.158302: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 12:39:02.158306: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-07 12:39:02.460838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-07 12:39:02.460873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-07 12:39:02.460879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-07 12:39:02.460887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0)
1615s - loss: 1.1852 - loss_function_ratio_regression: 0.0943 - loss_function_carl: 0.6652 - loss_function_carl_kl: 10.7027 - loss_function_score: 1.4857 - val_loss: 0.7482 - val_loss_function_ratio_regression: 0.0496 - val_loss_function_carl: 0.6615 - val_loss_function_carl_kl: 10.5595 - val_loss_function_score: 0.2477
Epoch 2/20
1614s - loss: 1.1168 - loss_function_ratio_regression: 0.0737 - loss_function_carl: 0.6639 - loss_function_carl_kl: 10.6842 - loss_function_score: 1.2941 - val_loss: 0.7499 - val_loss_function_ratio_regression: 0.0809 - val_loss_function_carl: 0.6657 - val_loss_function_carl_kl: 11.9798 - val_loss_function_score: 0.2405
Epoch 3/20
1614s - loss: 1.1062 - loss_function_ratio_regression: 0.0728 - loss_function_carl: 0.6638 - loss_function_carl_kl: 10.6814 - loss_function_score: 1.2640 - val_loss: 0.7473 - val_loss_function_ratio_regression: 0.0663 - val_loss_function_carl: 0.6636 - val_loss_function_carl_kl: 11.4086 - val_loss_function_score: 0.2392
Epoch 4/20
1614s - loss: 1.1036 - loss_function_ratio_regression: 0.0723 - loss_function_carl: 0.6638 - loss_function_carl_kl: 10.6836 - loss_function_score: 1.2567 - val_loss: 0.7509 - val_loss_function_ratio_regression: 0.0783 - val_loss_function_carl: 0.6651 - val_loss_function_carl_kl: 11.7815 - val_loss_function_score: 0.2451
Epoch 5/20
1583s - loss: 1.1026 - loss_function_ratio_regression: 0.0728 - loss_function_carl: 0.6639 - loss_function_carl_kl: 10.6789 - loss_function_score: 1.2534 - val_loss: 0.7496 - val_loss_function_ratio_regression: 0.0653 - val_loss_function_carl: 0.6633 - val_loss_function_carl_kl: 9.4058 - val_loss_function_score: 0.2464
Epoch 6/20
1533s - loss: 1.1067 - loss_function_ratio_regression: 0.0730 - loss_function_carl: 0.6639 - loss_function_carl_kl: 10.6842 - loss_function_score: 1.2653 - val_loss: 0.7459 - val_loss_function_ratio_regression: 0.0549 - val_loss_function_carl: 0.6625 - val_loss_function_carl_kl: 10.0711 - val_loss_function_score: 0.2383
Epoch 7/20
1551s - loss: 1.1053 - loss_function_ratio_regression: 0.0732 - loss_function_carl: 0.6639 - loss_function_carl_kl: 10.6754 - loss_function_score: 1.2611 - val_loss: 0.7485 - val_loss_function_ratio_regression: 0.0484 - val_loss_function_carl: 0.6615 - val_loss_function_carl_kl: 10.8729 - val_loss_function_score: 0.2485
Epoch 8/20
1539s - loss: 1.1023 - loss_function_ratio_regression: 0.0742 - loss_function_carl: 0.6640 - loss_function_carl_kl: 10.6925 - loss_function_score: 1.2523 - val_loss: 0.7485 - val_loss_function_ratio_regression: 0.0433 - val_loss_function_carl: 0.6611 - val_loss_function_carl_kl: 10.5724 - val_loss_function_score: 0.2497
Epoch 9/20
1536s - loss: 1.0987 - loss_function_ratio_regression: 0.0741 - loss_function_carl: 0.6639 - loss_function_carl_kl: 10.6917 - loss_function_score: 1.2421 - val_loss: 0.7600 - val_loss_function_ratio_regression: 0.1264 - val_loss_function_carl: 0.6707 - val_loss_function_carl_kl: 8.5702 - val_loss_function_score: 0.2549
Epoch 10/20
1536s - loss: 1.1003 - loss_function_ratio_regression: 0.0742 - loss_function_carl: 0.6640 - loss_function_carl_kl: 10.6903 - loss_function_score: 1.2466 - val_loss: 0.7516 - val_loss_function_ratio_regression: 0.1107 - val_loss_function_carl: 0.6689 - val_loss_function_carl_kl: 12.5064 - val_loss_function_score: 0.2361
Epoch 11/20
1535s - loss: 1.0997 - loss_function_ratio_regression: 0.0749 - loss_function_carl: 0.6640 - loss_function_carl_kl: 10.6869 - loss_function_score: 1.2449 - val_loss: 0.7460 - val_loss_function_ratio_regression: 0.0438 - val_loss_function_carl: 0.6614 - val_loss_function_carl_kl: 10.5130 - val_loss_function_score: 0.2417
Epoch 12/20
1535s - loss: 1.1017 - loss_function_ratio_regression: 0.0748 - loss_function_carl: 0.6641 - loss_function_carl_kl: 10.6861 - loss_function_score: 1.2503 - val_loss: 0.7508 - val_loss_function_ratio_regression: 0.0769 - val_loss_function_carl: 0.6651 - val_loss_function_carl_kl: 9.2362 - val_loss_function_score: 0.2449
Epoch 00011: early stopping
07.02.2018 17:52:35 INFO    Starting evaluation
07.02.2018 18:14:11 INFO    Starting roaming
07.02.2018 18:14:17 INFO    Starting calibrated evaluation and roaming
07.02.2018 21:32:23 INFO    Interpolating calibrated roaming
07.02.2018 21:33:50 INFO    That's it -- have a great day!
