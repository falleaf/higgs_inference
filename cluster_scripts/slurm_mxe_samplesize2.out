Using TensorFlow backend.
02.07.2018 08:11:39 INFO    Hi! How are you today?
02.07.2018 08:11:39 INFO    Startup options:
02.07.2018 08:11:39 INFO      Algorithm:                     mxe
02.07.2018 08:11:39 INFO      Point by point:                False
02.07.2018 08:11:39 INFO      Morphing-aware mode:           False
02.07.2018 08:11:39 INFO      Smeared data:                  False
02.07.2018 08:11:39 INFO      Training sample:               baseline
02.07.2018 08:11:39 INFO      alpha:                         None
02.07.2018 08:11:39 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
02.07.2018 08:11:39 INFO      AFC epsilon:                   None
02.07.2018 08:11:39 INFO      Denominator theta:             False
02.07.2018 08:11:39 INFO      Neyman construction toys:      0
02.07.2018 08:11:39 INFO      Training sample size limit:    2000000
02.07.2018 08:11:39 INFO      Other options:                 ['deep']
02.07.2018 08:11:39 INFO      Base directory:                /home/jb6504/higgs_inference
02.07.2018 08:11:39 INFO      ML-based strategies available: True
02.07.2018 08:11:39 INFO    Starting parameterized inference
02.07.2018 08:11:39 INFO    Main settings:
02.07.2018 08:11:39 INFO      Algorithm:                mxe
02.07.2018 08:11:39 INFO      Morphing-aware:           False
02.07.2018 08:11:39 INFO      Training sample:          baseline
02.07.2018 08:11:39 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
02.07.2018 08:11:39 INFO    Options:
02.07.2018 08:11:39 INFO      Number of hidden layers:  5
02.07.2018 08:11:39 INFO      Batch size:               128
02.07.2018 08:11:39 INFO      Learning rate:            0.001
02.07.2018 08:11:39 INFO      Learning rate decay:      0.018420680744
02.07.2018 08:11:39 INFO      Number of epochs:         250
02.07.2018 08:11:39 INFO      Training samples:         2000000
02.07.2018 08:11:39 INFO      NC experiments:           False
02.07.2018 08:11:39 INFO      Debug mode:               False
02.07.2018 08:11:48 INFO    Reduced training sample size from 9999997 to 2000000 (factor 5)
02.07.2018 08:12:07 INFO    Starting training
2018-07-02 08:12:08.515004: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:12:08.515043: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:12:08.515048: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:12:08.515052: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:12:08.515056: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-02 08:12:08.732686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:85:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-02 08:12:08.732727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-02 08:12:08.732733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-02 08:12:08.732742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:85:00.0)
02.07.2018 15:10:38 INFO    Starting evaluation
02.07.2018 15:12:36 INFO    Starting theta 100 / 1017
02.07.2018 15:14:30 INFO    Starting theta 200 / 1017
02.07.2018 15:16:24 INFO    Starting theta 300 / 1017
02.07.2018 15:18:19 INFO    Starting theta 400 / 1017
02.07.2018 15:20:13 INFO    Starting theta 500 / 1017
02.07.2018 15:22:08 INFO    Starting theta 600 / 1017
02.07.2018 15:24:02 INFO    Starting theta 700 / 1017
02.07.2018 15:25:57 INFO    Starting theta 800 / 1017
02.07.2018 15:27:51 INFO    Starting theta 900 / 1017
02.07.2018 15:29:46 INFO    Starting theta 1000 / 1017
02.07.2018 15:30:06 INFO    Evaluation timing: median 1.13353300095 s, mean 1.13380900198 s
02.07.2018 15:30:06 INFO    Starting roaming
02.07.2018 15:30:30 INFO    Starting calibrated evaluation and roaming
02.07.2018 16:46:26 INFO    Starting theta 100 / 1017
02.07.2018 18:02:08 INFO    Starting theta 200 / 1017
02.07.2018 19:17:57 INFO    Starting theta 300 / 1017
02.07.2018 20:33:33 INFO    Starting theta 400 / 1017
02.07.2018 21:48:11 INFO    Starting theta 500 / 1017
02.07.2018 23:03:50 INFO    Starting theta 600 / 1017
03.07.2018 00:19:27 INFO    Starting theta 700 / 1017
03.07.2018 01:35:06 INFO    Starting theta 800 / 1017
03.07.2018 02:50:25 INFO    Starting theta 900 / 1017
03.07.2018 04:05:30 INFO    Starting theta 1000 / 1017
03.07.2018 04:18:58 INFO    Calibrated evaluation timing: median 1.07577800751 s, mean 1.07759830734 s
03.07.2018 04:18:58 INFO    Interpolating calibrated roaming
03.07.2018 04:24:11 INFO    That's it -- have a great day!
Using TensorFlow backend.
03.07.2018 04:24:14 INFO    Hi! How are you today?
03.07.2018 04:24:14 INFO    Startup options:
03.07.2018 04:24:14 INFO      Algorithm:                     mxe
03.07.2018 04:24:14 INFO      Point by point:                False
03.07.2018 04:24:14 INFO      Morphing-aware mode:           False
03.07.2018 04:24:14 INFO      Smeared data:                  False
03.07.2018 04:24:14 INFO      Training sample:               baseline
03.07.2018 04:24:14 INFO      alpha:                         None
03.07.2018 04:24:14 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
03.07.2018 04:24:14 INFO      AFC epsilon:                   None
03.07.2018 04:24:14 INFO      Denominator theta:             False
03.07.2018 04:24:14 INFO      Neyman construction toys:      0
03.07.2018 04:24:14 INFO      Training sample size limit:    5000000
03.07.2018 04:24:14 INFO      Other options:                 ['deep']
03.07.2018 04:24:14 INFO      Base directory:                /home/jb6504/higgs_inference
03.07.2018 04:24:14 INFO      ML-based strategies available: True
03.07.2018 04:24:14 INFO    Starting parameterized inference
03.07.2018 04:24:14 INFO    Main settings:
03.07.2018 04:24:14 INFO      Algorithm:                mxe
03.07.2018 04:24:14 INFO      Morphing-aware:           False
03.07.2018 04:24:14 INFO      Training sample:          baseline
03.07.2018 04:24:14 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
03.07.2018 04:24:14 INFO    Options:
03.07.2018 04:24:14 INFO      Number of hidden layers:  5
03.07.2018 04:24:14 INFO      Batch size:               128
03.07.2018 04:24:14 INFO      Learning rate:            0.001
03.07.2018 04:24:14 INFO      Learning rate decay:      0.0460517018599
03.07.2018 04:24:14 INFO      Number of epochs:         100
03.07.2018 04:24:14 INFO      Training samples:         5000000
03.07.2018 04:24:14 INFO      NC experiments:           False
03.07.2018 04:24:14 INFO      Debug mode:               False
03.07.2018 04:24:34 INFO    Reduced training sample size from 9999997 to 5000000 (factor 2)
03.07.2018 04:24:59 INFO    Starting training
2018-07-03 04:25:00.145354: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 04:25:00.145393: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 04:25:00.145398: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 04:25:00.145407: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 04:25:00.145411: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-03 04:25:00.375754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:85:00.0
Total memory: 22.38GiB
Free memory: 22.22GiB
2018-07-03 04:25:00.375792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-07-03 04:25:00.375798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-07-03 04:25:00.375807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:85:00.0)
03.07.2018 10:57:13 INFO    Starting evaluation
03.07.2018 10:59:05 INFO    Starting theta 100 / 1017
03.07.2018 11:00:54 INFO    Starting theta 200 / 1017
03.07.2018 11:02:42 INFO    Starting theta 300 / 1017
03.07.2018 11:04:31 INFO    Starting theta 400 / 1017
03.07.2018 11:06:19 INFO    Starting theta 500 / 1017
03.07.2018 11:08:08 INFO    Starting theta 600 / 1017
03.07.2018 11:09:57 INFO    Starting theta 700 / 1017
03.07.2018 11:11:45 INFO    Starting theta 800 / 1017
03.07.2018 11:13:33 INFO    Starting theta 900 / 1017
03.07.2018 11:15:22 INFO    Starting theta 1000 / 1017
03.07.2018 11:15:41 INFO    Evaluation timing: median 1.07198786736 s, mean 1.07523328927 s
03.07.2018 11:15:41 INFO    Starting roaming
03.07.2018 11:16:04 INFO    Starting calibrated evaluation and roaming
03.07.2018 12:31:03 INFO    Starting theta 100 / 1017
03.07.2018 13:46:29 INFO    Starting theta 200 / 1017
03.07.2018 15:02:16 INFO    Starting theta 300 / 1017
03.07.2018 16:17:53 INFO    Starting theta 400 / 1017
03.07.2018 17:33:32 INFO    Starting theta 500 / 1017
03.07.2018 18:49:14 INFO    Starting theta 600 / 1017
03.07.2018 20:04:57 INFO    Starting theta 700 / 1017
03.07.2018 21:20:41 INFO    Starting theta 800 / 1017
03.07.2018 22:36:23 INFO    Starting theta 900 / 1017
03.07.2018 23:52:06 INFO    Starting theta 1000 / 1017
04.07.2018 00:05:43 INFO    Calibrated evaluation timing: median 1.0761089325 s, mean 1.07823469435 s
04.07.2018 00:05:43 INFO    Interpolating calibrated roaming
04.07.2018 00:10:42 INFO    That's it -- have a great day!
