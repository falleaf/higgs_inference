Using TensorFlow backend.
19.04.2018 10:34:04 INFO    Hi! How are you today?
19.04.2018 10:34:04 INFO    Startup options:
19.04.2018 10:34:04 INFO      Algorithm:                     combined
19.04.2018 10:34:04 INFO      Point by point:                False
19.04.2018 10:34:04 INFO      Morphing-aware mode:           False
19.04.2018 10:34:04 INFO      Smeared data:                  False
19.04.2018 10:34:04 INFO      Training sample:               baseline
19.04.2018 10:34:04 INFO      alpha:                         None
19.04.2018 10:34:04 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
19.04.2018 10:34:04 INFO      AFC epsilon:                   None
19.04.2018 10:34:04 INFO      Denominator theta:             False
19.04.2018 10:34:04 INFO      Neyman construction toys:      0
19.04.2018 10:34:04 INFO      Training sample size limit:    5000
19.04.2018 10:34:04 INFO      Other options:                 ['deep']
19.04.2018 10:34:04 INFO      Base directory:                /home/jb6504/higgs_inference
19.04.2018 10:34:04 INFO      ML-based strategies available: True
19.04.2018 10:34:04 INFO    Starting parameterized inference
19.04.2018 10:34:04 INFO    Main settings:
19.04.2018 10:34:04 INFO      Algorithm:                combined
19.04.2018 10:34:04 INFO      Morphing-aware:           False
19.04.2018 10:34:04 INFO      Training sample:          baseline
19.04.2018 10:34:04 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
19.04.2018 10:34:04 INFO    Options:
19.04.2018 10:34:04 INFO      Number of hidden layers:  5
19.04.2018 10:34:04 INFO      alpha:                    5.0
19.04.2018 10:34:04 INFO      Batch size:               128
19.04.2018 10:34:04 INFO      Learning rate:            0.001
19.04.2018 10:34:04 INFO      Learning rate decay:      4.60517018599e-05
19.04.2018 10:34:04 INFO      Number of epochs:         100000
19.04.2018 10:34:04 INFO      Training samples:         5000
19.04.2018 10:34:04 INFO      NC experiments:           False
19.04.2018 10:34:04 INFO      Debug mode:               False
19.04.2018 10:34:27 INFO    Reduced training sample size from 9999997 to 5000 (factor 2000)
19.04.2018 10:34:41 INFO    Starting training
2018-04-19 10:34:42.133298: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.133331: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.133335: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.133339: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.133343: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.437590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-19 10:34:42.437626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-19 10:34:42.437631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-19 10:34:42.437640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 20028: early stopping
19.04.2018 12:03:17 INFO    Starting evaluation
19.04.2018 12:05:08 INFO    Starting theta 100 / 1017
19.04.2018 12:06:56 INFO    Starting theta 200 / 1017
19.04.2018 12:08:44 INFO    Starting theta 300 / 1017
19.04.2018 12:10:31 INFO    Starting theta 400 / 1017
19.04.2018 12:12:19 INFO    Starting theta 500 / 1017
19.04.2018 12:14:07 INFO    Starting theta 600 / 1017
19.04.2018 12:15:55 INFO    Starting theta 700 / 1017
19.04.2018 12:17:42 INFO    Starting theta 800 / 1017
19.04.2018 12:19:30 INFO    Starting theta 900 / 1017
19.04.2018 12:21:17 INFO    Starting theta 1000 / 1017
19.04.2018 12:21:37 INFO    Evaluation timing: median 1.0616312027 s, mean 1.06738396029 s
19.04.2018 12:21:37 INFO    Starting roaming
19.04.2018 12:21:59 INFO    Starting calibrated evaluation and roaming
19.04.2018 13:36:31 INFO    Starting theta 100 / 1017
19.04.2018 14:52:37 INFO    Starting theta 200 / 1017
19.04.2018 16:10:15 INFO    Starting theta 300 / 1017
19.04.2018 17:26:15 INFO    Starting theta 400 / 1017
19.04.2018 18:43:16 INFO    Starting theta 500 / 1017
19.04.2018 20:01:37 INFO    Starting theta 600 / 1017
19.04.2018 21:19:57 INFO    Starting theta 700 / 1017
19.04.2018 22:38:17 INFO    Starting theta 800 / 1017
19.04.2018 23:56:40 INFO    Starting theta 900 / 1017
20.04.2018 01:15:01 INFO    Starting theta 1000 / 1017
20.04.2018 01:29:07 INFO    Calibrated evaluation timing: median 1.11297512054 s, mean 1.10199821312 s
20.04.2018 01:29:07 INFO    Interpolating calibrated roaming
20.04.2018 01:34:02 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 01:34:05 INFO    Hi! How are you today?
20.04.2018 01:34:05 INFO    Startup options:
20.04.2018 01:34:05 INFO      Algorithm:                     combined
20.04.2018 01:34:05 INFO      Point by point:                False
20.04.2018 01:34:05 INFO      Morphing-aware mode:           False
20.04.2018 01:34:05 INFO      Smeared data:                  False
20.04.2018 01:34:05 INFO      Training sample:               baseline
20.04.2018 01:34:05 INFO      alpha:                         None
20.04.2018 01:34:05 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 01:34:05 INFO      AFC epsilon:                   None
20.04.2018 01:34:05 INFO      Denominator theta:             False
20.04.2018 01:34:05 INFO      Neyman construction toys:      0
20.04.2018 01:34:05 INFO      Training sample size limit:    10000
20.04.2018 01:34:05 INFO      Other options:                 ['deep']
20.04.2018 01:34:05 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 01:34:05 INFO      ML-based strategies available: True
20.04.2018 01:34:05 INFO    Starting parameterized inference
20.04.2018 01:34:05 INFO    Main settings:
20.04.2018 01:34:05 INFO      Algorithm:                combined
20.04.2018 01:34:05 INFO      Morphing-aware:           False
20.04.2018 01:34:05 INFO      Training sample:          baseline
20.04.2018 01:34:05 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 01:34:05 INFO    Options:
20.04.2018 01:34:05 INFO      Number of hidden layers:  5
20.04.2018 01:34:05 INFO      alpha:                    5.0
20.04.2018 01:34:05 INFO      Batch size:               128
20.04.2018 01:34:05 INFO      Learning rate:            0.001
20.04.2018 01:34:05 INFO      Learning rate decay:      9.21034037198e-05
20.04.2018 01:34:05 INFO      Number of epochs:         50000
20.04.2018 01:34:05 INFO      Training samples:         10000
20.04.2018 01:34:05 INFO      NC experiments:           False
20.04.2018 01:34:05 INFO      Debug mode:               False
20.04.2018 01:34:27 INFO    Reduced training sample size from 9999997 to 10000 (factor 1000)
20.04.2018 01:34:42 INFO    Starting training
2018-04-20 01:34:42.882087: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 01:34:42.882120: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 01:34:42.882129: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 01:34:42.882133: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 01:34:42.882137: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 01:34:43.188253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-20 01:34:43.188289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 01:34:43.188295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 01:34:43.188304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 10035: early stopping
20.04.2018 03:06:20 INFO    Starting evaluation
20.04.2018 03:08:17 INFO    Starting theta 100 / 1017
20.04.2018 03:10:10 INFO    Starting theta 200 / 1017
20.04.2018 03:12:03 INFO    Starting theta 300 / 1017
20.04.2018 03:13:57 INFO    Starting theta 400 / 1017
20.04.2018 03:15:50 INFO    Starting theta 500 / 1017
20.04.2018 03:17:44 INFO    Starting theta 600 / 1017
20.04.2018 03:19:37 INFO    Starting theta 700 / 1017
20.04.2018 03:21:31 INFO    Starting theta 800 / 1017
20.04.2018 03:23:24 INFO    Starting theta 900 / 1017
20.04.2018 03:25:17 INFO    Starting theta 1000 / 1017
20.04.2018 03:25:38 INFO    Evaluation timing: median 1.12006902695 s, mean 1.12320107087 s
20.04.2018 03:25:38 INFO    Starting roaming
20.04.2018 03:26:01 INFO    Starting calibrated evaluation and roaming
20.04.2018 04:44:26 INFO    Starting theta 100 / 1017
20.04.2018 06:03:30 INFO    Starting theta 200 / 1017
20.04.2018 07:22:38 INFO    Starting theta 300 / 1017
20.04.2018 08:41:41 INFO    Starting theta 400 / 1017
20.04.2018 10:00:44 INFO    Starting theta 500 / 1017
20.04.2018 11:19:44 INFO    Starting theta 600 / 1017
20.04.2018 12:38:45 INFO    Starting theta 700 / 1017
20.04.2018 13:57:49 INFO    Starting theta 800 / 1017
20.04.2018 15:17:03 INFO    Starting theta 900 / 1017
20.04.2018 16:36:21 INFO    Starting theta 1000 / 1017
20.04.2018 16:50:37 INFO    Calibrated evaluation timing: median 1.12468194962 s, mean 1.12669650362 s
20.04.2018 16:50:37 INFO    Interpolating calibrated roaming
20.04.2018 16:56:12 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 16:56:15 INFO    Hi! How are you today?
20.04.2018 16:56:15 INFO    Startup options:
20.04.2018 16:56:15 INFO      Algorithm:                     combined
20.04.2018 16:56:15 INFO      Point by point:                False
20.04.2018 16:56:15 INFO      Morphing-aware mode:           False
20.04.2018 16:56:15 INFO      Smeared data:                  False
20.04.2018 16:56:15 INFO      Training sample:               baseline
20.04.2018 16:56:15 INFO      alpha:                         None
20.04.2018 16:56:15 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 16:56:15 INFO      AFC epsilon:                   None
20.04.2018 16:56:15 INFO      Denominator theta:             False
20.04.2018 16:56:15 INFO      Neyman construction toys:      0
20.04.2018 16:56:15 INFO      Training sample size limit:    20000
20.04.2018 16:56:15 INFO      Other options:                 ['deep']
20.04.2018 16:56:15 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 16:56:15 INFO      ML-based strategies available: True
20.04.2018 16:56:15 INFO    Starting parameterized inference
20.04.2018 16:56:15 INFO    Main settings:
20.04.2018 16:56:15 INFO      Algorithm:                combined
20.04.2018 16:56:15 INFO      Morphing-aware:           False
20.04.2018 16:56:15 INFO      Training sample:          baseline
20.04.2018 16:56:15 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 16:56:15 INFO    Options:
20.04.2018 16:56:15 INFO      Number of hidden layers:  5
20.04.2018 16:56:15 INFO      alpha:                    5.0
20.04.2018 16:56:15 INFO      Batch size:               128
20.04.2018 16:56:15 INFO      Learning rate:            0.001
20.04.2018 16:56:15 INFO      Learning rate decay:      0.00018420680744
20.04.2018 16:56:15 INFO      Number of epochs:         25000
20.04.2018 16:56:15 INFO      Training samples:         20000
20.04.2018 16:56:15 INFO      NC experiments:           False
20.04.2018 16:56:15 INFO      Debug mode:               False
20.04.2018 16:56:37 INFO    Reduced training sample size from 9999997 to 20000 (factor 500)
20.04.2018 16:56:51 INFO    Starting training
2018-04-20 16:56:52.303893: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 16:56:52.303926: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 16:56:52.303932: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 16:56:52.303945: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 16:56:52.303949: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 16:56:52.607801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-20 16:56:52.607838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 16:56:52.607844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 16:56:52.607852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 05021: early stopping
20.04.2018 18:28:06 INFO    Starting evaluation
20.04.2018 18:30:01 INFO    Starting theta 100 / 1017
20.04.2018 18:31:53 INFO    Starting theta 200 / 1017
20.04.2018 18:33:44 INFO    Starting theta 300 / 1017
20.04.2018 18:35:35 INFO    Starting theta 400 / 1017
20.04.2018 18:37:27 INFO    Starting theta 500 / 1017
20.04.2018 18:39:18 INFO    Starting theta 600 / 1017
20.04.2018 18:41:10 INFO    Starting theta 700 / 1017
20.04.2018 18:43:01 INFO    Starting theta 800 / 1017
20.04.2018 18:44:53 INFO    Starting theta 900 / 1017
20.04.2018 18:46:44 INFO    Starting theta 1000 / 1017
20.04.2018 18:47:04 INFO    Evaluation timing: median 1.10114383698 s, mean 1.10434856035 s
20.04.2018 18:47:04 INFO    Starting roaming
20.04.2018 18:47:27 INFO    Starting calibrated evaluation and roaming
20.04.2018 20:06:25 INFO    Starting theta 100 / 1017
20.04.2018 21:27:44 INFO    Starting theta 200 / 1017
20.04.2018 22:46:59 INFO    Starting theta 300 / 1017
21.04.2018 00:05:18 INFO    Starting theta 400 / 1017
21.04.2018 01:22:30 INFO    Starting theta 500 / 1017
21.04.2018 02:39:49 INFO    Starting theta 600 / 1017
21.04.2018 03:57:18 INFO    Starting theta 700 / 1017
21.04.2018 05:13:46 INFO    Starting theta 800 / 1017
21.04.2018 06:30:13 INFO    Starting theta 900 / 1017
21.04.2018 07:46:41 INFO    Starting theta 1000 / 1017
21.04.2018 08:00:27 INFO    Calibrated evaluation timing: median 1.09734678268 s, mean 1.1038009328 s
21.04.2018 08:00:27 INFO    Interpolating calibrated roaming
21.04.2018 08:05:33 INFO    That's it -- have a great day!
Using TensorFlow backend.
21.04.2018 08:05:37 INFO    Hi! How are you today?
21.04.2018 08:05:37 INFO    Startup options:
21.04.2018 08:05:37 INFO      Algorithm:                     combined
21.04.2018 08:05:37 INFO      Point by point:                False
21.04.2018 08:05:37 INFO      Morphing-aware mode:           False
21.04.2018 08:05:37 INFO      Smeared data:                  False
21.04.2018 08:05:37 INFO      Training sample:               baseline
21.04.2018 08:05:37 INFO      alpha:                         None
21.04.2018 08:05:37 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
21.04.2018 08:05:37 INFO      AFC epsilon:                   None
21.04.2018 08:05:37 INFO      Denominator theta:             False
21.04.2018 08:05:37 INFO      Neyman construction toys:      0
21.04.2018 08:05:37 INFO      Training sample size limit:    50000
21.04.2018 08:05:37 INFO      Other options:                 ['deep']
21.04.2018 08:05:37 INFO      Base directory:                /home/jb6504/higgs_inference
21.04.2018 08:05:37 INFO      ML-based strategies available: True
21.04.2018 08:05:37 INFO    Starting parameterized inference
21.04.2018 08:05:37 INFO    Main settings:
21.04.2018 08:05:37 INFO      Algorithm:                combined
21.04.2018 08:05:37 INFO      Morphing-aware:           False
21.04.2018 08:05:37 INFO      Training sample:          baseline
21.04.2018 08:05:37 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
21.04.2018 08:05:37 INFO    Options:
21.04.2018 08:05:37 INFO      Number of hidden layers:  5
21.04.2018 08:05:37 INFO      alpha:                    5.0
21.04.2018 08:05:37 INFO      Batch size:               128
21.04.2018 08:05:37 INFO      Learning rate:            0.001
21.04.2018 08:05:37 INFO      Learning rate decay:      0.000460517018599
21.04.2018 08:05:37 INFO      Number of epochs:         10000
21.04.2018 08:05:37 INFO      Training samples:         50000
21.04.2018 08:05:37 INFO      NC experiments:           False
21.04.2018 08:05:37 INFO      Debug mode:               False
21.04.2018 08:05:57 INFO    Reduced training sample size from 9999997 to 50000 (factor 200)
21.04.2018 08:06:11 INFO    Starting training
2018-04-21 08:06:12.038055: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 08:06:12.038088: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 08:06:12.038093: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 08:06:12.038097: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 08:06:12.038101: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 08:06:12.369835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-21 08:06:12.369870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-21 08:06:12.369876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-21 08:06:12.369884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 02042: early stopping
21.04.2018 09:33:56 INFO    Starting evaluation
21.04.2018 09:35:48 INFO    Starting theta 100 / 1017
21.04.2018 09:37:35 INFO    Starting theta 200 / 1017
21.04.2018 09:39:22 INFO    Starting theta 300 / 1017
21.04.2018 09:41:09 INFO    Starting theta 400 / 1017
21.04.2018 09:42:56 INFO    Starting theta 500 / 1017
21.04.2018 09:44:43 INFO    Starting theta 600 / 1017
21.04.2018 09:46:30 INFO    Starting theta 700 / 1017
21.04.2018 09:48:17 INFO    Starting theta 800 / 1017
21.04.2018 09:50:04 INFO    Starting theta 900 / 1017
21.04.2018 09:51:53 INFO    Starting theta 1000 / 1017
21.04.2018 09:52:12 INFO    Evaluation timing: median 1.05888199806 s, mean 1.06453768717 s
21.04.2018 09:52:12 INFO    Starting roaming
21.04.2018 09:52:34 INFO    Starting calibrated evaluation and roaming
21.04.2018 11:07:00 INFO    Starting theta 100 / 1017
21.04.2018 12:25:03 INFO    Starting theta 200 / 1017
21.04.2018 13:43:00 INFO    Starting theta 300 / 1017
21.04.2018 15:01:02 INFO    Starting theta 400 / 1017
21.04.2018 16:19:05 INFO    Starting theta 500 / 1017
21.04.2018 17:37:06 INFO    Starting theta 600 / 1017
21.04.2018 18:55:13 INFO    Starting theta 700 / 1017
21.04.2018 20:13:23 INFO    Starting theta 800 / 1017
21.04.2018 21:31:29 INFO    Starting theta 900 / 1017
21.04.2018 22:49:21 INFO    Starting theta 1000 / 1017
21.04.2018 23:02:50 INFO    Calibrated evaluation timing: median 1.10936307907 s, mean 1.10753724756 s
21.04.2018 23:02:50 INFO    Interpolating calibrated roaming
21.04.2018 23:06:56 INFO    That's it -- have a great day!
Using TensorFlow backend.
21.04.2018 23:06:59 INFO    Hi! How are you today?
21.04.2018 23:06:59 INFO    Startup options:
21.04.2018 23:06:59 INFO      Algorithm:                     combined
21.04.2018 23:06:59 INFO      Point by point:                False
21.04.2018 23:06:59 INFO      Morphing-aware mode:           False
21.04.2018 23:06:59 INFO      Smeared data:                  False
21.04.2018 23:06:59 INFO      Training sample:               baseline
21.04.2018 23:06:59 INFO      alpha:                         None
21.04.2018 23:06:59 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
21.04.2018 23:06:59 INFO      AFC epsilon:                   None
21.04.2018 23:06:59 INFO      Denominator theta:             False
21.04.2018 23:06:59 INFO      Neyman construction toys:      0
21.04.2018 23:06:59 INFO      Training sample size limit:    100000
21.04.2018 23:06:59 INFO      Other options:                 ['deep']
21.04.2018 23:06:59 INFO      Base directory:                /home/jb6504/higgs_inference
21.04.2018 23:06:59 INFO      ML-based strategies available: True
21.04.2018 23:06:59 INFO    Starting parameterized inference
21.04.2018 23:06:59 INFO    Main settings:
21.04.2018 23:06:59 INFO      Algorithm:                combined
21.04.2018 23:06:59 INFO      Morphing-aware:           False
21.04.2018 23:06:59 INFO      Training sample:          baseline
21.04.2018 23:06:59 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
21.04.2018 23:06:59 INFO    Options:
21.04.2018 23:06:59 INFO      Number of hidden layers:  5
21.04.2018 23:06:59 INFO      alpha:                    5.0
21.04.2018 23:06:59 INFO      Batch size:               128
21.04.2018 23:06:59 INFO      Learning rate:            0.001
21.04.2018 23:06:59 INFO      Learning rate decay:      0.000921034037198
21.04.2018 23:06:59 INFO      Number of epochs:         5000
21.04.2018 23:06:59 INFO      Training samples:         100000
21.04.2018 23:06:59 INFO      NC experiments:           False
21.04.2018 23:06:59 INFO      Debug mode:               False
21.04.2018 23:07:26 INFO    Reduced training sample size from 9999997 to 100000 (factor 100)
21.04.2018 23:07:40 INFO    Starting training
2018-04-21 23:07:41.009950: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 23:07:41.009985: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 23:07:41.009990: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 23:07:41.009993: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 23:07:41.009997: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 23:07:41.312651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-21 23:07:41.312687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-21 23:07:41.312692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-21 23:07:41.312700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 01224: early stopping
22.04.2018 00:51:26 INFO    Starting evaluation
22.04.2018 00:53:19 INFO    Starting theta 100 / 1017
22.04.2018 00:55:08 INFO    Starting theta 200 / 1017
22.04.2018 00:56:58 INFO    Starting theta 300 / 1017
22.04.2018 00:58:47 INFO    Starting theta 400 / 1017
22.04.2018 01:00:37 INFO    Starting theta 500 / 1017
22.04.2018 01:02:27 INFO    Starting theta 600 / 1017
22.04.2018 01:04:16 INFO    Starting theta 700 / 1017
22.04.2018 01:06:05 INFO    Starting theta 800 / 1017
22.04.2018 01:07:53 INFO    Starting theta 900 / 1017
22.04.2018 01:09:43 INFO    Starting theta 1000 / 1017
22.04.2018 01:10:02 INFO    Evaluation timing: median 1.07440495491 s, mean 1.08261510569 s
22.04.2018 01:10:02 INFO    Starting roaming
22.04.2018 01:10:25 INFO    Starting calibrated evaluation and roaming
22.04.2018 02:25:30 INFO    Starting theta 100 / 1017
22.04.2018 03:41:03 INFO    Starting theta 200 / 1017
22.04.2018 04:57:13 INFO    Starting theta 300 / 1017
22.04.2018 06:13:19 INFO    Starting theta 400 / 1017
22.04.2018 07:28:29 INFO    Starting theta 500 / 1017
22.04.2018 08:43:06 INFO    Starting theta 600 / 1017
22.04.2018 09:58:51 INFO    Starting theta 700 / 1017
22.04.2018 11:14:41 INFO    Starting theta 800 / 1017
22.04.2018 12:30:39 INFO    Starting theta 900 / 1017
22.04.2018 13:48:45 INFO    Starting theta 1000 / 1017
22.04.2018 14:02:48 INFO    Calibrated evaluation timing: median 1.06805205345 s, mean 1.08089192497 s
22.04.2018 14:02:48 INFO    Interpolating calibrated roaming
22.04.2018 14:08:20 INFO    That's it -- have a great day!
Using TensorFlow backend.
22.04.2018 14:08:23 INFO    Hi! How are you today?
22.04.2018 14:08:23 INFO    Startup options:
22.04.2018 14:08:23 INFO      Algorithm:                     combined
22.04.2018 14:08:23 INFO      Point by point:                False
22.04.2018 14:08:23 INFO      Morphing-aware mode:           False
22.04.2018 14:08:23 INFO      Smeared data:                  False
22.04.2018 14:08:23 INFO      Training sample:               baseline
22.04.2018 14:08:23 INFO      alpha:                         None
22.04.2018 14:08:23 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
22.04.2018 14:08:23 INFO      AFC epsilon:                   None
22.04.2018 14:08:23 INFO      Denominator theta:             False
22.04.2018 14:08:23 INFO      Neyman construction toys:      0
22.04.2018 14:08:23 INFO      Training sample size limit:    200000
22.04.2018 14:08:23 INFO      Other options:                 ['deep']
22.04.2018 14:08:23 INFO      Base directory:                /home/jb6504/higgs_inference
22.04.2018 14:08:23 INFO      ML-based strategies available: True
22.04.2018 14:08:23 INFO    Starting parameterized inference
22.04.2018 14:08:23 INFO    Main settings:
22.04.2018 14:08:23 INFO      Algorithm:                combined
22.04.2018 14:08:23 INFO      Morphing-aware:           False
22.04.2018 14:08:23 INFO      Training sample:          baseline
22.04.2018 14:08:23 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
22.04.2018 14:08:23 INFO    Options:
22.04.2018 14:08:23 INFO      Number of hidden layers:  5
22.04.2018 14:08:23 INFO      alpha:                    5.0
22.04.2018 14:08:23 INFO      Batch size:               128
22.04.2018 14:08:23 INFO      Learning rate:            0.001
22.04.2018 14:08:23 INFO      Learning rate decay:      0.0018420680744
22.04.2018 14:08:23 INFO      Number of epochs:         2500
22.04.2018 14:08:23 INFO      Training samples:         200000
22.04.2018 14:08:23 INFO      NC experiments:           False
22.04.2018 14:08:23 INFO      Debug mode:               False
22.04.2018 14:08:44 INFO    Reduced training sample size from 9999997 to 200000 (factor 50)
22.04.2018 14:08:59 INFO    Starting training
2018-04-22 14:08:59.680299: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 14:08:59.680333: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 14:08:59.680338: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 14:08:59.680342: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 14:08:59.680346: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 14:08:59.992838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-22 14:08:59.992874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-22 14:08:59.992879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-22 14:08:59.992888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 00683: early stopping
22.04.2018 16:13:04 INFO    Starting evaluation
22.04.2018 16:15:01 INFO    Starting theta 100 / 1017
22.04.2018 16:16:55 INFO    Starting theta 200 / 1017
22.04.2018 16:18:48 INFO    Starting theta 300 / 1017
22.04.2018 16:20:41 INFO    Starting theta 400 / 1017
22.04.2018 16:22:34 INFO    Starting theta 500 / 1017
22.04.2018 16:24:28 INFO    Starting theta 600 / 1017
22.04.2018 16:26:21 INFO    Starting theta 700 / 1017
22.04.2018 16:28:15 INFO    Starting theta 800 / 1017
22.04.2018 16:30:08 INFO    Starting theta 900 / 1017
22.04.2018 16:32:01 INFO    Starting theta 1000 / 1017
22.04.2018 16:32:22 INFO    Evaluation timing: median 1.11789822578 s, mean 1.12308775031 s
22.04.2018 16:32:22 INFO    Starting roaming
22.04.2018 16:32:45 INFO    Starting calibrated evaluation and roaming
22.04.2018 17:49:12 INFO    Starting theta 100 / 1017
22.04.2018 19:05:45 INFO    Starting theta 200 / 1017
22.04.2018 20:22:17 INFO    Starting theta 300 / 1017
22.04.2018 21:38:43 INFO    Starting theta 400 / 1017
22.04.2018 22:55:16 INFO    Starting theta 500 / 1017
23.04.2018 00:11:42 INFO    Starting theta 600 / 1017
23.04.2018 01:28:01 INFO    Starting theta 700 / 1017
23.04.2018 02:43:55 INFO    Starting theta 800 / 1017
23.04.2018 03:59:47 INFO    Starting theta 900 / 1017
23.04.2018 05:15:20 INFO    Starting theta 1000 / 1017
23.04.2018 05:28:56 INFO    Calibrated evaluation timing: median 1.081635952 s, mean 1.08623233329 s
23.04.2018 05:28:56 INFO    Interpolating calibrated roaming
23.04.2018 05:34:43 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 05:34:46 INFO    Hi! How are you today?
23.04.2018 05:34:46 INFO    Startup options:
23.04.2018 05:34:46 INFO      Algorithm:                     combined
23.04.2018 05:34:46 INFO      Point by point:                False
23.04.2018 05:34:46 INFO      Morphing-aware mode:           False
23.04.2018 05:34:46 INFO      Smeared data:                  False
23.04.2018 05:34:46 INFO      Training sample:               baseline
23.04.2018 05:34:46 INFO      alpha:                         None
23.04.2018 05:34:46 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 05:34:46 INFO      AFC epsilon:                   None
23.04.2018 05:34:46 INFO      Denominator theta:             False
23.04.2018 05:34:46 INFO      Neyman construction toys:      0
23.04.2018 05:34:46 INFO      Training sample size limit:    500000
23.04.2018 05:34:46 INFO      Other options:                 ['deep']
23.04.2018 05:34:46 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 05:34:46 INFO      ML-based strategies available: True
23.04.2018 05:34:46 INFO    Starting parameterized inference
23.04.2018 05:34:46 INFO    Main settings:
23.04.2018 05:34:46 INFO      Algorithm:                combined
23.04.2018 05:34:46 INFO      Morphing-aware:           False
23.04.2018 05:34:46 INFO      Training sample:          baseline
23.04.2018 05:34:46 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 05:34:46 INFO    Options:
23.04.2018 05:34:46 INFO      Number of hidden layers:  5
23.04.2018 05:34:46 INFO      alpha:                    5.0
23.04.2018 05:34:46 INFO      Batch size:               128
23.04.2018 05:34:46 INFO      Learning rate:            0.001
23.04.2018 05:34:46 INFO      Learning rate decay:      0.00460517018599
23.04.2018 05:34:46 INFO      Number of epochs:         1000
23.04.2018 05:34:46 INFO      Training samples:         500000
23.04.2018 05:34:46 INFO      NC experiments:           False
23.04.2018 05:34:46 INFO      Debug mode:               False
23.04.2018 05:35:08 INFO    Reduced training sample size from 9999997 to 500000 (factor 20)
23.04.2018 05:35:23 INFO    Starting training
2018-04-23 05:35:23.919155: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 05:35:23.919189: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 05:35:23.919193: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 05:35:23.919197: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 05:35:23.919201: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 05:35:24.233193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-23 05:35:24.233234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 05:35:24.233240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 05:35:24.233248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 00481: early stopping
23.04.2018 08:58:16 INFO    Starting evaluation
23.04.2018 09:00:06 INFO    Starting theta 100 / 1017
23.04.2018 09:01:53 INFO    Starting theta 200 / 1017
23.04.2018 09:03:41 INFO    Starting theta 300 / 1017
23.04.2018 09:05:28 INFO    Starting theta 400 / 1017
23.04.2018 09:07:15 INFO    Starting theta 500 / 1017
23.04.2018 09:09:02 INFO    Starting theta 600 / 1017
23.04.2018 09:10:49 INFO    Starting theta 700 / 1017
23.04.2018 09:12:37 INFO    Starting theta 800 / 1017
23.04.2018 09:14:24 INFO    Starting theta 900 / 1017
23.04.2018 09:16:11 INFO    Starting theta 1000 / 1017
23.04.2018 09:16:30 INFO    Evaluation timing: median 1.06050300598 s, mean 1.06367593693 s
23.04.2018 09:16:30 INFO    Starting roaming
23.04.2018 09:16:52 INFO    Starting calibrated evaluation and roaming
23.04.2018 10:31:23 INFO    Starting theta 100 / 1017
23.04.2018 11:49:16 INFO    Starting theta 200 / 1017
23.04.2018 13:05:38 INFO    Starting theta 300 / 1017
23.04.2018 14:23:08 INFO    Starting theta 400 / 1017
23.04.2018 15:41:50 INFO    Starting theta 500 / 1017
23.04.2018 16:59:39 INFO    Starting theta 600 / 1017
23.04.2018 18:18:15 INFO    Starting theta 700 / 1017
23.04.2018 19:37:20 INFO    Starting theta 800 / 1017
23.04.2018 20:56:23 INFO    Starting theta 900 / 1017
23.04.2018 22:13:24 INFO    Starting theta 1000 / 1017
23.04.2018 22:26:59 INFO    Calibrated evaluation timing: median 1.10531711578 s, mean 1.10493167265 s
23.04.2018 22:26:59 INFO    Interpolating calibrated roaming
23.04.2018 22:31:54 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 22:31:57 INFO    Hi! How are you today?
23.04.2018 22:31:57 INFO    Startup options:
23.04.2018 22:31:57 INFO      Algorithm:                     combined
23.04.2018 22:31:57 INFO      Point by point:                False
23.04.2018 22:31:57 INFO      Morphing-aware mode:           False
23.04.2018 22:31:57 INFO      Smeared data:                  False
23.04.2018 22:31:57 INFO      Training sample:               baseline
23.04.2018 22:31:57 INFO      alpha:                         None
23.04.2018 22:31:57 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 22:31:57 INFO      AFC epsilon:                   None
23.04.2018 22:31:57 INFO      Denominator theta:             False
23.04.2018 22:31:57 INFO      Neyman construction toys:      0
23.04.2018 22:31:57 INFO      Training sample size limit:    1000000
23.04.2018 22:31:57 INFO      Other options:                 ['deep']
23.04.2018 22:31:57 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 22:31:57 INFO      ML-based strategies available: True
23.04.2018 22:31:57 INFO    Starting parameterized inference
23.04.2018 22:31:57 INFO    Main settings:
23.04.2018 22:31:57 INFO      Algorithm:                combined
23.04.2018 22:31:57 INFO      Morphing-aware:           False
23.04.2018 22:31:57 INFO      Training sample:          baseline
23.04.2018 22:31:57 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 22:31:57 INFO    Options:
23.04.2018 22:31:57 INFO      Number of hidden layers:  5
23.04.2018 22:31:57 INFO      alpha:                    5.0
23.04.2018 22:31:57 INFO      Batch size:               128
23.04.2018 22:31:57 INFO      Learning rate:            0.001
23.04.2018 22:31:57 INFO      Learning rate decay:      0.00921034037198
23.04.2018 22:31:57 INFO      Number of epochs:         500
23.04.2018 22:31:57 INFO      Training samples:         1000000
23.04.2018 22:31:57 INFO      NC experiments:           False
23.04.2018 22:31:57 INFO      Debug mode:               False
23.04.2018 22:32:18 INFO    Reduced training sample size from 9999997 to 1000000 (factor 10)
23.04.2018 22:32:34 INFO    Starting training
2018-04-23 22:32:34.985308: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 22:32:34.985339: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 22:32:34.985344: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 22:32:34.985348: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 22:32:34.985352: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 22:32:35.296125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-23 22:32:35.296161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 22:32:35.296166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 22:32:35.296174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 00353: early stopping
24.04.2018 03:27:58 INFO    Starting evaluation
24.04.2018 03:29:49 INFO    Starting theta 100 / 1017
24.04.2018 03:31:36 INFO    Starting theta 200 / 1017
24.04.2018 03:33:24 INFO    Starting theta 300 / 1017
24.04.2018 03:35:12 INFO    Starting theta 400 / 1017
24.04.2018 03:36:59 INFO    Starting theta 500 / 1017
24.04.2018 03:38:47 INFO    Starting theta 600 / 1017
24.04.2018 03:40:34 INFO    Starting theta 700 / 1017
24.04.2018 03:42:22 INFO    Starting theta 800 / 1017
24.04.2018 03:44:10 INFO    Starting theta 900 / 1017
24.04.2018 03:45:57 INFO    Starting theta 1000 / 1017
24.04.2018 03:46:17 INFO    Evaluation timing: median 1.06377601624 s, mean 1.06758776691 s
24.04.2018 03:46:17 INFO    Starting roaming
24.04.2018 03:46:39 INFO    Starting calibrated evaluation and roaming
24.04.2018 05:01:20 INFO    Starting theta 100 / 1017
24.04.2018 06:16:42 INFO    Starting theta 200 / 1017
24.04.2018 07:32:00 INFO    Starting theta 300 / 1017
24.04.2018 08:47:19 INFO    Starting theta 400 / 1017
24.04.2018 10:02:38 INFO    Starting theta 500 / 1017
24.04.2018 11:19:05 INFO    Starting theta 600 / 1017
24.04.2018 12:35:33 INFO    Starting theta 700 / 1017
24.04.2018 13:51:32 INFO    Starting theta 800 / 1017
24.04.2018 15:06:54 INFO    Starting theta 900 / 1017
24.04.2018 16:23:47 INFO    Starting theta 1000 / 1017
24.04.2018 16:37:21 INFO    Calibrated evaluation timing: median 1.07333803177 s, mean 1.07990133563 s
24.04.2018 16:37:21 INFO    Interpolating calibrated roaming
24.04.2018 16:42:50 INFO    That's it -- have a great day!
Using TensorFlow backend.
24.04.2018 16:42:53 INFO    Hi! How are you today?
24.04.2018 16:42:53 INFO    Startup options:
24.04.2018 16:42:53 INFO      Algorithm:                     combined
24.04.2018 16:42:53 INFO      Point by point:                False
24.04.2018 16:42:53 INFO      Morphing-aware mode:           False
24.04.2018 16:42:53 INFO      Smeared data:                  False
24.04.2018 16:42:53 INFO      Training sample:               baseline
24.04.2018 16:42:53 INFO      alpha:                         None
24.04.2018 16:42:53 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
24.04.2018 16:42:53 INFO      AFC epsilon:                   None
24.04.2018 16:42:53 INFO      Denominator theta:             False
24.04.2018 16:42:53 INFO      Neyman construction toys:      0
24.04.2018 16:42:53 INFO      Training sample size limit:    2000000
24.04.2018 16:42:53 INFO      Other options:                 ['deep']
24.04.2018 16:42:53 INFO      Base directory:                /home/jb6504/higgs_inference
24.04.2018 16:42:53 INFO      ML-based strategies available: True
24.04.2018 16:42:53 INFO    Starting parameterized inference
24.04.2018 16:42:53 INFO    Main settings:
24.04.2018 16:42:53 INFO      Algorithm:                combined
24.04.2018 16:42:53 INFO      Morphing-aware:           False
24.04.2018 16:42:53 INFO      Training sample:          baseline
24.04.2018 16:42:53 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
24.04.2018 16:42:53 INFO    Options:
24.04.2018 16:42:53 INFO      Number of hidden layers:  5
24.04.2018 16:42:53 INFO      alpha:                    5.0
24.04.2018 16:42:53 INFO      Batch size:               128
24.04.2018 16:42:53 INFO      Learning rate:            0.001
24.04.2018 16:42:53 INFO      Learning rate decay:      0.018420680744
24.04.2018 16:42:53 INFO      Number of epochs:         250
24.04.2018 16:42:53 INFO      Training samples:         2000000
24.04.2018 16:42:53 INFO      NC experiments:           False
24.04.2018 16:42:53 INFO      Debug mode:               False
24.04.2018 16:43:14 INFO    Reduced training sample size from 9999997 to 2000000 (factor 5)
24.04.2018 16:43:33 INFO    Starting training
2018-04-24 16:43:33.666815: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 16:43:33.666847: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 16:43:33.666851: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 16:43:33.666855: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 16:43:33.666859: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 16:43:33.969978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:04:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-24 16:43:33.970014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-24 16:43:33.970020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-24 16:43:33.970027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:04:00.0)
Epoch 00182: early stopping
24.04.2018 21:48:44 INFO    Starting evaluation
24.04.2018 21:50:35 INFO    Starting theta 100 / 1017
24.04.2018 21:52:23 INFO    Starting theta 200 / 1017
24.04.2018 21:54:11 INFO    Starting theta 300 / 1017
24.04.2018 21:55:59 INFO    Starting theta 400 / 1017
24.04.2018 21:57:47 INFO    Starting theta 500 / 1017
24.04.2018 21:59:35 INFO    Starting theta 600 / 1017
24.04.2018 22:01:22 INFO    Starting theta 700 / 1017
24.04.2018 22:03:10 INFO    Starting theta 800 / 1017
24.04.2018 22:04:58 INFO    Starting theta 900 / 1017
24.04.2018 22:06:46 INFO    Starting theta 1000 / 1017
24.04.2018 22:07:05 INFO    Evaluation timing: median 1.06261706352 s, mean 1.06977206041 s
24.04.2018 22:07:05 INFO    Starting roaming
24.04.2018 22:07:27 INFO    Starting calibrated evaluation and roaming
24.04.2018 23:22:16 INFO    Starting theta 100 / 1017
25.04.2018 00:38:08 INFO    Starting theta 200 / 1017
25.04.2018 01:54:34 INFO    Starting theta 300 / 1017
25.04.2018 03:11:45 INFO    Starting theta 400 / 1017
25.04.2018 04:28:42 INFO    Starting theta 500 / 1017
25.04.2018 05:45:47 INFO    Starting theta 600 / 1017
25.04.2018 07:02:52 INFO    Starting theta 700 / 1017
25.04.2018 08:19:49 INFO    Starting theta 800 / 1017
25.04.2018 09:36:52 INFO    Starting theta 900 / 1017
