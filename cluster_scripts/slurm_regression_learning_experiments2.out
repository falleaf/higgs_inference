Using TensorFlow backend.
16.02.2018 07:01:17 INFO    Hi! How are you today?
16.02.2018 07:01:17 INFO    Startup options:
16.02.2018 07:01:17 INFO      Algorithm:                     regression
16.02.2018 07:01:17 INFO      Point by point:                False
16.02.2018 07:01:17 INFO      Morphing-aware mode:           False
16.02.2018 07:01:17 INFO      Smeared data:                  False
16.02.2018 07:01:17 INFO      Training sample:               baseline
16.02.2018 07:01:17 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
16.02.2018 07:01:17 INFO      alpha:                         None
16.02.2018 07:01:17 INFO      AFC epsilon:                   None
16.02.2018 07:01:17 INFO      Neyman construction toys:      False
16.02.2018 07:01:17 INFO      Other options:                 ['largebatch', 'constantlr']
16.02.2018 07:01:17 INFO      Base directory:                /home/jb6504/higgs_inference
16.02.2018 07:01:17 INFO      ML-based strategies available: True
16.02.2018 07:01:17 INFO    Starting parameterized inference
16.02.2018 07:01:17 INFO    Main settings:
16.02.2018 07:01:17 INFO      Algorithm:                regression
16.02.2018 07:01:17 INFO      Morphing-aware:           False
16.02.2018 07:01:17 INFO      Training sample:          baseline
16.02.2018 07:01:17 INFO    Options:
16.02.2018 07:01:17 INFO      Number of hidden layers:  2
16.02.2018 07:01:17 INFO      Batch size:               256
16.02.2018 07:01:17 INFO      Learning rate:            0.001
16.02.2018 07:01:17 INFO      Learning rate decay:      0.0
16.02.2018 07:01:17 INFO      Number of epochs:         50
16.02.2018 07:01:17 INFO      Debug mode:               False
16.02.2018 07:01:45 INFO    Starting training
Train on 7995920 samples, validate on 1998980 samples
Epoch 1/50
2018-02-16 07:01:45.904129: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:01:45.904506: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:01:45.904514: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:01:45.904519: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:01:45.904522: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:01:46.202606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-16 07:01:46.202640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-16 07:01:46.202646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-16 07:01:46.202654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0)
Traceback (most recent call last):
  File "experiments.py", line 139, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/parameterized.py", line 360, in parameterized_inference
    history = regr.fit(X_thetas_train[::], y_logr_score_train[::], callbacks=callbacks, batch_size=batch_size)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/wrappers/scikit_learn.py", line 149, in fit
    history = self.model.fit(x, y, **fit_args)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1485, in fit
    initial_epoch=initial_epoch)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1146, in _fit_loop
    callbacks.on_batch_end(batch_index, batch_logs)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/callbacks.py", line 111, in on_batch_end
    callback.on_batch_end(batch, logs)
  File "/home/jb6504/higgs_inference/higgs_inference/models/ml_utils.py", line 65, in on_batch_end
    if self.n_batches_in_buffer >= self.n_batches_per_entry:
AttributeError: 'DetailedHistory' object has no attribute 'n_batches_per_entry'
Using TensorFlow backend.
16.02.2018 07:01:49 INFO    Hi! How are you today?
16.02.2018 07:01:49 INFO    Startup options:
16.02.2018 07:01:49 INFO      Algorithm:                     regression
16.02.2018 07:01:49 INFO      Point by point:                False
16.02.2018 07:01:49 INFO      Morphing-aware mode:           False
16.02.2018 07:01:49 INFO      Smeared data:                  False
16.02.2018 07:01:49 INFO      Training sample:               baseline
16.02.2018 07:01:49 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
16.02.2018 07:01:49 INFO      alpha:                         None
16.02.2018 07:01:49 INFO      AFC epsilon:                   None
16.02.2018 07:01:49 INFO      Neyman construction toys:      False
16.02.2018 07:01:49 INFO      Other options:                 ['largebatch', 'fastlearning', 'constantlr']
16.02.2018 07:01:49 INFO      Base directory:                /home/jb6504/higgs_inference
16.02.2018 07:01:49 INFO      ML-based strategies available: True
16.02.2018 07:01:49 INFO    Starting parameterized inference
16.02.2018 07:01:49 INFO    Main settings:
16.02.2018 07:01:49 INFO      Algorithm:                regression
16.02.2018 07:01:49 INFO      Morphing-aware:           False
16.02.2018 07:01:49 INFO      Training sample:          baseline
16.02.2018 07:01:49 INFO    Options:
16.02.2018 07:01:49 INFO      Number of hidden layers:  2
16.02.2018 07:01:49 INFO      Batch size:               256
16.02.2018 07:01:49 INFO      Learning rate:            0.01
16.02.2018 07:01:49 INFO      Learning rate decay:      0.0
16.02.2018 07:01:49 INFO      Number of epochs:         50
16.02.2018 07:01:49 INFO      Debug mode:               False
16.02.2018 07:02:17 INFO    Starting training
Train on 7995920 samples, validate on 1998980 samples
Epoch 1/50
2018-02-16 07:02:18.072436: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:18.072800: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:18.072808: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:18.072812: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:18.072816: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:18.371003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-16 07:02:18.371037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-16 07:02:18.371043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-16 07:02:18.371052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0)
Traceback (most recent call last):
  File "experiments.py", line 139, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/parameterized.py", line 360, in parameterized_inference
    history = regr.fit(X_thetas_train[::], y_logr_score_train[::], callbacks=callbacks, batch_size=batch_size)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/wrappers/scikit_learn.py", line 149, in fit
    history = self.model.fit(x, y, **fit_args)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1485, in fit
    initial_epoch=initial_epoch)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1146, in _fit_loop
    callbacks.on_batch_end(batch_index, batch_logs)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/callbacks.py", line 111, in on_batch_end
    callback.on_batch_end(batch, logs)
  File "/home/jb6504/higgs_inference/higgs_inference/models/ml_utils.py", line 65, in on_batch_end
    if self.n_batches_in_buffer >= self.n_batches_per_entry:
AttributeError: 'DetailedHistory' object has no attribute 'n_batches_per_entry'
Using TensorFlow backend.
16.02.2018 07:02:21 INFO    Hi! How are you today?
16.02.2018 07:02:21 INFO    Startup options:
16.02.2018 07:02:21 INFO      Algorithm:                     regression
16.02.2018 07:02:21 INFO      Point by point:                False
16.02.2018 07:02:21 INFO      Morphing-aware mode:           False
16.02.2018 07:02:21 INFO      Smeared data:                  False
16.02.2018 07:02:21 INFO      Training sample:               baseline
16.02.2018 07:02:21 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
16.02.2018 07:02:21 INFO      alpha:                         None
16.02.2018 07:02:21 INFO      AFC epsilon:                   None
16.02.2018 07:02:21 INFO      Neyman construction toys:      False
16.02.2018 07:02:21 INFO      Other options:                 ['largebatch', 'slowlearning', 'constantlr']
16.02.2018 07:02:21 INFO      Base directory:                /home/jb6504/higgs_inference
16.02.2018 07:02:21 INFO      ML-based strategies available: True
16.02.2018 07:02:21 INFO    Starting parameterized inference
16.02.2018 07:02:21 INFO    Main settings:
16.02.2018 07:02:21 INFO      Algorithm:                regression
16.02.2018 07:02:21 INFO      Morphing-aware:           False
16.02.2018 07:02:21 INFO      Training sample:          baseline
16.02.2018 07:02:21 INFO    Options:
16.02.2018 07:02:21 INFO      Number of hidden layers:  2
16.02.2018 07:02:21 INFO      Batch size:               256
16.02.2018 07:02:21 INFO      Learning rate:            0.0001
16.02.2018 07:02:21 INFO      Learning rate decay:      0.0
16.02.2018 07:02:21 INFO      Number of epochs:         50
16.02.2018 07:02:21 INFO      Debug mode:               False
16.02.2018 07:02:48 INFO    Starting training
Train on 7995920 samples, validate on 1998980 samples
Epoch 1/50
2018-02-16 07:02:49.693345: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:49.693683: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:49.693692: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:49.693696: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:49.693702: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-16 07:02:49.995460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-02-16 07:02:49.995496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-02-16 07:02:49.995502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-02-16 07:02:49.995511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0)
Traceback (most recent call last):
  File "experiments.py", line 139, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/parameterized.py", line 360, in parameterized_inference
    history = regr.fit(X_thetas_train[::], y_logr_score_train[::], callbacks=callbacks, batch_size=batch_size)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/wrappers/scikit_learn.py", line 149, in fit
    history = self.model.fit(x, y, **fit_args)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1485, in fit
    initial_epoch=initial_epoch)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/engine/training.py", line 1146, in _fit_loop
    callbacks.on_batch_end(batch_index, batch_logs)
  File "/share/apps/keras/2.0.2/lib/python2.7/site-packages/Keras-2.0.2-py2.7.egg/keras/callbacks.py", line 111, in on_batch_end
    callback.on_batch_end(batch, logs)
  File "/home/jb6504/higgs_inference/higgs_inference/models/ml_utils.py", line 65, in on_batch_end
    if self.n_batches_in_buffer >= self.n_batches_per_entry:
AttributeError: 'DetailedHistory' object has no attribute 'n_batches_per_entry'
Using TensorFlow backend.
16.02.2018 07:02:53 INFO    Hi! How are you today?
16.02.2018 07:02:53 INFO    Startup options:
16.02.2018 07:02:53 INFO      Algorithm:                     regression
16.02.2018 07:02:53 INFO      Point by point:                False
16.02.2018 07:02:53 INFO      Morphing-aware mode:           False
16.02.2018 07:02:53 INFO      Smeared data:                  False
16.02.2018 07:02:53 INFO      Training sample:               baseline
16.02.2018 07:02:53 INFO      AFC X indices:                 [1, 38, 39, 40, 41]
16.02.2018 07:02:53 INFO      alpha:                         None
16.02.2018 07:02:53 INFO      AFC epsilon:                   None
16.02.2018 07:02:53 INFO      Neyman construction toys:      False
16.02.2018 07:02:53 INFO      Other options:                 ['constantlr']
16.02.2018 07:02:53 INFO      Base directory:                /home/jb6504/higgs_inference
16.02.2018 07:02:53 INFO      ML-based strategies available: True
16.02.2018 07:02:53 INFO    Starting parameterized inference
16.02.2018 07:02:53 INFO    Main settings:
16.02.2018 07:02:53 INFO      Algorithm:                regression
16.02.2018 07:02:53 INFO      Morphing-aware:           False
16.02.2018 07:02:53 INFO      Training sample:          baseline
16.02.2018 07:02:53 INFO    Options:
16.02.2018 07:02:53 INFO      Number of hidden layers:  2
16.02.2018 07:02:53 INFO      Batch size:               128
16.02.2018 07:02:53 INFO      Learning rate:            0.001
16.02.2018 07:02:53 INFO      Learning rate decay:      0.0
16.02.2018 07:02:53 INFO      Number of epochs:         50
16.02.2018 07:02:53 INFO      Debug mode:               False
slurmstepd: error: *** JOB 4553773 ON gpu-07 CANCELLED AT 2018-02-16T07:03:06 ***
