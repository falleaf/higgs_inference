Using TensorFlow backend.
19.04.2018 10:34:06 INFO    Hi! How are you today?
19.04.2018 10:34:06 INFO    Startup options:
19.04.2018 10:34:06 INFO      Algorithm:                     carl
19.04.2018 10:34:06 INFO      Point by point:                False
19.04.2018 10:34:06 INFO      Morphing-aware mode:           False
19.04.2018 10:34:06 INFO      Smeared data:                  False
19.04.2018 10:34:06 INFO      Training sample:               baseline
19.04.2018 10:34:06 INFO      alpha:                         None
19.04.2018 10:34:06 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
19.04.2018 10:34:06 INFO      AFC epsilon:                   None
19.04.2018 10:34:06 INFO      Denominator theta:             False
19.04.2018 10:34:06 INFO      Neyman construction toys:      0
19.04.2018 10:34:06 INFO      Training sample size limit:    5000
19.04.2018 10:34:06 INFO      Other options:                 ['shallow']
19.04.2018 10:34:06 INFO      Base directory:                /home/jb6504/higgs_inference
19.04.2018 10:34:06 INFO      ML-based strategies available: True
19.04.2018 10:34:06 INFO    Starting parameterized inference
19.04.2018 10:34:06 INFO    Main settings:
19.04.2018 10:34:06 INFO      Algorithm:                carl
19.04.2018 10:34:06 INFO      Morphing-aware:           False
19.04.2018 10:34:06 INFO      Training sample:          baseline
19.04.2018 10:34:06 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
19.04.2018 10:34:06 INFO    Options:
19.04.2018 10:34:06 INFO      Number of hidden layers:  2
19.04.2018 10:34:06 INFO      Batch size:               128
19.04.2018 10:34:06 INFO      Learning rate:            0.001
19.04.2018 10:34:06 INFO      Learning rate decay:      4.60517018599e-05
19.04.2018 10:34:06 INFO      Number of epochs:         100000
19.04.2018 10:34:06 INFO      Training samples:         5000
19.04.2018 10:34:06 INFO      NC experiments:           False
19.04.2018 10:34:06 INFO      Debug mode:               False
19.04.2018 10:34:27 INFO    Reduced training sample size from 9999997 to 5000 (factor 2000)
19.04.2018 10:34:42 INFO    Starting training
2018-04-19 10:34:42.928594: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.928632: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.928637: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.928642: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:42.928646: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:34:43.230961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-19 10:34:43.230996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-19 10:34:43.231002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-19 10:34:43.231010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 20002: early stopping
19.04.2018 11:54:11 INFO    Starting evaluation
19.04.2018 11:56:24 INFO    Starting theta 100 / 1017
19.04.2018 11:58:32 INFO    Starting theta 200 / 1017
19.04.2018 12:00:40 INFO    Starting theta 300 / 1017
19.04.2018 12:02:48 INFO    Starting theta 400 / 1017
19.04.2018 12:04:57 INFO    Starting theta 500 / 1017
19.04.2018 12:07:05 INFO    Starting theta 600 / 1017
19.04.2018 12:09:13 INFO    Starting theta 700 / 1017
19.04.2018 12:11:21 INFO    Starting theta 800 / 1017
19.04.2018 12:13:30 INFO    Starting theta 900 / 1017
19.04.2018 12:15:38 INFO    Starting theta 1000 / 1017
19.04.2018 12:16:01 INFO    Evaluation timing: median 1.26979398727 s, mean 1.27101221783 s
19.04.2018 12:16:01 INFO    Starting roaming
19.04.2018 12:16:27 INFO    Starting calibrated evaluation and roaming
19.04.2018 13:44:35 INFO    Starting theta 100 / 1017
19.04.2018 15:13:30 INFO    Starting theta 200 / 1017
19.04.2018 16:42:26 INFO    Starting theta 300 / 1017
19.04.2018 18:11:25 INFO    Starting theta 400 / 1017
19.04.2018 19:40:23 INFO    Starting theta 500 / 1017
19.04.2018 21:09:11 INFO    Starting theta 600 / 1017
19.04.2018 22:38:02 INFO    Starting theta 700 / 1017
20.04.2018 00:06:51 INFO    Starting theta 800 / 1017
20.04.2018 01:35:58 INFO    Starting theta 900 / 1017
20.04.2018 03:05:19 INFO    Starting theta 1000 / 1017
20.04.2018 03:21:23 INFO    Calibrated evaluation timing: median 1.27446818352 s, mean 1.27530459598 s
20.04.2018 03:21:23 INFO    Interpolating calibrated roaming
20.04.2018 03:26:20 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 03:26:25 INFO    Hi! How are you today?
20.04.2018 03:26:25 INFO    Startup options:
20.04.2018 03:26:25 INFO      Algorithm:                     carl
20.04.2018 03:26:25 INFO      Point by point:                False
20.04.2018 03:26:25 INFO      Morphing-aware mode:           False
20.04.2018 03:26:25 INFO      Smeared data:                  False
20.04.2018 03:26:25 INFO      Training sample:               baseline
20.04.2018 03:26:25 INFO      alpha:                         None
20.04.2018 03:26:25 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 03:26:25 INFO      AFC epsilon:                   None
20.04.2018 03:26:25 INFO      Denominator theta:             False
20.04.2018 03:26:25 INFO      Neyman construction toys:      0
20.04.2018 03:26:25 INFO      Training sample size limit:    10000
20.04.2018 03:26:25 INFO      Other options:                 ['shallow']
20.04.2018 03:26:25 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 03:26:25 INFO      ML-based strategies available: True
20.04.2018 03:26:25 INFO    Starting parameterized inference
20.04.2018 03:26:25 INFO    Main settings:
20.04.2018 03:26:25 INFO      Algorithm:                carl
20.04.2018 03:26:25 INFO      Morphing-aware:           False
20.04.2018 03:26:25 INFO      Training sample:          baseline
20.04.2018 03:26:25 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 03:26:25 INFO    Options:
20.04.2018 03:26:25 INFO      Number of hidden layers:  2
20.04.2018 03:26:25 INFO      Batch size:               128
20.04.2018 03:26:25 INFO      Learning rate:            0.001
20.04.2018 03:26:25 INFO      Learning rate decay:      9.21034037198e-05
20.04.2018 03:26:25 INFO      Number of epochs:         50000
20.04.2018 03:26:25 INFO      Training samples:         10000
20.04.2018 03:26:25 INFO      NC experiments:           False
20.04.2018 03:26:25 INFO      Debug mode:               False
20.04.2018 03:26:45 INFO    Reduced training sample size from 9999997 to 10000 (factor 1000)
20.04.2018 03:26:59 INFO    Starting training
2018-04-20 03:26:59.722805: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:26:59.722844: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:26:59.722849: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:26:59.722857: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:26:59.722862: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:27:00.011298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-20 03:27:00.011334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 03:27:00.011340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 03:27:00.011349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 10002: early stopping
20.04.2018 04:40:47 INFO    Starting evaluation
20.04.2018 04:42:53 INFO    Starting theta 100 / 1017
20.04.2018 04:44:56 INFO    Starting theta 200 / 1017
20.04.2018 04:46:58 INFO    Starting theta 300 / 1017
20.04.2018 04:49:01 INFO    Starting theta 400 / 1017
20.04.2018 04:51:03 INFO    Starting theta 500 / 1017
20.04.2018 04:53:06 INFO    Starting theta 600 / 1017
20.04.2018 04:55:08 INFO    Starting theta 700 / 1017
20.04.2018 04:57:11 INFO    Starting theta 800 / 1017
20.04.2018 04:59:14 INFO    Starting theta 900 / 1017
20.04.2018 05:01:16 INFO    Starting theta 1000 / 1017
20.04.2018 05:01:38 INFO    Evaluation timing: median 1.21540808678 s, mean 1.21630207627 s
20.04.2018 05:01:38 INFO    Starting roaming
20.04.2018 05:02:03 INFO    Starting calibrated evaluation and roaming
20.04.2018 06:26:53 INFO    Starting theta 100 / 1017
20.04.2018 07:54:28 INFO    Starting theta 200 / 1017
20.04.2018 09:22:10 INFO    Starting theta 300 / 1017
20.04.2018 10:49:47 INFO    Starting theta 400 / 1017
20.04.2018 12:17:38 INFO    Starting theta 500 / 1017
20.04.2018 13:45:20 INFO    Starting theta 600 / 1017
20.04.2018 15:12:57 INFO    Starting theta 700 / 1017
20.04.2018 16:40:38 INFO    Starting theta 800 / 1017
20.04.2018 18:08:27 INFO    Starting theta 900 / 1017
20.04.2018 19:36:05 INFO    Starting theta 1000 / 1017
20.04.2018 19:51:50 INFO    Calibrated evaluation timing: median 1.25441098213 s, mean 1.25163225415 s
20.04.2018 19:51:50 INFO    Interpolating calibrated roaming
20.04.2018 19:57:09 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 19:57:11 INFO    Hi! How are you today?
20.04.2018 19:57:11 INFO    Startup options:
20.04.2018 19:57:11 INFO      Algorithm:                     carl
20.04.2018 19:57:11 INFO      Point by point:                False
20.04.2018 19:57:11 INFO      Morphing-aware mode:           False
20.04.2018 19:57:11 INFO      Smeared data:                  False
20.04.2018 19:57:11 INFO      Training sample:               baseline
20.04.2018 19:57:11 INFO      alpha:                         None
20.04.2018 19:57:11 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 19:57:11 INFO      AFC epsilon:                   None
20.04.2018 19:57:11 INFO      Denominator theta:             False
20.04.2018 19:57:11 INFO      Neyman construction toys:      0
20.04.2018 19:57:11 INFO      Training sample size limit:    20000
20.04.2018 19:57:11 INFO      Other options:                 ['shallow']
20.04.2018 19:57:11 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 19:57:11 INFO      ML-based strategies available: True
20.04.2018 19:57:11 INFO    Starting parameterized inference
20.04.2018 19:57:11 INFO    Main settings:
20.04.2018 19:57:11 INFO      Algorithm:                carl
20.04.2018 19:57:11 INFO      Morphing-aware:           False
20.04.2018 19:57:11 INFO      Training sample:          baseline
20.04.2018 19:57:11 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 19:57:11 INFO    Options:
20.04.2018 19:57:11 INFO      Number of hidden layers:  2
20.04.2018 19:57:11 INFO      Batch size:               128
20.04.2018 19:57:11 INFO      Learning rate:            0.001
20.04.2018 19:57:11 INFO      Learning rate decay:      0.00018420680744
20.04.2018 19:57:11 INFO      Number of epochs:         25000
20.04.2018 19:57:11 INFO      Training samples:         20000
20.04.2018 19:57:11 INFO      NC experiments:           False
20.04.2018 19:57:11 INFO      Debug mode:               False
20.04.2018 19:57:37 INFO    Reduced training sample size from 9999997 to 20000 (factor 500)
20.04.2018 19:57:51 INFO    Starting training
2018-04-20 19:57:52.301117: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:57:52.301152: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:57:52.301158: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:57:52.301162: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:57:52.301166: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:57:52.600744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-20 19:57:52.600780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 19:57:52.600787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 19:57:52.600796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 05005: early stopping
20.04.2018 21:16:30 INFO    Starting evaluation
Traceback (most recent call last):
  File "experiments.py", line 154, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/parameterized.py", line 496, in parameterized_inference
    mse_log_r.append(calculate_mean_squared_error(np.log(r_test[t]), this_log_r, 0.))
  File "/home/jb6504/higgs_inference/higgs_inference/various/utils.py", line 47, in calculate_mean_squared_error
    return mean_squared_error(y_true, y_pred)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/metrics/regression.py", line 231, in mean_squared_error
    y_true, y_pred, multioutput)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/metrics/regression.py", line 76, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/utils/validation.py", line 407, in check_array
    _assert_all_finite(array)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/utils/validation.py", line 58, in _assert_all_finite
    " or a value too large for %r." % X.dtype)
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').
Using TensorFlow backend.
20.04.2018 21:16:34 INFO    Hi! How are you today?
20.04.2018 21:16:34 INFO    Startup options:
20.04.2018 21:16:34 INFO      Algorithm:                     carl
20.04.2018 21:16:34 INFO      Point by point:                False
20.04.2018 21:16:34 INFO      Morphing-aware mode:           False
20.04.2018 21:16:34 INFO      Smeared data:                  False
20.04.2018 21:16:34 INFO      Training sample:               baseline
20.04.2018 21:16:34 INFO      alpha:                         None
20.04.2018 21:16:34 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 21:16:34 INFO      AFC epsilon:                   None
20.04.2018 21:16:34 INFO      Denominator theta:             False
20.04.2018 21:16:34 INFO      Neyman construction toys:      0
20.04.2018 21:16:34 INFO      Training sample size limit:    50000
20.04.2018 21:16:34 INFO      Other options:                 ['shallow']
20.04.2018 21:16:34 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 21:16:34 INFO      ML-based strategies available: True
20.04.2018 21:16:34 INFO    Starting parameterized inference
20.04.2018 21:16:34 INFO    Main settings:
20.04.2018 21:16:34 INFO      Algorithm:                carl
20.04.2018 21:16:34 INFO      Morphing-aware:           False
20.04.2018 21:16:34 INFO      Training sample:          baseline
20.04.2018 21:16:34 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 21:16:34 INFO    Options:
20.04.2018 21:16:34 INFO      Number of hidden layers:  2
20.04.2018 21:16:34 INFO      Batch size:               128
20.04.2018 21:16:34 INFO      Learning rate:            0.001
20.04.2018 21:16:34 INFO      Learning rate decay:      0.000460517018599
20.04.2018 21:16:34 INFO      Number of epochs:         10000
20.04.2018 21:16:34 INFO      Training samples:         50000
20.04.2018 21:16:34 INFO      NC experiments:           False
20.04.2018 21:16:34 INFO      Debug mode:               False
20.04.2018 21:16:59 INFO    Reduced training sample size from 9999997 to 50000 (factor 200)
20.04.2018 21:17:14 INFO    Starting training
2018-04-20 21:17:14.543443: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 21:17:14.543477: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 21:17:14.543482: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 21:17:14.543487: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 21:17:14.543491: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 21:17:14.840584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-20 21:17:14.840622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 21:17:14.840628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 21:17:14.840637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 02011: early stopping
20.04.2018 22:35:28 INFO    Starting evaluation
Traceback (most recent call last):
  File "experiments.py", line 154, in <module>
    options=args.options)
  File "/home/jb6504/higgs_inference/higgs_inference/strategies/parameterized.py", line 496, in parameterized_inference
    mse_log_r.append(calculate_mean_squared_error(np.log(r_test[t]), this_log_r, 0.))
  File "/home/jb6504/higgs_inference/higgs_inference/various/utils.py", line 47, in calculate_mean_squared_error
    return mean_squared_error(y_true, y_pred)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/metrics/regression.py", line 231, in mean_squared_error
    y_true, y_pred, multioutput)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/metrics/regression.py", line 76, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/utils/validation.py", line 407, in check_array
    _assert_all_finite(array)
  File "/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/utils/validation.py", line 58, in _assert_all_finite
    " or a value too large for %r." % X.dtype)
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').
Using TensorFlow backend.
20.04.2018 22:35:32 INFO    Hi! How are you today?
20.04.2018 22:35:32 INFO    Startup options:
20.04.2018 22:35:32 INFO      Algorithm:                     carl
20.04.2018 22:35:32 INFO      Point by point:                False
20.04.2018 22:35:32 INFO      Morphing-aware mode:           False
20.04.2018 22:35:32 INFO      Smeared data:                  False
20.04.2018 22:35:32 INFO      Training sample:               baseline
20.04.2018 22:35:32 INFO      alpha:                         None
20.04.2018 22:35:32 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 22:35:32 INFO      AFC epsilon:                   None
20.04.2018 22:35:32 INFO      Denominator theta:             False
20.04.2018 22:35:32 INFO      Neyman construction toys:      0
20.04.2018 22:35:32 INFO      Training sample size limit:    100000
20.04.2018 22:35:32 INFO      Other options:                 ['shallow']
20.04.2018 22:35:32 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 22:35:32 INFO      ML-based strategies available: True
20.04.2018 22:35:32 INFO    Starting parameterized inference
20.04.2018 22:35:32 INFO    Main settings:
20.04.2018 22:35:32 INFO      Algorithm:                carl
20.04.2018 22:35:32 INFO      Morphing-aware:           False
20.04.2018 22:35:32 INFO      Training sample:          baseline
20.04.2018 22:35:32 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 22:35:32 INFO    Options:
20.04.2018 22:35:32 INFO      Number of hidden layers:  2
20.04.2018 22:35:32 INFO      Batch size:               128
20.04.2018 22:35:32 INFO      Learning rate:            0.001
20.04.2018 22:35:32 INFO      Learning rate decay:      0.000921034037198
20.04.2018 22:35:32 INFO      Number of epochs:         5000
20.04.2018 22:35:32 INFO      Training samples:         100000
20.04.2018 22:35:32 INFO      NC experiments:           False
20.04.2018 22:35:32 INFO      Debug mode:               False
20.04.2018 22:35:55 INFO    Reduced training sample size from 9999997 to 100000 (factor 100)
20.04.2018 22:36:10 INFO    Starting training
2018-04-20 22:36:10.792519: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 22:36:10.792557: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 22:36:10.792562: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 22:36:10.792567: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 22:36:10.792571: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 22:36:11.086929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-20 22:36:11.086966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 22:36:11.086972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 22:36:11.086980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 01006: early stopping
20.04.2018 23:54:13 INFO    Starting evaluation
20.04.2018 23:56:25 INFO    Starting theta 100 / 1017
20.04.2018 23:58:34 INFO    Starting theta 200 / 1017
21.04.2018 00:00:42 INFO    Starting theta 300 / 1017
21.04.2018 00:02:51 INFO    Starting theta 400 / 1017
21.04.2018 00:05:00 INFO    Starting theta 500 / 1017
21.04.2018 00:07:08 INFO    Starting theta 600 / 1017
21.04.2018 00:09:17 INFO    Starting theta 700 / 1017
21.04.2018 00:11:26 INFO    Starting theta 800 / 1017
21.04.2018 00:13:35 INFO    Starting theta 900 / 1017
21.04.2018 00:15:43 INFO    Starting theta 1000 / 1017
21.04.2018 00:16:06 INFO    Evaluation timing: median 1.27235913277 s, mean 1.27425283997 s
21.04.2018 00:16:06 INFO    Starting roaming
21.04.2018 00:16:32 INFO    Starting calibrated evaluation and roaming
21.04.2018 01:44:18 INFO    Starting theta 100 / 1017
21.04.2018 03:12:52 INFO    Starting theta 200 / 1017
21.04.2018 04:41:20 INFO    Starting theta 300 / 1017
21.04.2018 06:09:56 INFO    Starting theta 400 / 1017
21.04.2018 07:38:29 INFO    Starting theta 500 / 1017
21.04.2018 09:06:56 INFO    Starting theta 600 / 1017
21.04.2018 10:35:25 INFO    Starting theta 700 / 1017
21.04.2018 12:04:11 INFO    Starting theta 800 / 1017
21.04.2018 13:33:03 INFO    Starting theta 900 / 1017
21.04.2018 15:01:43 INFO    Starting theta 1000 / 1017
21.04.2018 15:17:40 INFO    Calibrated evaluation timing: median 1.26707601547 s, mean 1.26793343526 s
21.04.2018 15:17:40 INFO    Interpolating calibrated roaming
21.04.2018 15:23:10 INFO    That's it -- have a great day!
Using TensorFlow backend.
21.04.2018 15:23:12 INFO    Hi! How are you today?
21.04.2018 15:23:12 INFO    Startup options:
21.04.2018 15:23:12 INFO      Algorithm:                     carl
21.04.2018 15:23:12 INFO      Point by point:                False
21.04.2018 15:23:12 INFO      Morphing-aware mode:           False
21.04.2018 15:23:12 INFO      Smeared data:                  False
21.04.2018 15:23:12 INFO      Training sample:               baseline
21.04.2018 15:23:12 INFO      alpha:                         None
21.04.2018 15:23:12 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
21.04.2018 15:23:12 INFO      AFC epsilon:                   None
21.04.2018 15:23:12 INFO      Denominator theta:             False
21.04.2018 15:23:12 INFO      Neyman construction toys:      0
21.04.2018 15:23:12 INFO      Training sample size limit:    200000
21.04.2018 15:23:12 INFO      Other options:                 ['shallow']
21.04.2018 15:23:12 INFO      Base directory:                /home/jb6504/higgs_inference
21.04.2018 15:23:12 INFO      ML-based strategies available: True
21.04.2018 15:23:12 INFO    Starting parameterized inference
21.04.2018 15:23:12 INFO    Main settings:
21.04.2018 15:23:12 INFO      Algorithm:                carl
21.04.2018 15:23:12 INFO      Morphing-aware:           False
21.04.2018 15:23:12 INFO      Training sample:          baseline
21.04.2018 15:23:12 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
21.04.2018 15:23:12 INFO    Options:
21.04.2018 15:23:12 INFO      Number of hidden layers:  2
21.04.2018 15:23:12 INFO      Batch size:               128
21.04.2018 15:23:12 INFO      Learning rate:            0.001
21.04.2018 15:23:12 INFO      Learning rate decay:      0.0018420680744
21.04.2018 15:23:12 INFO      Number of epochs:         2500
21.04.2018 15:23:12 INFO      Training samples:         200000
21.04.2018 15:23:12 INFO      NC experiments:           False
21.04.2018 15:23:12 INFO      Debug mode:               False
21.04.2018 15:23:42 INFO    Reduced training sample size from 9999997 to 200000 (factor 50)
21.04.2018 15:23:57 INFO    Starting training
2018-04-21 15:23:58.322210: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 15:23:58.322252: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 15:23:58.322259: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 15:23:58.322264: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 15:23:58.322268: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 15:23:58.621846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-21 15:23:58.621883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-21 15:23:58.621889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-21 15:23:58.621897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 00510: early stopping
21.04.2018 16:43:12 INFO    Starting evaluation
21.04.2018 16:45:23 INFO    Starting theta 100 / 1017
21.04.2018 16:47:30 INFO    Starting theta 200 / 1017
21.04.2018 16:49:38 INFO    Starting theta 300 / 1017
21.04.2018 16:51:45 INFO    Starting theta 400 / 1017
21.04.2018 16:53:53 INFO    Starting theta 500 / 1017
21.04.2018 16:56:00 INFO    Starting theta 600 / 1017
21.04.2018 16:58:07 INFO    Starting theta 700 / 1017
21.04.2018 17:00:15 INFO    Starting theta 800 / 1017
21.04.2018 17:02:22 INFO    Starting theta 900 / 1017
21.04.2018 17:04:29 INFO    Starting theta 1000 / 1017
21.04.2018 17:04:52 INFO    Evaluation timing: median 1.26244807243 s, mean 1.26303196258 s
21.04.2018 17:04:52 INFO    Starting roaming
21.04.2018 17:05:18 INFO    Starting calibrated evaluation and roaming
21.04.2018 18:33:20 INFO    Starting theta 100 / 1017
21.04.2018 20:01:59 INFO    Starting theta 200 / 1017
21.04.2018 21:30:41 INFO    Starting theta 300 / 1017
21.04.2018 22:59:24 INFO    Starting theta 400 / 1017
22.04.2018 00:28:16 INFO    Starting theta 500 / 1017
22.04.2018 01:57:01 INFO    Starting theta 600 / 1017
22.04.2018 03:25:44 INFO    Starting theta 700 / 1017
22.04.2018 04:54:20 INFO    Starting theta 800 / 1017
22.04.2018 06:23:01 INFO    Starting theta 900 / 1017
22.04.2018 07:51:43 INFO    Starting theta 1000 / 1017
22.04.2018 08:07:41 INFO    Calibrated evaluation timing: median 1.27099990845 s, mean 1.27144235589 s
22.04.2018 08:07:41 INFO    Interpolating calibrated roaming
22.04.2018 08:12:48 INFO    That's it -- have a great day!
Using TensorFlow backend.
22.04.2018 08:12:51 INFO    Hi! How are you today?
22.04.2018 08:12:51 INFO    Startup options:
22.04.2018 08:12:51 INFO      Algorithm:                     carl
22.04.2018 08:12:51 INFO      Point by point:                False
22.04.2018 08:12:51 INFO      Morphing-aware mode:           False
22.04.2018 08:12:51 INFO      Smeared data:                  False
22.04.2018 08:12:51 INFO      Training sample:               baseline
22.04.2018 08:12:51 INFO      alpha:                         None
22.04.2018 08:12:51 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
22.04.2018 08:12:51 INFO      AFC epsilon:                   None
22.04.2018 08:12:51 INFO      Denominator theta:             False
22.04.2018 08:12:51 INFO      Neyman construction toys:      0
22.04.2018 08:12:51 INFO      Training sample size limit:    500000
22.04.2018 08:12:51 INFO      Other options:                 ['shallow']
22.04.2018 08:12:51 INFO      Base directory:                /home/jb6504/higgs_inference
22.04.2018 08:12:51 INFO      ML-based strategies available: True
22.04.2018 08:12:51 INFO    Starting parameterized inference
22.04.2018 08:12:51 INFO    Main settings:
22.04.2018 08:12:51 INFO      Algorithm:                carl
22.04.2018 08:12:51 INFO      Morphing-aware:           False
22.04.2018 08:12:51 INFO      Training sample:          baseline
22.04.2018 08:12:51 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
22.04.2018 08:12:51 INFO    Options:
22.04.2018 08:12:51 INFO      Number of hidden layers:  2
22.04.2018 08:12:51 INFO      Batch size:               128
22.04.2018 08:12:51 INFO      Learning rate:            0.001
22.04.2018 08:12:51 INFO      Learning rate decay:      0.00460517018599
22.04.2018 08:12:51 INFO      Number of epochs:         1000
22.04.2018 08:12:51 INFO      Training samples:         500000
22.04.2018 08:12:51 INFO      NC experiments:           False
22.04.2018 08:12:51 INFO      Debug mode:               False
22.04.2018 08:13:15 INFO    Reduced training sample size from 9999997 to 500000 (factor 20)
22.04.2018 08:13:30 INFO    Starting training
2018-04-22 08:13:31.027411: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 08:13:31.027449: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 08:13:31.027454: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 08:13:31.027458: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 08:13:31.027462: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 08:13:31.326848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-22 08:13:31.326883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-22 08:13:31.326889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-22 08:13:31.326898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 00214: early stopping
22.04.2018 09:32:36 INFO    Starting evaluation
22.04.2018 09:34:45 INFO    Starting theta 100 / 1017
22.04.2018 09:36:51 INFO    Starting theta 200 / 1017
22.04.2018 09:38:57 INFO    Starting theta 300 / 1017
22.04.2018 09:41:02 INFO    Starting theta 400 / 1017
22.04.2018 09:43:08 INFO    Starting theta 500 / 1017
22.04.2018 09:45:13 INFO    Starting theta 600 / 1017
22.04.2018 09:47:19 INFO    Starting theta 700 / 1017
22.04.2018 09:49:25 INFO    Starting theta 800 / 1017
22.04.2018 09:51:31 INFO    Starting theta 900 / 1017
22.04.2018 09:53:37 INFO    Starting theta 1000 / 1017
22.04.2018 09:53:59 INFO    Evaluation timing: median 1.24555683136 s, mean 1.24674206849 s
22.04.2018 09:53:59 INFO    Starting roaming
22.04.2018 09:54:25 INFO    Starting calibrated evaluation and roaming
22.04.2018 11:20:55 INFO    Starting theta 100 / 1017
22.04.2018 12:48:03 INFO    Starting theta 200 / 1017
22.04.2018 14:15:28 INFO    Starting theta 300 / 1017
22.04.2018 15:43:36 INFO    Starting theta 400 / 1017
22.04.2018 17:10:46 INFO    Starting theta 500 / 1017
22.04.2018 18:37:54 INFO    Starting theta 600 / 1017
22.04.2018 20:04:52 INFO    Starting theta 700 / 1017
22.04.2018 21:31:48 INFO    Starting theta 800 / 1017
22.04.2018 22:59:03 INFO    Starting theta 900 / 1017
23.04.2018 00:26:26 INFO    Starting theta 1000 / 1017
23.04.2018 00:42:09 INFO    Calibrated evaluation timing: median 1.24862480164 s, mean 1.24997715495 s
23.04.2018 00:42:09 INFO    Interpolating calibrated roaming
23.04.2018 00:47:24 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 00:47:26 INFO    Hi! How are you today?
23.04.2018 00:47:26 INFO    Startup options:
23.04.2018 00:47:26 INFO      Algorithm:                     carl
23.04.2018 00:47:26 INFO      Point by point:                False
23.04.2018 00:47:26 INFO      Morphing-aware mode:           False
23.04.2018 00:47:26 INFO      Smeared data:                  False
23.04.2018 00:47:26 INFO      Training sample:               baseline
23.04.2018 00:47:26 INFO      alpha:                         None
23.04.2018 00:47:26 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 00:47:26 INFO      AFC epsilon:                   None
23.04.2018 00:47:26 INFO      Denominator theta:             False
23.04.2018 00:47:26 INFO      Neyman construction toys:      0
23.04.2018 00:47:26 INFO      Training sample size limit:    1000000
23.04.2018 00:47:26 INFO      Other options:                 ['shallow']
23.04.2018 00:47:26 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 00:47:26 INFO      ML-based strategies available: True
23.04.2018 00:47:26 INFO    Starting parameterized inference
23.04.2018 00:47:26 INFO    Main settings:
23.04.2018 00:47:26 INFO      Algorithm:                carl
23.04.2018 00:47:26 INFO      Morphing-aware:           False
23.04.2018 00:47:26 INFO      Training sample:          baseline
23.04.2018 00:47:26 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 00:47:26 INFO    Options:
23.04.2018 00:47:26 INFO      Number of hidden layers:  2
23.04.2018 00:47:26 INFO      Batch size:               128
23.04.2018 00:47:26 INFO      Learning rate:            0.001
23.04.2018 00:47:26 INFO      Learning rate decay:      0.00921034037198
23.04.2018 00:47:26 INFO      Number of epochs:         500
23.04.2018 00:47:26 INFO      Training samples:         1000000
23.04.2018 00:47:26 INFO      NC experiments:           False
23.04.2018 00:47:26 INFO      Debug mode:               False
23.04.2018 00:47:46 INFO    Reduced training sample size from 9999997 to 1000000 (factor 10)
23.04.2018 00:48:02 INFO    Starting training
2018-04-23 00:48:03.042231: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 00:48:03.042306: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 00:48:03.042312: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 00:48:03.042316: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 00:48:03.042326: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 00:48:03.338791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-23 00:48:03.338829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 00:48:03.338835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 00:48:03.338844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 00111: early stopping
23.04.2018 02:10:14 INFO    Starting evaluation
23.04.2018 02:12:22 INFO    Starting theta 100 / 1017
23.04.2018 02:14:27 INFO    Starting theta 200 / 1017
23.04.2018 02:16:31 INFO    Starting theta 300 / 1017
23.04.2018 02:18:36 INFO    Starting theta 400 / 1017
23.04.2018 02:20:40 INFO    Starting theta 500 / 1017
23.04.2018 02:22:44 INFO    Starting theta 600 / 1017
23.04.2018 02:24:48 INFO    Starting theta 700 / 1017
23.04.2018 02:26:53 INFO    Starting theta 800 / 1017
23.04.2018 02:28:57 INFO    Starting theta 900 / 1017
23.04.2018 02:31:02 INFO    Starting theta 1000 / 1017
23.04.2018 02:31:25 INFO    Evaluation timing: median 1.23206186295 s, mean 1.2334421539 s
23.04.2018 02:31:25 INFO    Starting roaming
23.04.2018 02:31:50 INFO    Starting calibrated evaluation and roaming
23.04.2018 03:57:39 INFO    Starting theta 100 / 1017
23.04.2018 05:24:15 INFO    Starting theta 200 / 1017
23.04.2018 06:50:43 INFO    Starting theta 300 / 1017
23.04.2018 08:17:08 INFO    Starting theta 400 / 1017
23.04.2018 09:43:43 INFO    Starting theta 500 / 1017
23.04.2018 11:10:23 INFO    Starting theta 600 / 1017
23.04.2018 12:37:01 INFO    Starting theta 700 / 1017
23.04.2018 14:03:26 INFO    Starting theta 800 / 1017
23.04.2018 15:29:55 INFO    Starting theta 900 / 1017
23.04.2018 16:56:22 INFO    Starting theta 1000 / 1017
23.04.2018 17:11:54 INFO    Calibrated evaluation timing: median 1.23987197876 s, mean 1.24013750344 s
23.04.2018 17:11:54 INFO    Interpolating calibrated roaming
23.04.2018 17:16:46 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 17:16:48 INFO    Hi! How are you today?
23.04.2018 17:16:48 INFO    Startup options:
23.04.2018 17:16:48 INFO      Algorithm:                     carl
23.04.2018 17:16:48 INFO      Point by point:                False
23.04.2018 17:16:48 INFO      Morphing-aware mode:           False
23.04.2018 17:16:48 INFO      Smeared data:                  False
23.04.2018 17:16:48 INFO      Training sample:               baseline
23.04.2018 17:16:48 INFO      alpha:                         None
23.04.2018 17:16:48 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 17:16:48 INFO      AFC epsilon:                   None
23.04.2018 17:16:48 INFO      Denominator theta:             False
23.04.2018 17:16:48 INFO      Neyman construction toys:      0
23.04.2018 17:16:48 INFO      Training sample size limit:    2000000
23.04.2018 17:16:48 INFO      Other options:                 ['shallow']
23.04.2018 17:16:48 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 17:16:48 INFO      ML-based strategies available: True
23.04.2018 17:16:48 INFO    Starting parameterized inference
23.04.2018 17:16:48 INFO    Main settings:
23.04.2018 17:16:48 INFO      Algorithm:                carl
23.04.2018 17:16:48 INFO      Morphing-aware:           False
23.04.2018 17:16:48 INFO      Training sample:          baseline
23.04.2018 17:16:48 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 17:16:48 INFO    Options:
23.04.2018 17:16:48 INFO      Number of hidden layers:  2
23.04.2018 17:16:48 INFO      Batch size:               128
23.04.2018 17:16:48 INFO      Learning rate:            0.001
23.04.2018 17:16:48 INFO      Learning rate decay:      0.018420680744
23.04.2018 17:16:48 INFO      Number of epochs:         250
23.04.2018 17:16:48 INFO      Training samples:         2000000
23.04.2018 17:16:48 INFO      NC experiments:           False
23.04.2018 17:16:48 INFO      Debug mode:               False
23.04.2018 17:17:10 INFO    Reduced training sample size from 9999997 to 2000000 (factor 5)
23.04.2018 17:17:28 INFO    Starting training
2018-04-23 17:17:29.018162: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 17:17:29.018199: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 17:17:29.018205: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 17:17:29.018209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 17:17:29.018213: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 17:17:29.311026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-23 17:17:29.311062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 17:17:29.311068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 17:17:29.311077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 00058: early stopping
23.04.2018 18:44:12 INFO    Starting evaluation
23.04.2018 18:46:24 INFO    Starting theta 100 / 1017
23.04.2018 18:48:31 INFO    Starting theta 200 / 1017
23.04.2018 18:50:38 INFO    Starting theta 300 / 1017
23.04.2018 18:52:46 INFO    Starting theta 400 / 1017
23.04.2018 18:54:53 INFO    Starting theta 500 / 1017
23.04.2018 18:57:00 INFO    Starting theta 600 / 1017
23.04.2018 18:59:08 INFO    Starting theta 700 / 1017
23.04.2018 19:01:15 INFO    Starting theta 800 / 1017
23.04.2018 19:03:23 INFO    Starting theta 900 / 1017
23.04.2018 19:05:31 INFO    Starting theta 1000 / 1017
23.04.2018 19:05:54 INFO    Evaluation timing: median 1.26302790642 s, mean 1.26386600563 s
23.04.2018 19:05:54 INFO    Starting roaming
23.04.2018 19:06:19 INFO    Starting calibrated evaluation and roaming
23.04.2018 20:34:16 INFO    Starting theta 100 / 1017
23.04.2018 22:03:04 INFO    Starting theta 200 / 1017
23.04.2018 23:31:52 INFO    Starting theta 300 / 1017
24.04.2018 01:00:40 INFO    Starting theta 400 / 1017
24.04.2018 02:29:29 INFO    Starting theta 500 / 1017
24.04.2018 03:58:24 INFO    Starting theta 600 / 1017
24.04.2018 05:27:19 INFO    Starting theta 700 / 1017
24.04.2018 06:56:08 INFO    Starting theta 800 / 1017
24.04.2018 08:25:00 INFO    Starting theta 900 / 1017
24.04.2018 09:53:54 INFO    Starting theta 1000 / 1017
24.04.2018 10:09:56 INFO    Calibrated evaluation timing: median 1.27073502541 s, mean 1.27091761958 s
24.04.2018 10:09:56 INFO    Interpolating calibrated roaming
24.04.2018 10:15:02 INFO    That's it -- have a great day!
Using TensorFlow backend.
24.04.2018 10:15:04 INFO    Hi! How are you today?
24.04.2018 10:15:04 INFO    Startup options:
24.04.2018 10:15:04 INFO      Algorithm:                     carl
24.04.2018 10:15:04 INFO      Point by point:                False
24.04.2018 10:15:04 INFO      Morphing-aware mode:           False
24.04.2018 10:15:04 INFO      Smeared data:                  False
24.04.2018 10:15:04 INFO      Training sample:               baseline
24.04.2018 10:15:04 INFO      alpha:                         None
24.04.2018 10:15:04 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
24.04.2018 10:15:04 INFO      AFC epsilon:                   None
24.04.2018 10:15:04 INFO      Denominator theta:             False
24.04.2018 10:15:04 INFO      Neyman construction toys:      0
24.04.2018 10:15:04 INFO      Training sample size limit:    5000000
24.04.2018 10:15:04 INFO      Other options:                 ['shallow']
24.04.2018 10:15:04 INFO      Base directory:                /home/jb6504/higgs_inference
24.04.2018 10:15:04 INFO      ML-based strategies available: True
24.04.2018 10:15:04 INFO    Starting parameterized inference
24.04.2018 10:15:04 INFO    Main settings:
24.04.2018 10:15:04 INFO      Algorithm:                carl
24.04.2018 10:15:04 INFO      Morphing-aware:           False
24.04.2018 10:15:04 INFO      Training sample:          baseline
24.04.2018 10:15:04 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
24.04.2018 10:15:04 INFO    Options:
24.04.2018 10:15:04 INFO      Number of hidden layers:  2
24.04.2018 10:15:04 INFO      Batch size:               128
24.04.2018 10:15:04 INFO      Learning rate:            0.001
24.04.2018 10:15:04 INFO      Learning rate decay:      0.0460517018599
24.04.2018 10:15:04 INFO      Number of epochs:         100
24.04.2018 10:15:04 INFO      Training samples:         5000000
24.04.2018 10:15:04 INFO      NC experiments:           False
24.04.2018 10:15:04 INFO      Debug mode:               False
24.04.2018 10:15:25 INFO    Reduced training sample size from 9999997 to 5000000 (factor 2)
24.04.2018 10:15:49 INFO    Starting training
2018-04-24 10:15:50.346876: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 10:15:50.346915: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 10:15:50.346921: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 10:15:50.346925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 10:15:50.346929: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-24 10:15:50.641196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:84:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-04-24 10:15:50.641232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-24 10:15:50.641239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-24 10:15:50.641252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0)
Epoch 00060: early stopping
24.04.2018 13:54:00 INFO    Starting evaluation
24.04.2018 13:56:09 INFO    Starting theta 100 / 1017
24.04.2018 13:58:15 INFO    Starting theta 200 / 1017
24.04.2018 14:00:20 INFO    Starting theta 300 / 1017
24.04.2018 14:02:25 INFO    Starting theta 400 / 1017
24.04.2018 14:04:30 INFO    Starting theta 500 / 1017
24.04.2018 14:06:35 INFO    Starting theta 600 / 1017
24.04.2018 14:08:40 INFO    Starting theta 700 / 1017
24.04.2018 14:10:45 INFO    Starting theta 800 / 1017
24.04.2018 14:12:50 INFO    Starting theta 900 / 1017
24.04.2018 14:14:55 INFO    Starting theta 1000 / 1017
24.04.2018 14:15:17 INFO    Evaluation timing: median 1.23907518387 s, mean 1.24015470803 s
24.04.2018 14:15:17 INFO    Starting roaming
24.04.2018 14:15:43 INFO    Starting calibrated evaluation and roaming
24.04.2018 15:41:58 INFO    Starting theta 100 / 1017
24.04.2018 17:08:59 INFO    Starting theta 200 / 1017
24.04.2018 18:35:56 INFO    Starting theta 300 / 1017
24.04.2018 20:02:52 INFO    Starting theta 400 / 1017
24.04.2018 21:30:01 INFO    Starting theta 500 / 1017
24.04.2018 22:57:39 INFO    Starting theta 600 / 1017
25.04.2018 00:25:06 INFO    Starting theta 700 / 1017
25.04.2018 01:52:23 INFO    Starting theta 800 / 1017
25.04.2018 03:19:45 INFO    Starting theta 900 / 1017
25.04.2018 04:46:53 INFO    Starting theta 1000 / 1017
25.04.2018 05:02:35 INFO    Calibrated evaluation timing: median 1.24644589424 s, mean 1.24730182093 s
25.04.2018 05:02:35 INFO    Interpolating calibrated roaming
25.04.2018 05:08:28 INFO    That's it -- have a great day!
