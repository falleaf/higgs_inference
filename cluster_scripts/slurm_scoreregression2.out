Using TensorFlow backend.
06.03.2018 00:34:48 INFO    Hi! How are you today?
06.03.2018 00:34:48 INFO    Startup options:
06.03.2018 00:34:48 INFO      Algorithm:                     scoreregression
06.03.2018 00:34:48 INFO      Point by point:                False
06.03.2018 00:34:48 INFO      Morphing-aware mode:           False
06.03.2018 00:34:48 INFO      Smeared data:                  False
06.03.2018 00:34:48 INFO      Training sample:               baseline
06.03.2018 00:34:48 INFO      alpha:                         None
06.03.2018 00:34:48 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
06.03.2018 00:34:48 INFO      AFC epsilon:                   None
06.03.2018 00:34:48 INFO      Neyman construction toys:      True
06.03.2018 00:34:48 INFO      Other options:                 ['deep', 'new']
06.03.2018 00:34:48 INFO      Base directory:                /home/jb6504/higgs_inference
06.03.2018 00:34:48 INFO      ML-based strategies available: True
06.03.2018 00:34:48 INFO    Starting score regression inference
06.03.2018 00:34:48 INFO    Options:
06.03.2018 00:34:48 INFO      Number of hidden layers: 5
06.03.2018 00:34:48 INFO      Batch size:              128
06.03.2018 00:34:48 INFO      Learning rate:           0.001
06.03.2018 00:34:48 INFO      Learning rate decay:     0.0921034037198
06.03.2018 00:34:48 INFO      Number of epochs:        50
06.03.2018 00:35:14 INFO    Starting training of score regression
Train on 8000000 samples, validate on 2000000 samples
2018-03-06 00:35:14.665511: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-06 00:35:14.665863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-06 00:35:14.665872: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-03-06 00:35:14.665877: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-06 00:35:14.665881: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-03-06 00:35:14.959878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
2018-03-06 00:35:14.959913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-03-06 00:35:14.959920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-03-06 00:35:14.959928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0)
Epoch 1/50
344s - loss: 0.0628 - val_loss: 0.0402
Epoch 2/50
344s - loss: 0.0385 - val_loss: 0.0316
Epoch 3/50
344s - loss: 0.0334 - val_loss: 0.0305
Epoch 4/50
343s - loss: 0.0285 - val_loss: 0.0169
Epoch 5/50
343s - loss: 0.0239 - val_loss: 0.0186
Epoch 6/50
344s - loss: 0.0210 - val_loss: 0.0139
Epoch 7/50
344s - loss: 0.0183 - val_loss: 0.0181
Epoch 8/50
344s - loss: 0.0171 - val_loss: 0.0104
Epoch 9/50
344s - loss: 0.0150 - val_loss: 0.0128
Epoch 10/50
344s - loss: 0.0133 - val_loss: 0.0089
Epoch 11/50
345s - loss: 0.0125 - val_loss: 0.0093
Epoch 12/50
345s - loss: 0.0113 - val_loss: 0.0064
Epoch 13/50
345s - loss: 0.0102 - val_loss: 0.0070
Epoch 14/50
345s - loss: 0.0094 - val_loss: 0.0062
Epoch 15/50
345s - loss: 0.0086 - val_loss: 0.0052
Epoch 16/50
345s - loss: 0.0081 - val_loss: 0.0052
Epoch 17/50
345s - loss: 0.0077 - val_loss: 0.0044
Epoch 18/50
345s - loss: 0.0072 - val_loss: 0.0048
Epoch 19/50
345s - loss: 0.0069 - val_loss: 0.0047
Epoch 20/50
345s - loss: 0.0066 - val_loss: 0.0043
Epoch 21/50
345s - loss: 0.0063 - val_loss: 0.0048
Epoch 22/50
345s - loss: 0.0061 - val_loss: 0.0042
Epoch 23/50
345s - loss: 0.0059 - val_loss: 0.0040
Epoch 24/50
345s - loss: 0.0057 - val_loss: 0.0041
Epoch 25/50
345s - loss: 0.0056 - val_loss: 0.0033
Epoch 26/50
345s - loss: 0.0054 - val_loss: 0.0031
Epoch 27/50
345s - loss: 0.0054 - val_loss: 0.0034
Epoch 28/50
345s - loss: 0.0052 - val_loss: 0.0030
Epoch 29/50
345s - loss: 0.0051 - val_loss: 0.0029
Epoch 30/50
345s - loss: 0.0050 - val_loss: 0.0032
Epoch 31/50
345s - loss: 0.0049 - val_loss: 0.0029
Epoch 32/50
345s - loss: 0.0048 - val_loss: 0.0030
Epoch 33/50
345s - loss: 0.0048 - val_loss: 0.0030
Epoch 34/50
345s - loss: 0.0047 - val_loss: 0.0035
Epoch 35/50
345s - loss: 0.0046 - val_loss: 0.0035
Epoch 36/50
345s - loss: 0.0046 - val_loss: 0.0035
Epoch 37/50
345s - loss: 0.0045 - val_loss: 0.0035
Epoch 38/50
345s - loss: 0.0045 - val_loss: 0.0035
Epoch 39/50
345s - loss: 0.0045 - val_loss: 0.0035
Epoch 40/50
345s - loss: 0.0044 - val_loss: 0.0038
Epoch 00039: early stopping
06.03.2018 04:25:19 INFO    Starting evaluation
06.03.2018 04:25:25 INFO    Starting density estimation
06.03.2018 09:15:46 INFO    Starting theta 100 / 1017
06.03.2018 13:24:47 INFO    Starting theta 200 / 1017
06.03.2018 16:37:29 INFO    Starting theta 300 / 1017
06.03.2018 20:06:23 INFO    Starting theta 400 / 1017
07.03.2018 00:07:46 INFO    Starting theta 500 / 1017
07.03.2018 03:40:13 INFO    Starting theta 600 / 1017
07.03.2018 06:52:05 INFO    Starting theta 700 / 1017
