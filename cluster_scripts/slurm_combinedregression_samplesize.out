Using TensorFlow backend.
19.04.2018 10:42:42 INFO    Hi! How are you today?
19.04.2018 10:42:42 INFO    Startup options:
19.04.2018 10:42:42 INFO      Algorithm:                     combinedregression
19.04.2018 10:42:42 INFO      Point by point:                False
19.04.2018 10:42:42 INFO      Morphing-aware mode:           False
19.04.2018 10:42:42 INFO      Smeared data:                  False
19.04.2018 10:42:42 INFO      Training sample:               baseline
19.04.2018 10:42:42 INFO      alpha:                         None
19.04.2018 10:42:42 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
19.04.2018 10:42:42 INFO      AFC epsilon:                   None
19.04.2018 10:42:42 INFO      Denominator theta:             False
19.04.2018 10:42:42 INFO      Neyman construction toys:      0
19.04.2018 10:42:42 INFO      Training sample size limit:    1000
19.04.2018 10:42:42 INFO      Other options:                 ['deep']
19.04.2018 10:42:42 INFO      Base directory:                /home/jb6504/higgs_inference
19.04.2018 10:42:42 INFO      ML-based strategies available: True
19.04.2018 10:42:42 INFO    Starting parameterized inference
19.04.2018 10:42:42 INFO    Main settings:
19.04.2018 10:42:42 INFO      Algorithm:                combinedregression
19.04.2018 10:42:42 INFO      Morphing-aware:           False
19.04.2018 10:42:42 INFO      Training sample:          baseline
19.04.2018 10:42:42 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
19.04.2018 10:42:42 INFO    Options:
19.04.2018 10:42:42 INFO      Number of hidden layers:  5
19.04.2018 10:42:42 INFO      alpha:                    100.0
19.04.2018 10:42:42 INFO      Batch size:               128
19.04.2018 10:42:42 INFO      Learning rate:            0.001
19.04.2018 10:42:42 INFO      Learning rate decay:      9.21034037198e-06
19.04.2018 10:42:42 INFO      Number of epochs:         500000
19.04.2018 10:42:42 INFO      Training samples:         1000
19.04.2018 10:42:42 INFO      NC experiments:           False
19.04.2018 10:42:42 INFO      Debug mode:               False
19.04.2018 10:43:09 INFO    Reduced training sample size from 9999997 to 1000 (factor 10000)
19.04.2018 10:43:23 INFO    Starting training
2018-04-19 10:43:23.764734: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:43:23.764769: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:43:23.764774: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:43:23.764778: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:43:23.764782: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-19 10:43:24.070485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-19 10:43:24.070521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-19 10:43:24.070526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-19 10:43:24.070534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 185060: early stopping
19.04.2018 14:05:13 INFO    Starting evaluation
19.04.2018 14:07:08 INFO    Starting theta 100 / 1017
19.04.2018 14:09:00 INFO    Starting theta 200 / 1017
19.04.2018 14:10:52 INFO    Starting theta 300 / 1017
19.04.2018 14:12:45 INFO    Starting theta 400 / 1017
19.04.2018 14:14:37 INFO    Starting theta 500 / 1017
19.04.2018 14:16:29 INFO    Starting theta 600 / 1017
19.04.2018 14:18:21 INFO    Starting theta 700 / 1017
19.04.2018 14:20:14 INFO    Starting theta 800 / 1017
19.04.2018 14:22:06 INFO    Starting theta 900 / 1017
19.04.2018 14:23:59 INFO    Starting theta 1000 / 1017
19.04.2018 14:24:19 INFO    Evaluation timing: median 1.10672593117 s, mean 1.11187414293 s
19.04.2018 14:24:19 INFO    Starting roaming
19.04.2018 14:24:42 INFO    Starting calibrated evaluation and roaming
19.04.2018 15:42:05 INFO    Starting theta 100 / 1017
19.04.2018 17:00:08 INFO    Starting theta 200 / 1017
19.04.2018 18:18:10 INFO    Starting theta 300 / 1017
19.04.2018 19:36:11 INFO    Starting theta 400 / 1017
19.04.2018 20:53:41 INFO    Starting theta 500 / 1017
19.04.2018 22:11:09 INFO    Starting theta 600 / 1017
19.04.2018 23:28:42 INFO    Starting theta 700 / 1017
20.04.2018 00:46:17 INFO    Starting theta 800 / 1017
20.04.2018 02:04:22 INFO    Starting theta 900 / 1017
20.04.2018 03:21:55 INFO    Starting theta 1000 / 1017
20.04.2018 03:35:52 INFO    Calibrated evaluation timing: median 1.10331916809 s, mean 1.10864051183 s
20.04.2018 03:35:52 INFO    Interpolating calibrated roaming
20.04.2018 03:41:00 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 03:41:03 INFO    Hi! How are you today?
20.04.2018 03:41:03 INFO    Startup options:
20.04.2018 03:41:03 INFO      Algorithm:                     combinedregression
20.04.2018 03:41:03 INFO      Point by point:                False
20.04.2018 03:41:03 INFO      Morphing-aware mode:           False
20.04.2018 03:41:03 INFO      Smeared data:                  False
20.04.2018 03:41:03 INFO      Training sample:               baseline
20.04.2018 03:41:03 INFO      alpha:                         None
20.04.2018 03:41:03 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 03:41:03 INFO      AFC epsilon:                   None
20.04.2018 03:41:03 INFO      Denominator theta:             False
20.04.2018 03:41:03 INFO      Neyman construction toys:      0
20.04.2018 03:41:03 INFO      Training sample size limit:    2000
20.04.2018 03:41:03 INFO      Other options:                 ['deep']
20.04.2018 03:41:03 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 03:41:03 INFO      ML-based strategies available: True
20.04.2018 03:41:03 INFO    Starting parameterized inference
20.04.2018 03:41:03 INFO    Main settings:
20.04.2018 03:41:03 INFO      Algorithm:                combinedregression
20.04.2018 03:41:03 INFO      Morphing-aware:           False
20.04.2018 03:41:03 INFO      Training sample:          baseline
20.04.2018 03:41:03 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 03:41:03 INFO    Options:
20.04.2018 03:41:03 INFO      Number of hidden layers:  5
20.04.2018 03:41:03 INFO      alpha:                    100.0
20.04.2018 03:41:03 INFO      Batch size:               128
20.04.2018 03:41:03 INFO      Learning rate:            0.001
20.04.2018 03:41:03 INFO      Learning rate decay:      1.8420680744e-05
20.04.2018 03:41:03 INFO      Number of epochs:         250000
20.04.2018 03:41:03 INFO      Training samples:         2000
20.04.2018 03:41:03 INFO      NC experiments:           False
20.04.2018 03:41:03 INFO      Debug mode:               False
20.04.2018 03:41:23 INFO    Reduced training sample size from 9999997 to 2000 (factor 5000)
20.04.2018 03:41:37 INFO    Starting training
2018-04-20 03:41:37.662786: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:41:37.663024: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:41:37.663036: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:41:37.663040: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:41:37.663044: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 03:41:37.967139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-20 03:41:37.967172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 03:41:37.967178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 03:41:37.967185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 50041: early stopping
20.04.2018 05:19:50 INFO    Starting evaluation
20.04.2018 05:21:48 INFO    Starting theta 100 / 1017
20.04.2018 05:23:42 INFO    Starting theta 200 / 1017
20.04.2018 05:25:36 INFO    Starting theta 300 / 1017
20.04.2018 05:27:30 INFO    Starting theta 400 / 1017
20.04.2018 05:29:24 INFO    Starting theta 500 / 1017
20.04.2018 05:31:18 INFO    Starting theta 600 / 1017
20.04.2018 05:33:12 INFO    Starting theta 700 / 1017
20.04.2018 05:35:05 INFO    Starting theta 800 / 1017
20.04.2018 05:36:59 INFO    Starting theta 900 / 1017
20.04.2018 05:38:53 INFO    Starting theta 1000 / 1017
20.04.2018 05:39:14 INFO    Evaluation timing: median 1.12466192245 s, mean 1.12809781386 s
20.04.2018 05:39:14 INFO    Starting roaming
20.04.2018 05:39:37 INFO    Starting calibrated evaluation and roaming
20.04.2018 06:57:19 INFO    Starting theta 100 / 1017
20.04.2018 08:15:43 INFO    Starting theta 200 / 1017
20.04.2018 09:34:51 INFO    Starting theta 300 / 1017
20.04.2018 10:53:27 INFO    Starting theta 400 / 1017
20.04.2018 12:12:12 INFO    Starting theta 500 / 1017
20.04.2018 13:30:31 INFO    Starting theta 600 / 1017
20.04.2018 14:48:53 INFO    Starting theta 700 / 1017
20.04.2018 16:07:09 INFO    Starting theta 800 / 1017
20.04.2018 17:25:38 INFO    Starting theta 900 / 1017
20.04.2018 18:44:14 INFO    Starting theta 1000 / 1017
20.04.2018 18:58:20 INFO    Calibrated evaluation timing: median 1.11984610558 s, mean 1.12025401656 s
20.04.2018 18:58:20 INFO    Interpolating calibrated roaming
20.04.2018 19:03:54 INFO    That's it -- have a great day!
Using TensorFlow backend.
20.04.2018 19:03:57 INFO    Hi! How are you today?
20.04.2018 19:03:57 INFO    Startup options:
20.04.2018 19:03:57 INFO      Algorithm:                     combinedregression
20.04.2018 19:03:57 INFO      Point by point:                False
20.04.2018 19:03:57 INFO      Morphing-aware mode:           False
20.04.2018 19:03:57 INFO      Smeared data:                  False
20.04.2018 19:03:57 INFO      Training sample:               baseline
20.04.2018 19:03:57 INFO      alpha:                         None
20.04.2018 19:03:57 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
20.04.2018 19:03:57 INFO      AFC epsilon:                   None
20.04.2018 19:03:57 INFO      Denominator theta:             False
20.04.2018 19:03:57 INFO      Neyman construction toys:      0
20.04.2018 19:03:57 INFO      Training sample size limit:    5000
20.04.2018 19:03:57 INFO      Other options:                 ['deep']
20.04.2018 19:03:57 INFO      Base directory:                /home/jb6504/higgs_inference
20.04.2018 19:03:57 INFO      ML-based strategies available: True
20.04.2018 19:03:57 INFO    Starting parameterized inference
20.04.2018 19:03:57 INFO    Main settings:
20.04.2018 19:03:57 INFO      Algorithm:                combinedregression
20.04.2018 19:03:57 INFO      Morphing-aware:           False
20.04.2018 19:03:57 INFO      Training sample:          baseline
20.04.2018 19:03:57 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
20.04.2018 19:03:57 INFO    Options:
20.04.2018 19:03:57 INFO      Number of hidden layers:  5
20.04.2018 19:03:57 INFO      alpha:                    100.0
20.04.2018 19:03:57 INFO      Batch size:               128
20.04.2018 19:03:57 INFO      Learning rate:            0.001
20.04.2018 19:03:57 INFO      Learning rate decay:      4.60517018599e-05
20.04.2018 19:03:57 INFO      Number of epochs:         100000
20.04.2018 19:03:57 INFO      Training samples:         5000
20.04.2018 19:03:57 INFO      NC experiments:           False
20.04.2018 19:03:57 INFO      Debug mode:               False
20.04.2018 19:04:20 INFO    Reduced training sample size from 9999997 to 5000 (factor 2000)
20.04.2018 19:04:34 INFO    Starting training
2018-04-20 19:04:35.166716: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:04:35.166747: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:04:35.166752: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:04:35.166756: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:04:35.166760: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-20 19:04:35.487167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-20 19:04:35.487201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-20 19:04:35.487207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-20 19:04:35.487217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 22106: early stopping
20.04.2018 20:55:09 INFO    Starting evaluation
20.04.2018 20:57:07 INFO    Starting theta 100 / 1017
20.04.2018 20:59:01 INFO    Starting theta 200 / 1017
20.04.2018 21:00:55 INFO    Starting theta 300 / 1017
20.04.2018 21:02:49 INFO    Starting theta 400 / 1017
20.04.2018 21:04:45 INFO    Starting theta 500 / 1017
20.04.2018 21:06:39 INFO    Starting theta 600 / 1017
20.04.2018 21:08:33 INFO    Starting theta 700 / 1017
20.04.2018 21:10:26 INFO    Starting theta 800 / 1017
20.04.2018 21:12:21 INFO    Starting theta 900 / 1017
20.04.2018 21:14:16 INFO    Starting theta 1000 / 1017
20.04.2018 21:14:37 INFO    Evaluation timing: median 1.13032913208 s, mean 1.13191584054 s
20.04.2018 21:14:37 INFO    Starting roaming
20.04.2018 21:15:00 INFO    Starting calibrated evaluation and roaming
20.04.2018 22:33:59 INFO    Starting theta 100 / 1017
20.04.2018 23:53:41 INFO    Starting theta 200 / 1017
21.04.2018 01:13:57 INFO    Starting theta 300 / 1017
21.04.2018 02:33:39 INFO    Starting theta 400 / 1017
21.04.2018 03:53:17 INFO    Starting theta 500 / 1017
21.04.2018 05:12:46 INFO    Starting theta 600 / 1017
21.04.2018 06:32:17 INFO    Starting theta 700 / 1017
21.04.2018 07:51:51 INFO    Starting theta 800 / 1017
21.04.2018 09:08:25 INFO    Starting theta 900 / 1017
21.04.2018 10:25:47 INFO    Starting theta 1000 / 1017
21.04.2018 10:39:44 INFO    Calibrated evaluation timing: median 1.13080310822 s, mean 1.12901252373 s
21.04.2018 10:39:44 INFO    Interpolating calibrated roaming
21.04.2018 10:45:09 INFO    That's it -- have a great day!
Using TensorFlow backend.
21.04.2018 10:45:12 INFO    Hi! How are you today?
21.04.2018 10:45:12 INFO    Startup options:
21.04.2018 10:45:12 INFO      Algorithm:                     combinedregression
21.04.2018 10:45:12 INFO      Point by point:                False
21.04.2018 10:45:12 INFO      Morphing-aware mode:           False
21.04.2018 10:45:12 INFO      Smeared data:                  False
21.04.2018 10:45:12 INFO      Training sample:               baseline
21.04.2018 10:45:12 INFO      alpha:                         None
21.04.2018 10:45:12 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
21.04.2018 10:45:12 INFO      AFC epsilon:                   None
21.04.2018 10:45:12 INFO      Denominator theta:             False
21.04.2018 10:45:12 INFO      Neyman construction toys:      0
21.04.2018 10:45:12 INFO      Training sample size limit:    10000
21.04.2018 10:45:12 INFO      Other options:                 ['deep']
21.04.2018 10:45:12 INFO      Base directory:                /home/jb6504/higgs_inference
21.04.2018 10:45:12 INFO      ML-based strategies available: True
21.04.2018 10:45:12 INFO    Starting parameterized inference
21.04.2018 10:45:12 INFO    Main settings:
21.04.2018 10:45:12 INFO      Algorithm:                combinedregression
21.04.2018 10:45:12 INFO      Morphing-aware:           False
21.04.2018 10:45:12 INFO      Training sample:          baseline
21.04.2018 10:45:12 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
21.04.2018 10:45:12 INFO    Options:
21.04.2018 10:45:12 INFO      Number of hidden layers:  5
21.04.2018 10:45:12 INFO      alpha:                    100.0
21.04.2018 10:45:12 INFO      Batch size:               128
21.04.2018 10:45:12 INFO      Learning rate:            0.001
21.04.2018 10:45:12 INFO      Learning rate decay:      9.21034037198e-05
21.04.2018 10:45:12 INFO      Number of epochs:         50000
21.04.2018 10:45:12 INFO      Training samples:         10000
21.04.2018 10:45:12 INFO      NC experiments:           False
21.04.2018 10:45:12 INFO      Debug mode:               False
21.04.2018 10:45:33 INFO    Reduced training sample size from 9999997 to 10000 (factor 1000)
21.04.2018 10:45:47 INFO    Starting training
2018-04-21 10:45:47.743175: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 10:45:47.743208: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 10:45:47.743213: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 10:45:47.743217: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 10:45:47.743221: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-21 10:45:48.073497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-21 10:45:48.073530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-21 10:45:48.073536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-21 10:45:48.073549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 11605: early stopping
21.04.2018 12:33:33 INFO    Starting evaluation
21.04.2018 12:35:25 INFO    Starting theta 100 / 1017
21.04.2018 12:37:14 INFO    Starting theta 200 / 1017
21.04.2018 12:39:02 INFO    Starting theta 300 / 1017
21.04.2018 12:40:50 INFO    Starting theta 400 / 1017
21.04.2018 12:42:37 INFO    Starting theta 500 / 1017
21.04.2018 12:44:24 INFO    Starting theta 600 / 1017
21.04.2018 12:46:11 INFO    Starting theta 700 / 1017
21.04.2018 12:47:58 INFO    Starting theta 800 / 1017
21.04.2018 12:49:46 INFO    Starting theta 900 / 1017
21.04.2018 12:51:33 INFO    Starting theta 1000 / 1017
21.04.2018 12:51:53 INFO    Evaluation timing: median 1.06133699417 s, mean 1.06817547011 s
21.04.2018 12:51:53 INFO    Starting roaming
21.04.2018 12:52:15 INFO    Starting calibrated evaluation and roaming
21.04.2018 14:06:42 INFO    Starting theta 100 / 1017
21.04.2018 15:21:51 INFO    Starting theta 200 / 1017
21.04.2018 16:37:00 INFO    Starting theta 300 / 1017
21.04.2018 17:52:12 INFO    Starting theta 400 / 1017
21.04.2018 19:07:21 INFO    Starting theta 500 / 1017
21.04.2018 20:22:25 INFO    Starting theta 600 / 1017
21.04.2018 21:38:56 INFO    Starting theta 700 / 1017
21.04.2018 22:57:48 INFO    Starting theta 800 / 1017
22.04.2018 00:16:40 INFO    Starting theta 900 / 1017
22.04.2018 01:36:06 INFO    Starting theta 1000 / 1017
22.04.2018 01:50:31 INFO    Calibrated evaluation timing: median 1.06906604767 s, mean 1.08989413884 s
22.04.2018 01:50:31 INFO    Interpolating calibrated roaming
22.04.2018 01:56:41 INFO    That's it -- have a great day!
Using TensorFlow backend.
22.04.2018 01:56:44 INFO    Hi! How are you today?
22.04.2018 01:56:44 INFO    Startup options:
22.04.2018 01:56:44 INFO      Algorithm:                     combinedregression
22.04.2018 01:56:44 INFO      Point by point:                False
22.04.2018 01:56:44 INFO      Morphing-aware mode:           False
22.04.2018 01:56:44 INFO      Smeared data:                  False
22.04.2018 01:56:44 INFO      Training sample:               baseline
22.04.2018 01:56:44 INFO      alpha:                         None
22.04.2018 01:56:44 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
22.04.2018 01:56:44 INFO      AFC epsilon:                   None
22.04.2018 01:56:44 INFO      Denominator theta:             False
22.04.2018 01:56:44 INFO      Neyman construction toys:      0
22.04.2018 01:56:44 INFO      Training sample size limit:    20000
22.04.2018 01:56:44 INFO      Other options:                 ['deep']
22.04.2018 01:56:44 INFO      Base directory:                /home/jb6504/higgs_inference
22.04.2018 01:56:44 INFO      ML-based strategies available: True
22.04.2018 01:56:44 INFO    Starting parameterized inference
22.04.2018 01:56:44 INFO    Main settings:
22.04.2018 01:56:44 INFO      Algorithm:                combinedregression
22.04.2018 01:56:44 INFO      Morphing-aware:           False
22.04.2018 01:56:44 INFO      Training sample:          baseline
22.04.2018 01:56:44 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
22.04.2018 01:56:44 INFO    Options:
22.04.2018 01:56:44 INFO      Number of hidden layers:  5
22.04.2018 01:56:44 INFO      alpha:                    100.0
22.04.2018 01:56:44 INFO      Batch size:               128
22.04.2018 01:56:44 INFO      Learning rate:            0.001
22.04.2018 01:56:44 INFO      Learning rate decay:      0.00018420680744
22.04.2018 01:56:44 INFO      Number of epochs:         25000
22.04.2018 01:56:44 INFO      Training samples:         20000
22.04.2018 01:56:44 INFO      NC experiments:           False
22.04.2018 01:56:44 INFO      Debug mode:               False
22.04.2018 01:57:09 INFO    Reduced training sample size from 9999997 to 20000 (factor 500)
22.04.2018 01:57:24 INFO    Starting training
2018-04-22 01:57:24.799302: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 01:57:24.799340: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 01:57:24.799346: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 01:57:24.799350: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 01:57:24.799354: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 01:57:25.126161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-22 01:57:25.126197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-22 01:57:25.126202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-22 01:57:25.126210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 06510: early stopping
22.04.2018 04:04:36 INFO    Starting evaluation
22.04.2018 04:06:35 INFO    Starting theta 100 / 1017
22.04.2018 04:08:29 INFO    Starting theta 200 / 1017
22.04.2018 04:10:24 INFO    Starting theta 300 / 1017
22.04.2018 04:12:19 INFO    Starting theta 400 / 1017
22.04.2018 04:14:13 INFO    Starting theta 500 / 1017
22.04.2018 04:16:08 INFO    Starting theta 600 / 1017
22.04.2018 04:18:03 INFO    Starting theta 700 / 1017
22.04.2018 04:19:57 INFO    Starting theta 800 / 1017
22.04.2018 04:21:52 INFO    Starting theta 900 / 1017
22.04.2018 04:23:47 INFO    Starting theta 1000 / 1017
22.04.2018 04:24:08 INFO    Evaluation timing: median 1.13676691055 s, mean 1.13584093405 s
22.04.2018 04:24:08 INFO    Starting roaming
22.04.2018 04:24:32 INFO    Starting calibrated evaluation and roaming
22.04.2018 05:43:05 INFO    Starting theta 100 / 1017
22.04.2018 07:02:04 INFO    Starting theta 200 / 1017
22.04.2018 08:20:52 INFO    Starting theta 300 / 1017
22.04.2018 09:39:48 INFO    Starting theta 400 / 1017
22.04.2018 10:58:42 INFO    Starting theta 500 / 1017
22.04.2018 12:17:45 INFO    Starting theta 600 / 1017
22.04.2018 13:35:09 INFO    Starting theta 700 / 1017
22.04.2018 14:50:38 INFO    Starting theta 800 / 1017
22.04.2018 16:06:42 INFO    Starting theta 900 / 1017
22.04.2018 17:23:24 INFO    Starting theta 1000 / 1017
22.04.2018 17:37:05 INFO    Calibrated evaluation timing: median 1.12236094475 s, mean 1.11195214074 s
22.04.2018 17:37:05 INFO    Interpolating calibrated roaming
22.04.2018 17:41:40 INFO    That's it -- have a great day!
Using TensorFlow backend.
22.04.2018 17:41:44 INFO    Hi! How are you today?
22.04.2018 17:41:44 INFO    Startup options:
22.04.2018 17:41:44 INFO      Algorithm:                     combinedregression
22.04.2018 17:41:44 INFO      Point by point:                False
22.04.2018 17:41:44 INFO      Morphing-aware mode:           False
22.04.2018 17:41:44 INFO      Smeared data:                  False
22.04.2018 17:41:44 INFO      Training sample:               baseline
22.04.2018 17:41:44 INFO      alpha:                         None
22.04.2018 17:41:44 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
22.04.2018 17:41:44 INFO      AFC epsilon:                   None
22.04.2018 17:41:44 INFO      Denominator theta:             False
22.04.2018 17:41:44 INFO      Neyman construction toys:      0
22.04.2018 17:41:44 INFO      Training sample size limit:    50000
22.04.2018 17:41:44 INFO      Other options:                 ['deep']
22.04.2018 17:41:44 INFO      Base directory:                /home/jb6504/higgs_inference
22.04.2018 17:41:44 INFO      ML-based strategies available: True
22.04.2018 17:41:44 INFO    Starting parameterized inference
22.04.2018 17:41:44 INFO    Main settings:
22.04.2018 17:41:44 INFO      Algorithm:                combinedregression
22.04.2018 17:41:44 INFO      Morphing-aware:           False
22.04.2018 17:41:44 INFO      Training sample:          baseline
22.04.2018 17:41:44 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
22.04.2018 17:41:44 INFO    Options:
22.04.2018 17:41:44 INFO      Number of hidden layers:  5
22.04.2018 17:41:44 INFO      alpha:                    100.0
22.04.2018 17:41:44 INFO      Batch size:               128
22.04.2018 17:41:44 INFO      Learning rate:            0.001
22.04.2018 17:41:44 INFO      Learning rate decay:      0.000460517018599
22.04.2018 17:41:44 INFO      Number of epochs:         10000
22.04.2018 17:41:44 INFO      Training samples:         50000
22.04.2018 17:41:44 INFO      NC experiments:           False
22.04.2018 17:41:44 INFO      Debug mode:               False
22.04.2018 17:42:05 INFO    Reduced training sample size from 9999997 to 50000 (factor 200)
22.04.2018 17:42:19 INFO    Starting training
2018-04-22 17:42:19.965229: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 17:42:19.965261: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 17:42:19.965266: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 17:42:19.965270: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 17:42:19.965274: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-22 17:42:20.307788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-22 17:42:20.307822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-22 17:42:20.307827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-22 17:42:20.307835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 02055: early stopping
22.04.2018 19:18:19 INFO    Starting evaluation
22.04.2018 19:20:11 INFO    Starting theta 100 / 1017
22.04.2018 19:22:00 INFO    Starting theta 200 / 1017
22.04.2018 19:23:49 INFO    Starting theta 300 / 1017
22.04.2018 19:25:37 INFO    Starting theta 400 / 1017
22.04.2018 19:27:25 INFO    Starting theta 500 / 1017
22.04.2018 19:29:13 INFO    Starting theta 600 / 1017
22.04.2018 19:31:01 INFO    Starting theta 700 / 1017
22.04.2018 19:32:49 INFO    Starting theta 800 / 1017
22.04.2018 19:34:37 INFO    Starting theta 900 / 1017
22.04.2018 19:36:25 INFO    Starting theta 1000 / 1017
22.04.2018 19:36:44 INFO    Evaluation timing: median 1.06722283363 s, mean 1.07232881108 s
22.04.2018 19:36:44 INFO    Starting roaming
22.04.2018 19:37:07 INFO    Starting calibrated evaluation and roaming
22.04.2018 20:52:10 INFO    Starting theta 100 / 1017
22.04.2018 22:08:10 INFO    Starting theta 200 / 1017
22.04.2018 23:24:02 INFO    Starting theta 300 / 1017
23.04.2018 00:39:54 INFO    Starting theta 400 / 1017
23.04.2018 01:55:43 INFO    Starting theta 500 / 1017
23.04.2018 03:11:55 INFO    Starting theta 600 / 1017
23.04.2018 04:28:08 INFO    Starting theta 700 / 1017
23.04.2018 05:43:55 INFO    Starting theta 800 / 1017
23.04.2018 06:59:34 INFO    Starting theta 900 / 1017
23.04.2018 08:15:10 INFO    Starting theta 1000 / 1017
23.04.2018 08:28:48 INFO    Calibrated evaluation timing: median 1.07492899895 s, mean 1.07995291492 s
23.04.2018 08:28:48 INFO    Interpolating calibrated roaming
23.04.2018 08:34:06 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 08:34:09 INFO    Hi! How are you today?
23.04.2018 08:34:09 INFO    Startup options:
23.04.2018 08:34:09 INFO      Algorithm:                     combinedregression
23.04.2018 08:34:09 INFO      Point by point:                False
23.04.2018 08:34:09 INFO      Morphing-aware mode:           False
23.04.2018 08:34:09 INFO      Smeared data:                  False
23.04.2018 08:34:09 INFO      Training sample:               baseline
23.04.2018 08:34:09 INFO      alpha:                         None
23.04.2018 08:34:09 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 08:34:09 INFO      AFC epsilon:                   None
23.04.2018 08:34:09 INFO      Denominator theta:             False
23.04.2018 08:34:09 INFO      Neyman construction toys:      0
23.04.2018 08:34:09 INFO      Training sample size limit:    100000
23.04.2018 08:34:09 INFO      Other options:                 ['deep']
23.04.2018 08:34:09 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 08:34:09 INFO      ML-based strategies available: True
23.04.2018 08:34:09 INFO    Starting parameterized inference
23.04.2018 08:34:09 INFO    Main settings:
23.04.2018 08:34:09 INFO      Algorithm:                combinedregression
23.04.2018 08:34:09 INFO      Morphing-aware:           False
23.04.2018 08:34:09 INFO      Training sample:          baseline
23.04.2018 08:34:09 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 08:34:09 INFO    Options:
23.04.2018 08:34:09 INFO      Number of hidden layers:  5
23.04.2018 08:34:09 INFO      alpha:                    100.0
23.04.2018 08:34:09 INFO      Batch size:               128
23.04.2018 08:34:09 INFO      Learning rate:            0.001
23.04.2018 08:34:09 INFO      Learning rate decay:      0.000921034037198
23.04.2018 08:34:09 INFO      Number of epochs:         5000
23.04.2018 08:34:09 INFO      Training samples:         100000
23.04.2018 08:34:09 INFO      NC experiments:           False
23.04.2018 08:34:09 INFO      Debug mode:               False
23.04.2018 08:34:29 INFO    Reduced training sample size from 9999997 to 100000 (factor 100)
23.04.2018 08:34:43 INFO    Starting training
2018-04-23 08:34:44.314742: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 08:34:44.314971: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 08:34:44.314980: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 08:34:44.314984: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 08:34:44.314988: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 08:34:44.646902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-23 08:34:44.646939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 08:34:44.646946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 08:34:44.646954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 01034: early stopping
23.04.2018 10:09:45 INFO    Starting evaluation
23.04.2018 10:11:37 INFO    Starting theta 100 / 1017
23.04.2018 10:13:25 INFO    Starting theta 200 / 1017
23.04.2018 10:15:14 INFO    Starting theta 300 / 1017
23.04.2018 10:17:02 INFO    Starting theta 400 / 1017
23.04.2018 10:18:51 INFO    Starting theta 500 / 1017
23.04.2018 10:20:40 INFO    Starting theta 600 / 1017
23.04.2018 10:22:28 INFO    Starting theta 700 / 1017
23.04.2018 10:24:16 INFO    Starting theta 800 / 1017
23.04.2018 10:26:05 INFO    Starting theta 900 / 1017
23.04.2018 10:27:53 INFO    Starting theta 1000 / 1017
23.04.2018 10:28:13 INFO    Evaluation timing: median 1.06938385963 s, mean 1.074868819 s
23.04.2018 10:28:13 INFO    Starting roaming
23.04.2018 10:28:35 INFO    Starting calibrated evaluation and roaming
23.04.2018 11:43:36 INFO    Starting theta 100 / 1017
23.04.2018 12:59:17 INFO    Starting theta 200 / 1017
23.04.2018 14:15:01 INFO    Starting theta 300 / 1017
23.04.2018 15:30:46 INFO    Starting theta 400 / 1017
23.04.2018 16:49:11 INFO    Starting theta 500 / 1017
23.04.2018 18:09:39 INFO    Starting theta 600 / 1017
23.04.2018 19:30:16 INFO    Starting theta 700 / 1017
23.04.2018 20:51:07 INFO    Starting theta 800 / 1017
23.04.2018 22:12:07 INFO    Starting theta 900 / 1017
23.04.2018 23:33:00 INFO    Starting theta 1000 / 1017
23.04.2018 23:47:36 INFO    Calibrated evaluation timing: median 1.1471529007 s, mean 1.1196959089 s
23.04.2018 23:47:36 INFO    Interpolating calibrated roaming
23.04.2018 23:53:32 INFO    That's it -- have a great day!
Using TensorFlow backend.
23.04.2018 23:53:35 INFO    Hi! How are you today?
23.04.2018 23:53:35 INFO    Startup options:
23.04.2018 23:53:35 INFO      Algorithm:                     combinedregression
23.04.2018 23:53:35 INFO      Point by point:                False
23.04.2018 23:53:35 INFO      Morphing-aware mode:           False
23.04.2018 23:53:35 INFO      Smeared data:                  False
23.04.2018 23:53:35 INFO      Training sample:               baseline
23.04.2018 23:53:35 INFO      alpha:                         None
23.04.2018 23:53:35 INFO      Histogram / AFC X indices:     [1, 38, 39, 40, 41]
23.04.2018 23:53:35 INFO      AFC epsilon:                   None
23.04.2018 23:53:35 INFO      Denominator theta:             False
23.04.2018 23:53:35 INFO      Neyman construction toys:      0
23.04.2018 23:53:35 INFO      Training sample size limit:    200000
23.04.2018 23:53:35 INFO      Other options:                 ['deep']
23.04.2018 23:53:35 INFO      Base directory:                /home/jb6504/higgs_inference
23.04.2018 23:53:35 INFO      ML-based strategies available: True
23.04.2018 23:53:35 INFO    Starting parameterized inference
23.04.2018 23:53:35 INFO    Main settings:
23.04.2018 23:53:35 INFO      Algorithm:                combinedregression
23.04.2018 23:53:35 INFO      Morphing-aware:           False
23.04.2018 23:53:35 INFO      Training sample:          baseline
23.04.2018 23:53:35 INFO      Denominator theta:        denominator 0 = theta 708 = [ 0.39293227  0.43229216]
23.04.2018 23:53:35 INFO    Options:
23.04.2018 23:53:35 INFO      Number of hidden layers:  5
23.04.2018 23:53:35 INFO      alpha:                    100.0
23.04.2018 23:53:35 INFO      Batch size:               128
23.04.2018 23:53:35 INFO      Learning rate:            0.001
23.04.2018 23:53:35 INFO      Learning rate decay:      0.0018420680744
23.04.2018 23:53:35 INFO      Number of epochs:         2500
23.04.2018 23:53:35 INFO      Training samples:         200000
23.04.2018 23:53:35 INFO      NC experiments:           False
23.04.2018 23:53:35 INFO      Debug mode:               False
23.04.2018 23:53:57 INFO    Reduced training sample size from 9999997 to 200000 (factor 50)
23.04.2018 23:54:13 INFO    Starting training
2018-04-23 23:54:14.213581: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 23:54:14.213616: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 23:54:14.213621: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 23:54:14.213626: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 23:54:14.213630: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-04-23 23:54:14.542236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Tesla P40
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:05:00.0
Total memory: 22.38GiB
Free memory: 22.21GiB
2018-04-23 23:54:14.542273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-04-23 23:54:14.542279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-04-23 23:54:14.542287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P40, pci bus id: 0000:05:00.0)
Epoch 00559: early stopping
24.04.2018 01:47:40 INFO    Starting evaluation
24.04.2018 01:49:43 INFO    Starting theta 100 / 1017
24.04.2018 01:51:41 INFO    Starting theta 200 / 1017
24.04.2018 01:53:40 INFO    Starting theta 300 / 1017
24.04.2018 01:55:39 INFO    Starting theta 400 / 1017
24.04.2018 01:57:37 INFO    Starting theta 500 / 1017
24.04.2018 01:59:36 INFO    Starting theta 600 / 1017
24.04.2018 02:01:35 INFO    Starting theta 700 / 1017
24.04.2018 02:03:33 INFO    Starting theta 800 / 1017
24.04.2018 02:05:32 INFO    Starting theta 900 / 1017
24.04.2018 02:07:30 INFO    Starting theta 1000 / 1017
24.04.2018 02:07:52 INFO    Evaluation timing: median 1.17286014557 s, mean 1.1756110972 s
24.04.2018 02:07:52 INFO    Starting roaming
24.04.2018 02:08:17 INFO    Starting calibrated evaluation and roaming
24.04.2018 03:30:24 INFO    Starting theta 100 / 1017
24.04.2018 04:50:57 INFO    Starting theta 200 / 1017
24.04.2018 06:09:26 INFO    Starting theta 300 / 1017
24.04.2018 07:27:51 INFO    Starting theta 400 / 1017
24.04.2018 08:46:15 INFO    Starting theta 500 / 1017
24.04.2018 10:06:02 INFO    Starting theta 600 / 1017
24.04.2018 11:25:23 INFO    Starting theta 700 / 1017
