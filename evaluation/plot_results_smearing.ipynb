{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import LinearNDInterpolator, CloughTocher2DInterpolator\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.mlab import griddata\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append('..')\n",
    "from higgs_inference.various.utils import interpolate, format_number, asymptotic_p_value\n",
    "from higgs_inference import settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation in final plot.\n",
    "interpolation_method = 'gp' #'linear' or 'gp'\n",
    "\n",
    "# Which benchmark point to use\n",
    "use_not_trained_benchmark = True\n",
    "\n",
    "# Which algorithm to use for the PbP vs parameterized vs morphing-aware plot\n",
    "use_regression_as_pbp_param_aware_example = False\n",
    "\n",
    "# Neyman construction settings\n",
    "neyman_plots = True\n",
    "remove_duplicates_for_nc = False\n",
    "\n",
    "# Asymptotics settings\n",
    "use_median_rather_than_asimov = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors     = ['black', '0.65', 'darkgreen',  'mediumblue',    'c', '#CC002E', 'orange', 'orange', 'darkgreen', 'mediumblue']\n",
    "colors     = ['0.65', 'orange', 'darkgreen',  'mediumblue',  'c', '#CC002E', 'orchid', 'orange', 'darkgreen', 'mediumblue']\n",
    "linestyles = [  '-',     ':',   '--',       '-.',      ':',         '--',          '-.',        '-',         '--',  ':']\n",
    "linewidths = [1.5 if ls == ':' else 1.5 for ls in linestyles]\n",
    "\n",
    "scatter_alpha = 1.\n",
    "\n",
    "def lighter_color(color, fraction_white=0.5):\n",
    "    rgb = np.asarray(matplotlib.colors.to_rgb(color))\n",
    "    white = np.asarray((1.,1.,1.))\n",
    "    return fraction_white * white + (1. - fraction_white)*rgb\n",
    "\n",
    "#for color in colors:\n",
    "#    print(color, matplotlib.colors.to_rgb(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.load('../data/thetas/thetas_parameterized.npy')\n",
    "\n",
    "n_thetas = len(thetas)\n",
    "theta1 = 708\n",
    "theta_observed = 0\n",
    "thetas_train = list(range(17,1017))\n",
    "thetas_test = list(range(17))\n",
    "\n",
    "if use_not_trained_benchmark:\n",
    "    theta_benchmark = 9\n",
    "    benchmark_name = 'nottrained'\n",
    "else:\n",
    "    theta_benchmark = 422\n",
    "    benchmark_name = 'trained'\n",
    "    \n",
    "pbp_training_thetas = [0, 13, 14, 15, 16, 9, 422, 956, 666, 802, 675, 839, 699, 820, 203, 291, 634, 371, 973, 742, 901, 181, 82, 937, 510, 919, 745, 588, 804, 963, 396, 62, 401, 925, 874, 770, 108, 179, 669, 758, 113, 587, 600, 975, 496, 66, 467, 412, 701, 986, 598, 810, 97, 18, 723, 159, 320, 301, 352, 159, 89, 421, 574, 923, 849, 299, 119, 167, 939, 402, 52, 787, 978, 41, 873, 533, 827, 304, 294, 760, 890, 539, 1000, 291, 740, 276, 679, 167, 125, 429, 149, 430, 720, 123, 908, 256, 777, 809, 269, 851]\n",
    "basis_thetas = [0, 101, 106, 902, 910,\n",
    "                226, 373, 583, 747, 841,\n",
    "                599, 709, 422, 367, 167]\n",
    "thetas_highlighted = []\n",
    "\n",
    "X_observed = np.load('../data/unweighted_events/X_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_l_absolute = 8. * 0.1\n",
    "margin_r_absolute = 8. * 0.02\n",
    "margin_sep_absolute = 8. * 0.02\n",
    "margin_t_absolute = 8. * 0.02\n",
    "margin_t_absolute_extra = 8. * 0.10\n",
    "margin_b_absolute = 8. * 0.08\n",
    "\n",
    "def calculate_height(n_panels=2, width=8., panel_aspect_ratio=1., extra_top_space=False):\n",
    "    \n",
    "    if isinstance(n_panels, collections.Sequence):\n",
    "        n_panels_h, n_panels_v = n_panels\n",
    "    else:\n",
    "        n_panels_h = n_panels\n",
    "        n_panels_v = 1\n",
    "        \n",
    "    # Determine top margin\n",
    "    _margin_t_absolute = margin_t_absolute_extra if extra_top_space else margin_t_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    margin_l = margin_l_absolute / width\n",
    "    margin_r = margin_r_absolute / width\n",
    "    margin_l_subsequent = margin_l\n",
    "    if n_panels_h > 2:\n",
    "        margin_l_subsequent = margin_r\n",
    "    margin_sep = margin_sep_absolute / width\n",
    "    if n_panels_h > 2:\n",
    "        margin_sep = 0\n",
    "    margin_sep_total = margin_r + margin_sep + margin_l_subsequent\n",
    "    panel_width = (1. - margin_l - margin_r - (n_panels_h - 1)*margin_sep_total) / n_panels_h\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    wspace = margin_sep_total / panel_width\n",
    "    \n",
    "    # Calculate absolute height\n",
    "    panel_height_absolute = panel_width * width / panel_aspect_ratio\n",
    "    height = n_panels_v * (panel_height_absolute + _margin_t_absolute + margin_b_absolute) + (n_panels_v - 1) * margin_sep_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    panel_height = panel_height_absolute / height\n",
    "    margin_t = _margin_t_absolute / height\n",
    "    margin_b = margin_b_absolute / height\n",
    "    margin_sep_total = (margin_t + margin_b + margin_sep_absolute / height)\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    hspace = margin_sep_total / panel_height\n",
    "    \n",
    "    # Return height\n",
    "    return height\n",
    "\n",
    "\n",
    "def adjust_margins(n_panels=2, width=8., panel_aspect_ratio=1., extra_top_space=False):\n",
    "    \n",
    "    if isinstance(n_panels, collections.Sequence):\n",
    "        n_panels_h, n_panels_v = n_panels\n",
    "    else:\n",
    "        n_panels_h = n_panels\n",
    "        n_panels_v = 1\n",
    "        \n",
    "    # Determine top margin\n",
    "    _margin_t_absolute = margin_t_absolute_extra if extra_top_space else margin_t_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    margin_l = margin_l_absolute / width\n",
    "    margin_r = margin_r_absolute / width\n",
    "    margin_l_subsequent = margin_l\n",
    "    if n_panels_h > 2:\n",
    "        margin_l_subsequent = margin_r\n",
    "    margin_sep = margin_sep_absolute / width\n",
    "    if n_panels_h > 2:\n",
    "        margin_sep = 0\n",
    "    margin_sep_total = margin_r + margin_sep + margin_l_subsequent\n",
    "    panel_width = (1. - margin_l - margin_r - (n_panels_h - 1)*margin_sep_total) / n_panels_h\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    wspace = margin_sep_total / panel_width\n",
    "    \n",
    "    # Calculate absolute height\n",
    "    panel_height_absolute = panel_width * width / panel_aspect_ratio\n",
    "    height = n_panels_v * (panel_height_absolute + _margin_t_absolute + margin_b_absolute) + (n_panels_v - 1) * margin_sep_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    panel_height = panel_height_absolute / height\n",
    "    margin_t = _margin_t_absolute / height\n",
    "    margin_b = margin_b_absolute / height\n",
    "    margin_sep_total = (margin_t + margin_b + margin_sep_absolute / height)\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    hspace = margin_sep_total / panel_height\n",
    "    \n",
    "    # Set margins\n",
    "    plt.subplots_adjust(left = margin_l,\n",
    "                        right = 1. - margin_r,\n",
    "                        bottom = margin_b,\n",
    "                        top = 1. - margin_t,\n",
    "                        wspace = wspace,\n",
    "                        hspace = hspace)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define strategies and load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load(name, folder='parameterized'):\n",
    "    return np.load('../results/' + folder + '/' + name + '.npy')\n",
    "\n",
    "def add_strategy(label, suffix, folder,\n",
    "                 suffices_ensemble=None, suffix_uncalibrated=None,\n",
    "                 panel=-1, in_pbp_param_aware_plot=False, in_main_plot=True, is_truth=False,\n",
    "                 zorder=None):\n",
    "    \n",
    "    neyman_string = 'neyman3' if remove_duplicates_for_nc else 'neyman2'\n",
    "    \n",
    "    try:\n",
    "        _expected_llr = _load('llr_' + suffix, folder)\n",
    "        _r_benchmark = _load('r_' + benchmark_name + '_' + suffix, folder)\n",
    "    except IOError:\n",
    "        print('Results for strategy ' + label + ' not found')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        _mse_log_r = _load('mse_logr_' + suffix, folder)\n",
    "        _trimmed_mse_log_r = _load('trimmed_mse_logr_' + suffix, folder)\n",
    "        do_mse_log_r = True\n",
    "    except IOError:\n",
    "        _mse_log_r = None\n",
    "        _trimmed_mse_log_r = None\n",
    "        do_mse_log_r = False\n",
    "        \n",
    "    if suffix_uncalibrated is not None:\n",
    "        try:\n",
    "            _r_benchmark_uncalibrated = _load('r_' + benchmark_name + '_' + suffix_uncalibrated, folder)\n",
    "            do_calibration = True\n",
    "        except IOError:\n",
    "            _r_benchmark_uncalibrated = None\n",
    "            do_calibration = False\n",
    "    else:\n",
    "        _r_benchmark_uncalibrated = None\n",
    "        do_calibration = False\n",
    "        \n",
    "    if suffices_ensemble is not None:\n",
    "        try:\n",
    "            _expected_llr_ensemble = []\n",
    "            for i in range(4):\n",
    "                _filename = 'llr_' + suffices_ensemble.replace(r'%i', str(i+1))\n",
    "                _expected_llr_ensemble.append(_load(_filename, folder))\n",
    "            do_diagnostics = True\n",
    "        except IOError:\n",
    "            do_diagnostics = False\n",
    "            _expected_llr_ensemble = None\n",
    "    else:\n",
    "        do_diagnostics = False\n",
    "        _expected_llr_ensemble = None\n",
    "    \n",
    "    try:\n",
    "        _p_values = _load(neyman_string + '_pvalues_' + suffix, folder)\n",
    "        _q_thresholds = _load(neyman_string + '_qcut_' + suffix, folder)\n",
    "        _q_threshold_uncertainties = _load(neyman_string + '_qcut_uncertainties_' + suffix, folder)\n",
    "        _q_medians = _load(neyman_string + '_qmedian_' + suffix, folder)\n",
    "        do_neyman = True\n",
    "        \n",
    "        assert not np.all(np.isnan(_q_thresholds)), 'q thresholds contain only NaNs'\n",
    "        assert not np.all(np.isnan(_q_medians)), 'q medians contain only NaNs'\n",
    "        assert not np.all(np.isnan(_q_threshold_uncertainties)), 'q threshold uncertainties contain only NaNs'\n",
    "    except IOError:\n",
    "        _p_values = None\n",
    "        _q_thresholds = None\n",
    "        _q_threshold_uncertainties = None\n",
    "        _q_medians = None\n",
    "        do_neyman = False\n",
    "    except AssertionError as err:\n",
    "        _p_values = None\n",
    "        _q_thresholds = None\n",
    "        _q_threshold_uncertainties = None\n",
    "        _q_medians = None\n",
    "        do_neyman = False\n",
    "    \n",
    "    try:\n",
    "        _r_roam = _load('r_roam_' + suffix, folder)\n",
    "        do_roaming = True\n",
    "    except IOError:\n",
    "        _r_roam = None\n",
    "        do_roaming = False\n",
    "        \n",
    "    try:\n",
    "        _mle_thetas = _load('neyman_mle_' + suffix, folder)\n",
    "        do_mle = True\n",
    "    except IOError:\n",
    "        _mle_thetas = None\n",
    "        do_mle = False\n",
    "        \n",
    "    labels.append(label)\n",
    "    suffices.append(suffix)\n",
    "    \n",
    "    expected_llr.append(_expected_llr)\n",
    "    expected_llr_ensemble.append(_expected_llr_ensemble)\n",
    "    mse_log_r.append(_mse_log_r)\n",
    "    trimmed_mse_log_r.append(_trimmed_mse_log_r)\n",
    "    p_values.append(_p_values)\n",
    "    q_medians.append(_q_medians)\n",
    "    q_threshold_uncertainties.append(_q_threshold_uncertainties)\n",
    "    q_thresholds.append(_q_thresholds)\n",
    "    mle_thetas.append(_mle_thetas)\n",
    "    r_benchmark.append(_r_benchmark)\n",
    "    r_benchmark_uncalibrated.append(_r_benchmark_uncalibrated)\n",
    "    r_roam.append(_r_roam)\n",
    "    \n",
    "    index = len(labels) - 1\n",
    "    if is_truth:\n",
    "        truth_index = index\n",
    "    if panel >= 0 and panel < 3:\n",
    "        panel_indices[panel].append(index)\n",
    "    in_pbp_param_aware_plots.append(in_pbp_param_aware_plot)\n",
    "    in_main_plots.append(in_main_plot)\n",
    "    \n",
    "    zorders.append(zorder)\n",
    "        \n",
    "    if do_neyman or do_roaming or do_mle or do_diagnostics or do_calibration:\n",
    "        supported = []\n",
    "        if do_diagnostics:\n",
    "            supported.append('ensemble diagnostics')\n",
    "        if do_neyman:\n",
    "            supported.append('Neyman construction')\n",
    "        if do_mle:\n",
    "            supported.append('MLE')\n",
    "        if do_roaming:\n",
    "            supported.append('theta dependence plots')\n",
    "        if do_calibration:\n",
    "            supported.append('calibration plots')\n",
    "        supported = ', '.join(supported)\n",
    "            \n",
    "        print('Loaded strategy ' + label + ' with support for ' + supported)\n",
    "        \n",
    "    else:\n",
    "        print('Loaded strategy ' + label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded strategy Truth with support for Neyman construction, MLE, theta dependence plots\n",
      "Loaded strategy Histogram with support for Neyman construction\n",
      "Loaded strategy CARL with support for Neyman construction, theta dependence plots\n",
      "Loaded strategy Local score regr. with support for Neyman construction\n",
      "Loaded strategy Ratio regression with support for Neyman construction, theta dependence plots\n",
      "Loaded strategy CARL + score regr. with support for Neyman construction, theta dependence plots\n",
      "Loaded strategy Ratio + score regr. with support for Neyman construction, theta dependence plots\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "suffices = []\n",
    "folders = []\n",
    "\n",
    "truth_index = 0\n",
    "panel_indices = ([], [])\n",
    "panel_indices = ([], [], [])\n",
    "in_pbp_param_aware_plots = []\n",
    "in_main_plots = []\n",
    "\n",
    "expected_llr = []\n",
    "expected_llr_ensemble = []\n",
    "mse_log_r = []\n",
    "trimmed_mse_log_r = []\n",
    "p_values = []\n",
    "q_medians = []\n",
    "q_thresholds = []\n",
    "q_threshold_uncertainties = []\n",
    "mle_thetas = []\n",
    "r_benchmark = []\n",
    "r_benchmark_uncalibrated = []\n",
    "r_roam = []\n",
    "\n",
    "zorders = []\n",
    "\n",
    "add_strategy('Truth', 'truth', 'truth', is_truth=True)\n",
    "\n",
    "add_strategy('Histogram', 'histo_2d_smeared', 'histo', panel=0)\n",
    "add_strategy('CARL', 'carl_calibrated_shallow_smeared', 'parameterized', panel=0)\n",
    "add_strategy('Local score regr.', 'scoreregression_rotatedscore_deep_smeared', 'score_regression', panel=1)\n",
    "add_strategy('Ratio regression', 'regression_calibrated_smeared', 'parameterized', panel=1)\n",
    "add_strategy('CARL + score regr.', 'combined_calibrated_deep_smeared', 'parameterized', panel=2)\n",
    "add_strategy('Ratio + score regr.', 'combinedregression_calibrated_deep_smeared', 'parameterized', panel=2)\n",
    "\n",
    "n_strategies = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_indices = ([1, 2], [4, 3], [5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate LLR and p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannbrehmer/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / np.sqrt(D.sum(2))[:, :, np.newaxis]\n",
      "/Users/johannbrehmer/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00063258,  0.00062673,  0.1456518 ]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 117, 'nit': 31, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting strategy 1 / 7\n"
     ]
    }
   ],
   "source": [
    "# grid\n",
    "thetas_filtered = thetas[:]\n",
    "xi = np.linspace(-1.0, 1.0, 200)\n",
    "yi = np.linspace(-1.0, 1.0, 200)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "# first, interpolate LLR results\n",
    "interpolated_expected_llr = []\n",
    "interpolated_expected_llr_mle = []\n",
    "interpolated_expected_llr_median = []\n",
    "interpolated_expected_llr_min = []\n",
    "interpolated_expected_llr_max = []\n",
    "\n",
    "for llr, llr_ensemble in zip(expected_llr, expected_llr_ensemble):\n",
    "    _llr, _mle = interpolate(thetas, llr, xx, yy, method=interpolation_method, subtract_min=False)\n",
    "    _llr -= llr[settings.theta_observed]\n",
    "    \n",
    "    if llr_ensemble is not None:\n",
    "        _llr_ensemble = [_llr]\n",
    "        for i, llr_from_ensemble in enumerate(llr_ensemble):\n",
    "            _llr_ens, _ = interpolate(thetas, llr_from_ensemble, xx, yy,\n",
    "                                      method=interpolation_method, subtract_min=False)\n",
    "            _llr_ens -= llr_ensemble[i][settings.theta_observed]\n",
    "            _llr_ensemble.append(_llr_ens)\n",
    "        _llr_ensemble = np.asarray(_llr_ensemble)\n",
    "        \n",
    "        _llr_median = np.median(_llr_ensemble, axis=0)\n",
    "        _llr_min = np.min(_llr_ensemble, axis=0)\n",
    "        _llr_max = np.max(_llr_ensemble, axis=0)\n",
    "            \n",
    "    else:\n",
    "        _llr_ensemble = None\n",
    "        _llr_median = _llr\n",
    "        _llr_min = _llr\n",
    "        _llr_max = _llr\n",
    "        \n",
    "    interpolated_expected_llr.append(_llr)\n",
    "    interpolated_expected_llr_mle.append(_mle)\n",
    "    interpolated_expected_llr_median.append(_llr_median)\n",
    "    interpolated_expected_llr_min.append(_llr_min)\n",
    "    interpolated_expected_llr_max.append(_llr_max)\n",
    "    \n",
    "if neyman_plots:\n",
    "    interpolated_q_medians = []\n",
    "    interpolated_q_thresholds = []\n",
    "    interpolated_cl_excluded = []\n",
    "\n",
    "    for i, (qmed, qthresh, qthresh_err) in enumerate(zip(q_medians, q_thresholds, q_threshold_uncertainties)):\n",
    "            \n",
    "        print('Starting strategy {} / {}'.format(i + 1, n_strategies))\n",
    "\n",
    "        if qmed is None or qthresh is None or qthresh_err is None:\n",
    "            interpolated_q_medians.append(None)\n",
    "            interpolated_q_thresholds.append(None)\n",
    "            interpolated_cl_excluded.append(None)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cut = np.all(np.isfinite(qthresh),axis=1) & (np.isfinite(qmed)) & np.all(np.isfinite(qthresh_err),axis=1)\n",
    "            \n",
    "            _qmed, _ = interpolate(thetas[cut], qmed[cut], xx, yy,\n",
    "                                  method='gp',\n",
    "                                  length_scale_default=0.1, length_scale_min=0.01, length_scale_max=1.,\n",
    "                                  matern_exponent=2.5,\n",
    "                                  noise_level=0.01)\n",
    "            \n",
    "            _qthreshs = []\n",
    "            for j in range(len(settings.confidence_levels)):\n",
    "                _qthresh, _ = interpolate(thetas[cut], qthresh[cut,j], xx, yy,\n",
    "                                         z_uncertainties_thetas=2*qthresh_err[cut,j],\n",
    "                                         method='gp',\n",
    "                                         length_scale_default=1., length_scale_min=0.5, length_scale_max=2.,\n",
    "                                         matern_exponent=2.5,\n",
    "                                         noise_level=0.01)\n",
    "                _qthreshs.append(copy.deepcopy(_qthresh))\n",
    "            _qthreshs = np.asarray(_qthreshs)\n",
    "\n",
    "            _excludeds = np.asarray([_qmed - _qthreshs[j] for j in range(_qthreshs.shape[0])])\n",
    "\n",
    "            interpolated_q_medians.append(_qmed)\n",
    "            interpolated_q_thresholds.append(_qthreshs)\n",
    "            interpolated_cl_excluded.append(_excludeds)\n",
    "            \n",
    "            # Debug plot\n",
    "            zmin, zmax = -20.,20.\n",
    "            plt.figure(figsize=(10,8))\n",
    "\n",
    "            plt.subplot(2,2,1)\n",
    "            zi = np.clip(_qmed,zmin,zmax)\n",
    "            cs = plt.contourf(xi, yi, zi, 100, cmap='viridis_r', vmin=zmin, vmax=zmax)\n",
    "            plt.scatter(thetas[:,0], thetas[:,1], c=qmed[:],\n",
    "                        s=30., lw=0.5, cmap='viridis_r', edgecolors='k', vmin=zmin, vmax=zmax)\n",
    "            cbar = plt.colorbar()\n",
    "            cs = plt.contour(xi, yi, zi, [settings.q_threshold],\n",
    "                             linewidths=1.5, colors='w',\n",
    "                             linestyles='solid')\n",
    "            plt.xlim(-1.,1.)\n",
    "            plt.ylim(-1.,1.)\n",
    "            plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "            plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "            cbar.set_label('Median observed $q$')\n",
    "            \n",
    "            for j in range(len(settings.confidence_levels)):\n",
    "                plt.subplot(2,2,j+2)\n",
    "                zi = np.clip(_qthreshs[j], zmin, zmax)\n",
    "                cs = plt.contourf(xi, yi, zi, 100, cmap='viridis_r', vmin=zmin, vmax=zmax)\n",
    "                plt.scatter(thetas[:,0], thetas[:,1], c=qthresh[:,j],\n",
    "                            s=30., lw=0.5, cmap='viridis_r', edgecolors='k', vmin=zmin, vmax=zmax)\n",
    "                cbar = plt.colorbar()\n",
    "                plt.xlim(-1.,1.)\n",
    "                plt.ylim(-1.,1.)\n",
    "                plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "                plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "                cbar.set_label('$q$ threshold')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"../figures/neyman/cl_interpolation_\" + suffices[i] + \".pdf\")\n",
    "\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            interpolated_q_medians.append(None)\n",
    "            interpolated_q_thresholds.append(None)\n",
    "            interpolated_cl_excluded.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neyman_plots:\n",
    "    interpolated_cl_excluded = []\n",
    "    for _qmed, _qthreshs in zip(interpolated_q_medians, interpolated_q_thresholds):\n",
    "        if _qmed is None:\n",
    "            interpolated_cl_excluded.append(None)\n",
    "        else:\n",
    "            interpolated_cl_excluded.append(np.asarray([_qmed - _qthreshs[j] for j in range(_qthreshs.shape[0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate p values from Asimov data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_p_values_asymptotics = []\n",
    "interpolated_p_values_asymptotics_median = []\n",
    "interpolated_p_values_asymptotics_lower_bound = []\n",
    "interpolated_p_values_asymptotics_upper_bound = []\n",
    "\n",
    "for llrs in interpolated_expected_llr:\n",
    "    pvals = []\n",
    "    \n",
    "    for llr in llrs.flatten():\n",
    "        pvals.append(asymptotic_p_value(llr, use_median_rather_than_asimov=True))\n",
    "    pvals = np.asarray(pvals)\n",
    "    \n",
    "    pvals = pvals.reshape(llrs.shape)\n",
    "    interpolated_p_values_asymptotics.append(pvals)\n",
    "    \n",
    "    \n",
    "for medians, mins, maxs in zip(interpolated_expected_llr_median, interpolated_expected_llr_min, interpolated_expected_llr_max):\n",
    "    pvals_median = []\n",
    "    pvals_lower = []\n",
    "    pvals_upper = []\n",
    "                         \n",
    "    for median, lmin, lmax in zip(medians.flatten(), mins.flatten(), maxs.flatten()):\n",
    "        pvals_median.append(asymptotic_p_value(median, use_median_rather_than_asimov=use_median_rather_than_asimov))\n",
    "        pvals_lower.append(asymptotic_p_value(lmin, use_median_rather_than_asimov=use_median_rather_than_asimov))\n",
    "        pvals_upper.append(asymptotic_p_value(lmax, use_median_rather_than_asimov=use_median_rather_than_asimov))\n",
    "                         \n",
    "    pvals_median = np.asarray(pvals_median)\n",
    "    pvals_lower = np.asarray(pvals_lower)\n",
    "    pvals_upper = np.asarray(pvals_upper)\n",
    "                         \n",
    "    pvals_median = pvals_median.reshape(medians.shape)\n",
    "    pvals_lower = pvals_lower.reshape(medians.shape)\n",
    "    pvals_upper = pvals_upper.reshape(medians.shape)\n",
    "                         \n",
    "    interpolated_p_values_asymptotics_median.append(pvals_median)\n",
    "    interpolated_p_values_asymptotics_lower_bound.append(pvals_lower)\n",
    "    interpolated_p_values_asymptotics_upper_bound.append(pvals_upper)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark theta: approximate r(x) vs r(x,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = 0.7,1.3\n",
    "bins=31\n",
    "\n",
    "fig = plt.figure(figsize=(9., calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "    \n",
    "    for i, s in enumerate(panel_indices[panel]):\n",
    "        plt.hist(r_benchmark[s] / r_benchmark[truth_index],\n",
    "                 range=(xmin, xmax), bins=bins, color=colors[s], alpha=0.1, density=True)\n",
    "    for i, s in enumerate(panel_indices[panel]):\n",
    "        plt.hist(r_benchmark[s] / r_benchmark[truth_index],\n",
    "                 range=(xmin, xmax), bins=bins, color=colors[s], histtype='step', lw=1.5, ls='-',density=True)\n",
    "        plt.plot([],[],lw=1.5,ls='-',c=colors[s],label=labels[s])\n",
    "        \n",
    "    plt.legend(loc='upper left', frameon=False)\n",
    "    \n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(0.,16.)\n",
    "    plt.xlabel(r\"$\\hat{r}(x| \\theta_0,\\,\\theta_1) \\;/\\; r(x,z| \\theta_0,\\,\\theta_1)$\")\n",
    "    if panel == 0:\n",
    "        plt.ylabel(r\"$p(\\hat{r} / r | \\theta_{SM})$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/r_smearing.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL contours from asymptotics (expected LLR contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grid\n",
    "thetas_filtered = thetas[:]\n",
    "xi = np.linspace(-1.0, 1.0, 200)\n",
    "yi = np.linspace(-1.0, 1.0, 200)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "p_value_lines = [0.003,0.05,0.32]\n",
    "\n",
    "fig = plt.figure(figsize=(9.,calculate_height(3,9.,1.,True)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "        \n",
    "    for s in panel_indices[panel]:\n",
    "        cs = plt.contour(xi, yi, interpolated_p_values_asymptotics[s], p_value_lines,\n",
    "                         linewidths=linewidths[s], colors=colors[s],\n",
    "                         linestyles=linestyles[s])\n",
    "        cs.collections[0].set_label(labels[s])\n",
    "\n",
    "    for s in panel_indices[panel]:\n",
    "        plt.scatter([xi[interpolated_expected_llr_mle[s][1]]],\n",
    "                    [yi[interpolated_expected_llr_mle[s][0]]],\n",
    "                    marker='o', c=colors[s], s=50, lw=0, zorder=10)\n",
    "\n",
    "    plt.legend(loc='lower left', bbox_to_anchor=(-0.02,.99), frameon=False)\n",
    "\n",
    "    plt.xlim(-1, 1.)\n",
    "    plt.ylim(-1, 1.)\n",
    "    plt.xticks(np.linspace(-1.,1.,5))\n",
    "    plt.yticks(np.linspace(-1.,1.,5))\n",
    "    plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "    if panel==0:\n",
    "        plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.,1.,True)\n",
    "plt.savefig(\"../figures/paper/constraints_asymptotics_smearing.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL contours from Neyman construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neyman_plots:\n",
    "    fig = plt.figure(figsize=(9.,calculate_height(3,9.,1,True)))\n",
    "\n",
    "    for panel in range(3):\n",
    "\n",
    "        if panel == 0:\n",
    "            ax0 = plt.subplot(1, 3, panel+1)\n",
    "        else:\n",
    "            ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "\n",
    "        for s in panel_indices[panel]:\n",
    "            if interpolated_cl_excluded[s] is None:\n",
    "                continue\n",
    "\n",
    "            for cl in range(len(interpolated_cl_excluded[truth_index])):\n",
    "                cs = plt.contour(xi, yi, interpolated_cl_excluded[s][cl], [0.],\n",
    "                                 linewidths=linewidths[s], colors=colors[s],\n",
    "                                 linestyles=linestyles[s])\n",
    "                if cl==0:\n",
    "                    cs.collections[0].set_label(labels[s])\n",
    "\n",
    "        plt.legend(loc='lower left', bbox_to_anchor=(-0.02,.99), frameon=False)\n",
    "\n",
    "        plt.xlim(-1, 1.)\n",
    "        plt.ylim(-1, 1.)\n",
    "        plt.xticks(np.linspace(-1.,1.,5))\n",
    "        plt.yticks(np.linspace(-1.,1.,5))\n",
    "        \n",
    "        plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "        if panel==0:\n",
    "            plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "        else:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "    adjust_margins(3,9.,1,True)\n",
    "    plt.savefig(\"../figures/paper/constraints_nc_smearing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
