{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sys.path.append('..')\n",
    "from higgs_inference import settings\n",
    "from higgs_inference.various.utils import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '../results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TablePrinter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TablePrinter:\n",
    "    \n",
    "    def __init__(self, metric_fns=[], header=None, precisions=[]):\n",
    "        \n",
    "        # Functions for metrics\n",
    "        self.metric_fns = metric_fns\n",
    "        self.n_metrics = len(self.metric_fns)\n",
    "        self.precisions = precisions if len(precisions) == self.n_metrics else [2] * self.n_metrics\n",
    "        \n",
    "        # Total table and current block\n",
    "        self.table = ''\n",
    "        self.block_entries = []\n",
    "        self.block_brackets = []\n",
    "        self.content_in_last_block = False\n",
    "\n",
    "        # Formatting options\n",
    "        self.indent = '   '\n",
    "        self.col_sep = ' & '\n",
    "        self.end_row = r'\\\\'\n",
    "        self.midrule = r'\\midrule'\n",
    "        self.end_line = '\\n'\n",
    "        self.emphasis_begin = r'\\mathbf{'\n",
    "        self.emphasis_end = r'}'\n",
    "        \n",
    "        # Header\n",
    "        self.table = ''\n",
    "        if header is not None:\n",
    "            self.table += self.indent + header + self.end_row + self.end_line\n",
    "    \n",
    "    \n",
    "    def finalise_block(self):\n",
    "\n",
    "        # Find best performance\n",
    "        block_metrics = [line[2:] for line in self.block_entries]\n",
    "        block_metrics = np.array(block_metrics)\n",
    "        block_best = []\n",
    "        for i in range(self.n_metrics):\n",
    "            try:\n",
    "                block_best.append(np.nanargmin(block_metrics[:,i]))\n",
    "            except ValueError:\n",
    "                block_best.append(-1)\n",
    "\n",
    "        # Format entries\n",
    "        text = ''\n",
    "        for i, (line, brackets) in enumerate(zip(self.block_entries, self.block_brackets)):\n",
    "            \n",
    "            # Skip entirely empty lines\n",
    "            try:\n",
    "                if not np.any(np.isfinite(line[2:])):\n",
    "                    continue\n",
    "            except TypeError:\n",
    "                print(line)\n",
    "                continue\n",
    "                \n",
    "            self.content_in_last_block = True\n",
    "            \n",
    "            # Labels\n",
    "            text += self.indent + line[0] + self.col_sep + line[1] + self.col_sep\n",
    "            \n",
    "            # Metrics\n",
    "            for j in range(self.n_metrics):\n",
    "                if np.isfinite(line[j + 2]):\n",
    "                    if brackets[j+2]:\n",
    "                        text += '(' + format_number(line[j + 2], self.precisions[j], emphasize=(i == block_best[j])) + ')'\n",
    "                    else:\n",
    "                        text += format_number(line[j + 2], self.precisions[j], emphasize=(i == block_best[j]))\n",
    "                if j == len(line) - 3:\n",
    "                    text += self.end_row + self.end_line\n",
    "                else:\n",
    "                    text += self.col_sep\n",
    "\n",
    "        # Add to document and reset for next block\n",
    "        self.table += text\n",
    "        self.block_entries = []\n",
    "        self.block_brackets = []\n",
    "    \n",
    "    \n",
    "    def new_block(self):\n",
    "        self.finalise_block()\n",
    "        if self.content_in_last_block:\n",
    "            self.table += self.indent + self.midrule + self.end_line\n",
    "            self.content_in_last_block = False\n",
    "    \n",
    "    \n",
    "    def add(self, col1, col2, filename, folder='parameterized'):\n",
    "        \n",
    "        # Label columns\n",
    "        line = [col1, col2]\n",
    "        brackets = [False, False]\n",
    "        \n",
    "        # Metrics\n",
    "        for fn in self.metric_fns:\n",
    "            bracket = False\n",
    "            try:\n",
    "                value = fn(filename, folder)\n",
    "            except (IOError, ValueError):\n",
    "                #print('File', filename, 'in folder', folder, 'not found')\n",
    "                value = np.nan\n",
    "                \n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value, bracket = value\n",
    "                \n",
    "            line.append(value)\n",
    "            brackets.append(bracket)\n",
    "\n",
    "        self.block_entries.append(line)\n",
    "        self.block_brackets.append(brackets)\n",
    "    \n",
    "    \n",
    "    def print(self):\n",
    "        self.finalise_block()\n",
    "        return self.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_mse_log_r(filename, folder='parameterized'):\n",
    "    mse_log_r = np.load(result_dir + folder + '/mse_logr_' + filename + '.npy')[settings.thetas_train]\n",
    "    return np.mean((mse_log_r))\n",
    "                       \n",
    "def expected_trimmed_mse_log_r(filename, folder='parameterized'):\n",
    "    mse_log_r = np.load(result_dir + folder + '/trimmed_mse_logr_' + filename + '.npy')[settings.thetas_train]\n",
    "    return np.mean((mse_log_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_log_r_nottrained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_nottrained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_nottrained_' + filename + '.npy'))\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_error(log_r_truth, log_r_estimated))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(log_r_truth) & np.isfinite(log_r_estimated)\n",
    "        return np.sqrt(mean_squared_error(log_r_truth[finites], log_r_estimated[finites])), True\n",
    "    \n",
    "def trimmed_mse_log_r_nottrained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_nottrained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_nottrained_' + filename + '.npy'))\n",
    "    try:\n",
    "        return np.sqrt(trim_mean((log_r_truth - log_r_estimated)**2, settings.trim_mean_fraction))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(log_r_truth) & np.isfinite(log_r_estimated)\n",
    "        return np.sqrt(trim_mean((log_r_truth - log_r_estimated)**2, settings.trim_mean_fraction)), True\n",
    "    \n",
    "def median_error_log_r_nottrained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_nottrained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_nottrained_' + filename + '.npy'))\n",
    "    errors = np.abs(log_r_truth - log_r_estimated)\n",
    "    return np.sqrt(np.median(errors))\n",
    "\n",
    "def mse_log_r_trained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_trained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_trained_' + filename + '.npy'))\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_error(log_r_truth, log_r_estimated))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(log_r_truth) & np.isfinite(log_r_estimated)\n",
    "        return np.sqrt(mean_squared_error(log_r_truth[finites], log_r_estimated[finites])), True\n",
    "    \n",
    "def trimmed_mse_log_r_trained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_trained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_nottrained_' + filename + '.npy'))\n",
    "    try:\n",
    "        return np.sqrt(trim_mean((log_r_truth - log_r_estimated)**2, settings.trim_mean_fraction))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(log_r_truth) & np.isfinite(log_r_estimated)\n",
    "        return np.sqrt(trim_mean((log_r_truth - log_r_estimated)**2, settings.trim_mean_fraction)), True\n",
    "    \n",
    "def median_error_log_r_trained(filename, folder='parameterized'):\n",
    "    log_r_truth = np.log(np.load(result_dir + 'truth/r_trained_truth.npy'))\n",
    "    log_r_estimated = np.log(np.load(result_dir + folder + '/r_trained_' + filename + '.npy'))\n",
    "    errors = np.abs(log_r_truth - log_r_estimated)\n",
    "    return np.median(errors)\n",
    "\n",
    "def mse_expected_log_r(filename, folder='parameterized'):\n",
    "    expected_log_r_truth = np.load(result_dir + 'truth/llr_truth.npy')[settings.thetas_train]\n",
    "    expected_log_r_estimated = np.load(result_dir + folder + '/llr_' + filename + '.npy')[settings.thetas_train]\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_error(expected_log_r_truth, expected_log_r_estimated))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(expected_log_r_truth) & np.isfinite(expected_log_r_estimated)\n",
    "        return np.sqrt(mean_squared_error(expected_log_r_truth[finites], expected_log_r_estimated[finites])), True\n",
    "\n",
    "def mse_delta_expected_log_r(filename, folder='parameterized'):\n",
    "    expected_log_r_truth = np.load(result_dir + 'truth/llr_truth.npy')[settings.thetas_train]\n",
    "    expected_log_r_truth -= np.min(expected_log_r_truth)\n",
    "    expected_log_r_estimated = np.load(result_dir + folder + '/llr_' + filename + '.npy')[settings.thetas_train]\n",
    "    expected_log_r_estimated -= np.min(expected_log_r_estimated)\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_error(expected_log_r_truth, expected_log_r_estimated))\n",
    "    except ValueError:\n",
    "        finites = np.isfinite(expected_log_r_truth) & np.isfinite(expected_log_r_estimated)\n",
    "        return np.sqrt(mean_squared_error(expected_log_r_truth[finites], expected_log_r_estimated[finites])), True\n",
    "\n",
    "def mse_score_nottrained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_nottrained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_nottrained_' + filename + '.npy')\n",
    "    return np.sqrt(mean_squared_error(t_truth, t_estimated))\n",
    "\n",
    "def trimmed_mse_score_nottrained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_nottrained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_nottrained_' + filename + '.npy')\n",
    "    return np.sqrt(trim_mean(np.linalg.norm(t_truth - t_estimated,axis=1)**2, settings.trim_mean_fraction))\n",
    "    \n",
    "def median_error_score_nottrained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_nottrained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_nottrained_' + filename + '.npy')\n",
    "    errors = np.abs(t_truth - t_estimated)\n",
    "    return np.median(errors)\n",
    "\n",
    "def mse_score_trained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_trained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_trained_' + filename + '.npy')\n",
    "    return np.sqrt(mean_squared_error(t_truth, t_estimated))\n",
    "\n",
    "def trimmed_mse_score_trained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_trained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_trained_' + filename + '.npy')\n",
    "    return np.sqrt(trim_mean(np.linalg.norm(t_truth - t_estimated,axis=1)**2, settings.trim_mean_fraction))\n",
    "    \n",
    "def median_error_score_trained(filename, folder='parameterized'):\n",
    "    t_truth = np.load(result_dir  + 'truth/scores_trained_truth.npy')\n",
    "    t_estimated = np.load(result_dir + folder + '/scores_trained_' + filename + '.npy')\n",
    "    errors = np.abs(t_truth - t_estimated)\n",
    "    return np.median(errors)\n",
    "\n",
    "def var_expected_log_r(filename, folder='parameterized'):\n",
    "    expected_log_r_truth = np.load(result_dir + 'truth/llr_truth.npy')[settings.thetas_train]\n",
    "    expected_log_r_estimated = np.load(result_dir + folder + '/llr_' + filename + '.npy')[settings.thetas_train]\n",
    "    return np.sqrt(np.var(expected_log_r_truth - expected_log_r_estimated))\n",
    "\n",
    "def var_delta_expected_log_r(filename, folder='parameterized'):\n",
    "    expected_log_r_truth = np.load(result_dir + 'truth/llr_truth.npy')[settings.thetas_train]\n",
    "    expected_log_r_truth -= np.min(expected_log_r_truth)\n",
    "    expected_log_r_estimated = np.load(result_dir + folder + '/llr_' + filename + '.npy')[settings.thetas_train]\n",
    "    expected_log_r_estimated -= np.min(expected_log_r_estimated)\n",
    "    return np.sqrt(np.var(expected_log_r_truth - expected_log_r_estimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Histogram',\n",
    "           r'AFC', # (density est.\\ in $\\boldx$)',\n",
    "          'carl (PbP, raw)',\n",
    "          'carl (PbP, cal.)',\n",
    "          'carl (param., raw)',\n",
    "          'carl (param., cal.)',\n",
    "          'carl (aware, raw)',\n",
    "          'carl (aware, cal.)',\n",
    "          \n",
    "          'SM score regr.\\ + density est.',\n",
    "          'carl + score (param., raw)',\n",
    "          'carl + score (param., cal.)',\n",
    "          'carl + score (aware, raw)',\n",
    "          'carl + score (aware, cal.)',\n",
    "          \n",
    "          'Ratio regression (PbP, raw)',\n",
    "          'Ratio regression (PbP, cal.)',\n",
    "          'Ratio regression (param., raw)',\n",
    "          'Ratio regression (param., cal.)',\n",
    "          'Ratio regression (aware, raw)',\n",
    "          'Ratio regression (aware, cal.)',\n",
    "          \n",
    "          r'Ratio + score regr.\\ (param., raw)',\n",
    "          r'Ratio + score regr.\\ (param., cal.)',\n",
    "          r'Ratio + score regr.\\ (aware, raw)',\n",
    "          r'Ratio + score regr.\\ (aware, cal.)']\n",
    "\n",
    "folders = (['histo'] + ['afc'] + ['point_by_point'] * 2 + ['parameterized'] * 4\n",
    "          + ['score_regression'] + ['parameterized'] * 4\n",
    "          + ['point_by_point'] * 2 + ['parameterized'] * 4\n",
    "          + ['parameterized'] * 4)\n",
    "\n",
    "filenames = ['histo',\n",
    "             'afc',\n",
    "             'carl',\n",
    "             'carl_calibrated',\n",
    "             'carl',\n",
    "             'carl_calibrated',\n",
    "             'carl_aware',\n",
    "             'carl_calibrated_aware',\n",
    "             \n",
    "             'scoreregression',\n",
    "             'combined',\n",
    "             'combined_calibrated',\n",
    "             'combined_aware',\n",
    "             'combined_calibrated_aware',\n",
    "             \n",
    "             'regression',\n",
    "             'regression_calibrated',\n",
    "             'regression',\n",
    "             'regression_calibrated',\n",
    "             'regression_aware',\n",
    "             'regression_calibrated_aware',\n",
    "             \n",
    "             'combinedregression',\n",
    "             'combinedregression_calibrated'\n",
    "             'combinedregression_aware',\n",
    "             'combinedregression_calibrated_aware']\n",
    "\n",
    "\n",
    "def show_main_table(algorithm_begin=0, algorithm_end=None):\n",
    "    \n",
    "    #table = TablePrinter([trimmed_mse_log_r_nottrained, mse_expected_log_r],\n",
    "    #                      precisions=[3,2])\n",
    "    table = TablePrinter([expected_mse_log_r, expected_trimmed_mse_log_r],\n",
    "                          precisions=[4,4])\n",
    "\n",
    "    for i, (label, filename, folder) in enumerate(\n",
    "        zip(labels[algorithm_begin:algorithm_end], filenames[algorithm_begin:algorithm_end], folders[algorithm_begin:algorithm_end])):\n",
    "\n",
    "        if i > 0:\n",
    "            table.new_block()\n",
    "\n",
    "        if folder == 'point_by_point':\n",
    "            table.add('', 'PbP', filename, 'point_by_point')\n",
    "            table.add('', 'PbP, shallow', filename + '_shallow', 'point_by_point')\n",
    "            table.add('', 'PbP, deep', filename + '_deep', 'point_by_point')\n",
    "\n",
    "        elif folder == 'histo':\n",
    "            table.add(label, r'$p_{T,j1}$', filename + '_ptj', 'histo')\n",
    "            table.add('', r'$\\Delta \\phi_{jj}$', filename + '_deltaphi', 'histo')\n",
    "            table.add('', '2d', filename + '_2d', 'histo')\n",
    "\n",
    "        elif folder == 'afc':\n",
    "            table.add(label, '2d, $\\epsilon = 1$', filename + '_2d_epsilon_1.00', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.5$', filename + '_2d_epsilon_0.50', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.2$', filename + '_2d_epsilon_0.20', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.1$', filename + '_2d_epsilon_0.10', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.05$', filename + '_2d_epsilon_0.05', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.02$', filename + '_2d_epsilon_0.02', 'afc')\n",
    "            table.add('', '2d, $\\epsilon = 0.01$', filename + '_2d_epsilon_0.01', 'afc')\n",
    "\n",
    "            table.add(label, '5d, $\\epsilon = 1$', filename + '_5d_epsilon_1.00', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.5$', filename + '_5d_epsilon_0.50', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.2$', filename + '_5d_epsilon_0.20', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.1$', filename + '_5d_epsilon_0.10', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.05$', filename + '_5d_epsilon_0.05', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.02$', filename + '_5d_epsilon_0.02', 'afc')\n",
    "            table.add('', '5d, $\\epsilon = 0.01$', filename + '_5d_epsilon_0.01', 'afc')\n",
    "\n",
    "        elif folder == 'score_regression':\n",
    "            table.add(label, r'Fixed density est. on $t$', filename + '_score', 'score_regression')\n",
    "            table.add('', r'Dyn. dens. est. on $t$', filename + '_rotatedscore', 'score_regression')\n",
    "            table.add('', r'Dens. est. on $t \\cdot \\theta$', filename + '_scoretheta', 'score_regression')\n",
    "\n",
    "        else:\n",
    "            table.add(label, r'Baseline', filename)\n",
    "            table.add('', r'Baseline, shallow', filename + '_shallow')\n",
    "            table.add('', r'Baseline, deep', filename + '_deep')\n",
    "            \n",
    "            table.add('', r'Baseline, $\\alpha = 0.01$', filename + '_alpha_0.010')\n",
    "            table.add('', r'Baseline, $\\alpha = 0.02$', filename + '_alpha_0.020')\n",
    "            table.add('', r'Baseline, $\\alpha = 0.05$', filename + '_alpha_0.050')\n",
    "            table.add('', r'Baseline, $\\alpha = 0.1$', filename + '_alpha_0.10')\n",
    "            table.add('', r'Baseline, $\\alpha = 0.2$', filename + '_alpha_0.20')\n",
    "            table.add('', r'Baseline, $\\alpha = 0.5$', filename + '_alpha_0.50')\n",
    "            table.add('', r'Baseline, $\\alpha = 1$', filename + '_alpha_1.0')\n",
    "            table.add('', r'Baseline, $\\alpha = 2$', filename + '_alpha_2.0')\n",
    "            table.add('', r'Baseline, $\\alpha = 5$', filename + '_alpha_5.0')\n",
    "            table.add('', r'Baseline, $\\alpha = 10$', filename + '_alpha_10')\n",
    "            table.add('', r'Baseline, $\\alpha = 20$', filename + '_alpha_20')\n",
    "            table.add('', r'Baseline, $\\alpha = 50$', filename + '_alpha_50')\n",
    "            table.add('', r'Baseline, $\\alpha = 100$', filename + '_alpha_100')\n",
    "            \n",
    "            table.add('', r'Baseline, large batches', filename + '_largebatch')\n",
    "            table.add('', r'Baseline, small batches', filename + '_smallbatch')\n",
    "            table.add('', r'Baseline, const.\\ LR', filename + '_constantlr')\n",
    "            table.add('', r'Baseline, const.\\ LR, large batches', filename + '_constantlr_largebatch')\n",
    "            table.add('', r'Baseline, const.\\ LR, small batches', filename + '_constantlr_largebatch')\n",
    "            table.add('', r'Baseline, small LR', filename + '_slowlearning')\n",
    "            table.add('', r'Baseline, small LR, large batches', filename + '_slowlearning_largebatch')\n",
    "            table.add('', r'Baseline, small LR, small batches', filename + '_slowlearning_smallbatch')\n",
    "            table.add('', r'Baseline, small const.\\ LR', filename + '_slowlearning_constantlr')\n",
    "            table.add('', r'Baseline, small const.\\ LR, large batches', filename + '_slowlearning_constantlr_largebatch')\n",
    "            table.add('', r'Baseline, small const.\\ LR, small batches', filename + '_slowlearning_constantlr_smallbatch')\n",
    "            table.add('', r'Baseline, large LR', filename + '_fastlearning')\n",
    "            table.add('', r'Baseline, large LR, large batches', filename + '_fastlearning_largebatch')\n",
    "            table.add('', r'Baseline, large LR, small batches', filename + '_fastlearning_smallbatch')\n",
    "            table.add('', r'Baseline, large const.\\ LR', filename + '_fastlearning_constantlr')\n",
    "            table.add('', r'Baseline, large const.\\ LR, large batches', filename + '_fastlearning_constantlr_largebatch')\n",
    "            table.add('', r'Baseline, large const.\\ LR, small batches', filename + '_fastlearning_constantlr_smallbatch')\n",
    "            \n",
    "            table.add('', r'Random $\\boldtheta$, shallow', filename + '_random_shallow')\n",
    "            table.add('', r'Random $\\boldtheta$', filename + '_random')\n",
    "            table.add('', r'Random $\\boldtheta$, deep', filename + '_random_deep')\n",
    "            \n",
    "            table.add('', r'Morphing basis, shallow', filename + '_basis_shallow')\n",
    "            table.add('', r'Morphing basis', filename + '_basis')\n",
    "            table.add('', r'Morphing basis, deep', filename + '_basis_deep')\n",
    "\n",
    "    print(table.print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Histogram & $p_{T,j1}$ & 0.2633 & 0.0814\\\\\n",
      "    & $\\Delta \\phi_{jj}$ & 0.3233 & 0.0991\\\\\n",
      "    & 2d & \\emph{0.1545} & \\emph{0.0328}\\\\\n",
      "   \\midrule\n",
      "   AFC & 2d, $\\epsilon = 1$ & 0.2883 & 0.0757\\\\\n",
      "   AFC & 5d, $\\epsilon = 1$ & 0.2746 & 0.0677\\\\\n",
      "    & 5d, $\\epsilon = 0.5$ & \\emph{0.1866} & \\emph{0.0376}\\\\\n",
      "    & 5d, $\\epsilon = 0.2$ & 0.2168 & 0.0565\\\\\n",
      "    & 5d, $\\epsilon = 0.1$ & 2.7947 & 0.8854\\\\\n",
      "    & 5d, $\\epsilon = 0.05$ & 73.8664 & 13.2071\\\\\n",
      "    & 5d, $\\epsilon = 0.02$ & 6046.7529 & 240.5334\\\\\n",
      "    & 5d, $\\epsilon = 0.01$ & 151909.8097 & 16891.7454\\\\\n",
      "   \\midrule\n",
      "   carl (param., raw) & Baseline & 0.0288 & 0.0069\\\\\n",
      "    & Baseline, shallow & \\emph{0.0254} & \\emph{0.0060}\\\\\n",
      "    & Baseline, deep & 0.0309 & 0.0067\\\\\n",
      "    & Random $\\boldtheta$, shallow & 0.0275 & 0.0063\\\\\n",
      "    & Random $\\boldtheta$ & 0.0275 & 0.0064\\\\\n",
      "   \\midrule\n",
      "   carl (param., cal.) & Baseline & 0.0298 & 0.0060\\\\\n",
      "    & Baseline, shallow & \\emph{0.0245} & \\emph{0.0053}\\\\\n",
      "    & Baseline, deep & 0.0325 & 0.0059\\\\\n",
      "    & Random $\\boldtheta$, shallow & 0.0263 & 0.0056\\\\\n",
      "    & Random $\\boldtheta$ & 0.0285 & 0.0057\\\\\n",
      "   \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_main_table(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SM score regr.\\ + density est. & Fixed density est. on $t$ & \\emph{0.0311} & \\emph{0.0019}\\\\\n",
      "    & Dyn. dens. est. on $t$ & 0.0313 & 0.0020\\\\\n",
      "    & Dens. est. on $t \\cdot \\theta$ & 0.0585 & 0.0038\\\\\n",
      "   \\midrule\n",
      "   carl + score (param., raw) & Baseline & 0.0034 & 0.0007\\\\\n",
      "    & Baseline, shallow & 0.0065 & 0.0009\\\\\n",
      "    & Baseline, deep & \\emph{0.0026} & \\emph{0.0007}\\\\\n",
      "    & Baseline, $\\alpha = 0.1$ & 0.0063 & 0.0014\\\\\n",
      "    & Baseline, $\\alpha = 0.2$ & 0.0048 & 0.0011\\\\\n",
      "    & Baseline, $\\alpha = 0.5$ & 0.0038 & 0.0008\\\\\n",
      "    & Random $\\boldtheta$, shallow & 0.0068 & 0.0009\\\\\n",
      "    & Random $\\boldtheta$ & 0.0035 & 0.0007\\\\\n",
      "   \\midrule\n",
      "   carl + score (param., cal.) & Baseline & \\emph{0.0027} & \\emph{0.0006}\\\\\n",
      "    & Baseline, shallow & 0.0051 & 0.0007\\\\\n",
      "    & Baseline, $\\alpha = 0.1$ & 0.0061 & 0.0014\\\\\n",
      "    & Baseline, $\\alpha = 0.2$ & 0.0044 & 0.0009\\\\\n",
      "    & Random $\\boldtheta$, shallow & 0.0055 & 0.0007\\\\\n",
      "    & Random $\\boldtheta$ & 0.0028 & 0.0006\\\\\n",
      "   \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_main_table(7,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ratio regression (param., raw) & Baseline & \\emph{0.0055} & 0.0030\\\\\n",
      "    & Baseline, shallow & 0.0098 & 0.0052\\\\\n",
      "    & Random $\\boldtheta$ & 0.0055 & \\emph{0.0030}\\\\\n",
      "   \\midrule\n",
      "   Ratio regression (param., cal.) & Baseline & \\emph{0.0052} & 0.0028\\\\\n",
      "    & Baseline, shallow & 0.0090 & 0.0047\\\\\n",
      "    & Random $\\boldtheta$ & 0.0053 & \\emph{0.0028}\\\\\n",
      "   \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_main_table(12,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ratio + score regr.\\ (param., raw) & Baseline & 0.0018 & 0.0007\\\\\n",
      "    & Baseline, shallow & 0.0044 & 0.0012\\\\\n",
      "    & Baseline, $\\alpha = 5$ & 0.0022 & 0.0009\\\\\n",
      "    & Baseline, $\\alpha = 10$ & 0.0019 & 0.0008\\\\\n",
      "    & Baseline, $\\alpha = 50$ & \\emph{0.0017} & \\emph{0.0007}\\\\\n",
      "    & Random $\\boldtheta$ & 0.0018 & 0.0007\\\\\n",
      "   \\midrule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_main_table(18,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score accuracy table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7982ea683700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'Baseline, shallow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_shallow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8c811ec982a5>\u001b[0m in \u001b[0;36mnew_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalise_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_in_last_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidrule\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-8c811ec982a5>\u001b[0m in \u001b[0;36mfinalise_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mblock_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mblock_best\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "labels = ['carl (param.)',\n",
    "          'carl (aware)',\n",
    "          'carl + score regr.\\ (param.)',\n",
    "          'carl + score regr.\\ (aware)',\n",
    "          'Ratio regression (param.)',\n",
    "          'Ratio regression (aware)',\n",
    "          'Ratio + score regr.\\ (param.)',\n",
    "          'Ratio + score regr.\\ (aware)']\n",
    "\n",
    "filenames = ['carl',\n",
    "             'carl_aware',\n",
    "             'combined',\n",
    "             'combined_aware',\n",
    "             'regression',\n",
    "             'regression_aware',\n",
    "             'combinedregression',\n",
    "             'combinedregression_aware']\n",
    "\n",
    "table = TablePrinter([trimmed_mse_score_nottrained],\n",
    "                      precisions=[2])\n",
    "\n",
    "for i, (label, filename) in enumerate(zip(labels, filenames)):\n",
    "    \n",
    "    if i > 0:\n",
    "        table.new_block()\n",
    "        \n",
    "        table.add(label, r'Baseline, shallow', filename + '_shallow')\n",
    "        table.add(label, r'Baseline', filename)\n",
    "        table.add('', r'Baseline, deep', filename + '_deep')\n",
    "\n",
    "        table.add('', r'Baseline, $\\alpha = 0.01$', filename + '_alpha_0.010')\n",
    "        table.add('', r'Baseline, $\\alpha = 0.02$', filename + '_alpha_0.020')\n",
    "        table.add('', r'Baseline, $\\alpha = 0.05$', filename + '_alpha_0.050')\n",
    "        table.add('', r'Baseline, $\\alpha = 0.1$', filename + '_alpha_0.10')\n",
    "        table.add('', r'Baseline, $\\alpha = 0.2$', filename + '_alpha_0.20')\n",
    "        table.add('', r'Baseline, $\\alpha = 0.5$', filename + '_alpha_0.50')\n",
    "        table.add('', r'Baseline, $\\alpha = 1$', filename + '_alpha_1.0')\n",
    "        table.add('', r'Baseline, $\\alpha = 2$', filename + '_alpha_2.0')\n",
    "        table.add('', r'Baseline, $\\alpha = 5$', filename + '_alpha_5.0')\n",
    "        table.add('', r'Baseline, $\\alpha = 10$', filename + '_alpha_10')\n",
    "        table.add('', r'Baseline, $\\alpha = 20$', filename + '_alpha_20')\n",
    "        table.add('', r'Baseline, $\\alpha = 50$', filename + '_alpha_50')\n",
    "        table.add('', r'Baseline, $\\alpha = 100$', filename + '_alpha_100')\n",
    "\n",
    "        table.add('', r'Baseline, large batches', filename + '_largebatch')\n",
    "        table.add('', r'Baseline, small batches', filename + '_smallbatch')\n",
    "        table.add('', r'Baseline, const.\\ LR', filename + '_constantlr')\n",
    "        table.add('', r'Baseline, const.\\ LR, large batches', filename + '_constantlr_largebatch')\n",
    "        table.add('', r'Baseline, const.\\ LR, small batches', filename + '_constantlr_largebatch')\n",
    "        table.add('', r'Baseline, small LR', filename + '_slowlearning')\n",
    "        table.add('', r'Baseline, small LR, large batches', filename + '_slowlearning_largebatch')\n",
    "        table.add('', r'Baseline, small LR, small batches', filename + '_slowlearning_smallbatch')\n",
    "        table.add('', r'Baseline, small const.\\ LR', filename + '_slowlearning_constantlr')\n",
    "        table.add('', r'Baseline, small const.\\ LR, large batches', filename + '_slowlearning_constantlr_largebatch')\n",
    "        table.add('', r'Baseline, small const.\\ LR, small batches', filename + '_slowlearning_constantlr_smallbatch')\n",
    "        table.add('', r'Baseline, large LR', filename + '_fastlearning')\n",
    "        table.add('', r'Baseline, large LR, large batches', filename + '_fastlearning_largebatch')\n",
    "        table.add('', r'Baseline, large LR, small batches', filename + '_fastlearning_smallbatch')\n",
    "        table.add('', r'Baseline, large const.\\ LR', filename + '_fastlearning_constantlr')\n",
    "        table.add('', r'Baseline, large const.\\ LR, large batches', filename + '_fastlearning_constantlr_largebatch')\n",
    "        table.add('', r'Baseline, large const.\\ LR, small batches', filename + '_fastlearning_constantlr_smallbatch')\n",
    "\n",
    "        table.add('', r'Random $\\boldtheta$, shallow', filename + '_random_shallow')\n",
    "        table.add('', r'Random $\\boldtheta$', filename + '_random')\n",
    "        table.add('', r'Random $\\boldtheta$, deep', filename + '_random_deep')\n",
    "\n",
    "        table.add('', r'Morphing basis, shallow', filename + '_basis_shallow')\n",
    "        table.add('', r'Morphing basis', filename + '_basis')\n",
    "        table.add('', r'Morphing basis, deep', filename + '_basis_deep')\n",
    "\n",
    "print(table.print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
