{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import LinearNDInterpolator, CloughTocher2DInterpolator\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.mlab import griddata\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append('..')\n",
    "from higgs_inference.various.utils import interpolate, format_number, asymptotic_p_value\n",
    "from higgs_inference import settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio expectation recalibration\n",
    "use_recalibration = False\n",
    "use_separate_recalibration_sample = False\n",
    "\n",
    "# Which benchmark point to use\n",
    "use_not_trained_benchmark = True\n",
    "\n",
    "# Which algorithm to use for the PbP vs parameterized vs morphing-aware plot\n",
    "use_regression_as_pbp_param_aware_example = False  # If False, use carl\n",
    "\n",
    "# Neyman settings\n",
    "neyman_plots = True\n",
    "remove_duplicates_for_nc = False\n",
    "\n",
    "# Interpolation in final plot.\n",
    "interpolation_method = 'gp' #'linear', 'gp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors     = ['black', '0.65', '#CC002E',  'c',    'mediumblue', 'darkgreen', 'orange', 'orange', '#CC002E', 'mediumblue']\n",
    "linestyles = [  '-',     ':',   '--',   '-.',    ':',      '-.',          '--',        '-',         '--',  ':']\n",
    "linewidths = [  1.5,     2.,    1.5,     1.5,    2.,       1.5,            1.5,         1.5,          1.5,  2]\n",
    "band_alpha = [ 0.2,       0.4,     0.2,    0.4,       0.2,           0.2,         0.4,    0.4,        0.2,      0.2]\n",
    "\n",
    "scatter_alpha = 1.\n",
    "\n",
    "def lighter_color(color, fraction_white=0.5):\n",
    "    rgb = np.asarray(matplotlib.colors.to_rgb(color))\n",
    "    white = np.asarray((1.,1.,1.))\n",
    "    return fraction_white * white + (1. - fraction_white)*rgb\n",
    "\n",
    "#for color in colors:\n",
    "#    print(color, matplotlib.colors.to_rgb(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.load('../data/thetas/thetas_parameterized.npy')\n",
    "\n",
    "n_thetas = len(thetas)\n",
    "theta1 = 708\n",
    "theta_observed = 0\n",
    "thetas_train = list(range(17,1017))\n",
    "thetas_test = list(range(17))\n",
    "\n",
    "if use_not_trained_benchmark:\n",
    "    theta_benchmark = 9\n",
    "    benchmark_name = 'nottrained'\n",
    "else:\n",
    "    theta_benchmark = 422\n",
    "    benchmark_name = 'trained'\n",
    "    \n",
    "pbp_training_thetas = [0, 13, 14, 15, 16, 9, 422, 956, 666, 802, 675, 839, 699, 820, 203, 291, 634, 371, 973, 742, 901, 181, 82, 937, 510, 919, 745, 588, 804, 963, 396, 62, 401, 925, 874, 770, 108, 179, 669, 758, 113, 587, 600, 975, 496, 66, 467, 412, 701, 986, 598, 810, 97, 18, 723, 159, 320, 301, 352, 159, 89, 421, 574, 923, 849, 299, 119, 167, 939, 402, 52, 787, 978, 41, 873, 533, 827, 304, 294, 760, 890, 539, 1000, 291, 740, 276, 679, 167, 125, 429, 149, 430, 720, 123, 908, 256, 777, 809, 269, 851]\n",
    "basis_thetas = [0, 101, 106, 902, 910,\n",
    "                226, 373, 583, 747, 841,\n",
    "                599, 709, 422, 367, 167]\n",
    "thetas_highlighted = []\n",
    "\n",
    "#print(thetas[theta1])\n",
    "#print(thetas[theta_benchmark])\n",
    "\n",
    "X_observed = np.load('../data/unweighted_events/X_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_l_absolute = 8. * 0.1\n",
    "margin_r_absolute = 8. * 0.02\n",
    "margin_sep_absolute = 8. * 0.02\n",
    "margin_t_absolute = 8. * 0.02\n",
    "margin_b_absolute = 8. * 0.08\n",
    "\n",
    "def calculate_height(n_panels=2, width=8.):\n",
    "    \n",
    "    if isinstance(n_panels, collections.Sequence):\n",
    "        n_panels_h, n_panels_v = n_panels\n",
    "    else:\n",
    "        n_panels_h = n_panels\n",
    "        n_panels_v = 1\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    margin_l = margin_l_absolute / width\n",
    "    margin_r = margin_r_absolute / width\n",
    "    margin_l_subsequent = margin_l\n",
    "    if n_panels_h > 2:\n",
    "        margin_l_subsequent = margin_r\n",
    "    margin_sep = margin_sep_absolute / width\n",
    "    if n_panels_h > 2:\n",
    "        margin_sep = 0\n",
    "    margin_sep_total = margin_r + margin_sep + margin_l_subsequent\n",
    "    panel_width = (1. - margin_l - margin_r - (n_panels_h - 1)*margin_sep_total) / n_panels_h\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    wspace = margin_sep_total / panel_width\n",
    "    \n",
    "    # Calculate absolute height\n",
    "    panel_height_absolute = panel_width * width # Square plots\n",
    "    height = n_panels_v * (panel_height_absolute + margin_t_absolute + margin_b_absolute) + (n_panels_v - 1) * margin_sep_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    panel_height = panel_height_absolute / height\n",
    "    margin_t = margin_t_absolute / height\n",
    "    margin_b = margin_b_absolute / height\n",
    "    margin_sep_total = (margin_t + margin_b + margin_sep_absolute / height)\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    hspace = margin_sep_total / panel_height\n",
    "    \n",
    "    # Return height\n",
    "    return height\n",
    "\n",
    "\n",
    "def adjust_margins(n_panels=2, width=8.):\n",
    "    \n",
    "    if isinstance(n_panels, collections.Sequence):\n",
    "        n_panels_h, n_panels_v = n_panels\n",
    "    else:\n",
    "        n_panels_h = n_panels\n",
    "        n_panels_v = 1\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    margin_l = margin_l_absolute / width\n",
    "    margin_r = margin_r_absolute / width\n",
    "    margin_l_subsequent = margin_l\n",
    "    if n_panels_h > 2:\n",
    "        margin_l_subsequent = margin_r\n",
    "    margin_sep = margin_sep_absolute / width\n",
    "    if n_panels_h > 2:\n",
    "        margin_sep = 0\n",
    "    margin_sep_total = margin_r + margin_sep + margin_l_subsequent\n",
    "    panel_width = (1. - margin_l - margin_r - (n_panels_h - 1)*margin_sep_total) / n_panels_h\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    wspace = margin_sep_total / panel_width\n",
    "    \n",
    "    # Calculate absolute height\n",
    "    panel_height_absolute = panel_width * width # Square plots\n",
    "    height = n_panels_v * (panel_height_absolute + margin_t_absolute + margin_b_absolute) + (n_panels_v - 1) * margin_sep_absolute\n",
    "    \n",
    "    # Calculate horizontal margins. Units: relative to width.\n",
    "    panel_height = panel_height_absolute / height\n",
    "    margin_t = margin_t_absolute / height\n",
    "    margin_b = margin_b_absolute / height\n",
    "    margin_sep_total = (margin_t + margin_b + margin_sep_absolute / height)\n",
    "    \n",
    "    # Calculate wspace argument of subplots_adjust\n",
    "    hspace = margin_sep_total / panel_height\n",
    "    \n",
    "    # Set margins\n",
    "    plt.subplots_adjust(left = margin_l,\n",
    "                        right = 1. - margin_r,\n",
    "                        bottom = margin_b,\n",
    "                        top = 1. - margin_t,\n",
    "                        wspace = wspace)\n",
    "    \n",
    "#print(calculate_height(2,8.))\n",
    "#print(calculate_height(3,8.))\n",
    "#print(calculate_height((2,2),8.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define strategies and load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load(name, folder='parameterized'):\n",
    "    return np.load('../results/' + folder + '/' + name + '.npy')\n",
    "\n",
    "def add_strategy(label, suffix, folder,\n",
    "                 suffices_ensemble=None, suffix_uncalibrated=None,\n",
    "                 panel=-1, in_pbp_param_aware_plot=False, in_main_plot=True, is_truth=False,\n",
    "                 zorder=None, exponentiate_uncalibrated=False):\n",
    "    \n",
    "    neyman_string = 'neyman3' if remove_duplicates_for_nc else 'neyman2'\n",
    "    \n",
    "    try:\n",
    "        _expected_llr = _load('llr_' + suffix, folder)\n",
    "        _r_benchmark = _load('r_' + benchmark_name + '_' + suffix, folder)\n",
    "    except IOError:\n",
    "        print('Results for strategy ' + label + ' not found')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        _mse_log_r = _load('mse_logr_' + suffix, folder)\n",
    "        _trimmed_mse_log_r = _load('trimmed_mse_logr_' + suffix, folder)\n",
    "        do_mse_log_r = True\n",
    "    except IOError:\n",
    "        _mse_log_r = None\n",
    "        _trimmed_mse_log_r = None\n",
    "        do_mse_log_r = False\n",
    "        \n",
    "    if suffix_uncalibrated is not None:\n",
    "        try:\n",
    "            _r_benchmark_uncalibrated = _load('r_' + benchmark_name + '_' + suffix_uncalibrated, folder)\n",
    "            if exponentiate_uncalibrated:\n",
    "                _r_benchmark_uncalibrated = np.exp(_r_benchmark_uncalibrated)\n",
    "            do_calibration = True\n",
    "        except IOError:\n",
    "            _r_benchmark_uncalibrated = None\n",
    "            do_calibration = False\n",
    "    else:\n",
    "        _r_benchmark_uncalibrated = None\n",
    "        do_calibration = False\n",
    "        \n",
    "    if suffices_ensemble is not None:\n",
    "        try:\n",
    "            _expected_llr_ensemble = []\n",
    "            for i in range(4):\n",
    "                _filename = 'llr_' + suffices_ensemble.replace(r'%i', str(i+1))\n",
    "                _expected_llr_ensemble.append(_load(_filename, folder))\n",
    "            do_diagnostics = True\n",
    "        except IOError:\n",
    "            do_diagnostics = False\n",
    "            _expected_llr_ensemble = None\n",
    "    else:\n",
    "        do_diagnostics = False\n",
    "        _expected_llr_ensemble = None\n",
    "    \n",
    "    try:\n",
    "        _p_values = _load(neyman_string + '_pvalues_' + suffix, folder)\n",
    "        _q_thresholds = _load(neyman_string + '_qcut_' + suffix, folder)\n",
    "        _q_threshold_uncertainties = _load(neyman_string + '_qcut_uncertainties_' + suffix, folder)\n",
    "        _q_medians = _load(neyman_string + '_qmedian_' + suffix, folder)\n",
    "        do_neyman = True\n",
    "        \n",
    "        assert not np.all(np.isnan(_q_thresholds)), 'q thresholds contain only NaNs'\n",
    "        assert not np.all(np.isnan(_q_medians)), 'q medians contain only NaNs'\n",
    "        assert not np.all(np.isnan(_q_threshold_uncertainties)), 'q threshold uncertainties contain only NaNs'\n",
    "    except IOError:\n",
    "        _p_values = None\n",
    "        _q_thresholds = None\n",
    "        _q_threshold_uncertainties = None\n",
    "        _q_medians = None\n",
    "        do_neyman = False\n",
    "    except AssertionError as err:\n",
    "        _p_values = None\n",
    "        _q_thresholds = None\n",
    "        _q_threshold_uncertainties = None\n",
    "        _q_medians = None\n",
    "        do_neyman = False\n",
    "        \n",
    "    recalibration_string = 'recalibration_expected_r_vs_sm_' if use_separate_recalibration_sample else 'expected_r_vs_sm_'\n",
    "        \n",
    "    try:\n",
    "        _recalibration_correction = 2. * settings.n_expected_events * np.log(_load(recalibration_string + suffix, folder))\n",
    "        do_recalibration = True\n",
    "    except IOError:\n",
    "        _recalibration_correction = None\n",
    "        do_recalibration = False\n",
    "        \n",
    "    if suffices_ensemble is not None and do_recalibration:\n",
    "        try:\n",
    "            _recalibration_correction_ensemble = []\n",
    "            for i in range(4):\n",
    "                _filename = recalibration_string + suffices_ensemble.replace(r'%i', str(i+1))\n",
    "                _ratio_expectation = _load(_filename, folder)\n",
    "                _recalibration_correction_ensemble.append(2. * settings.n_expected_events * np.log(_ratio_expectation))\n",
    "            do_ensemble_recalibration = True\n",
    "        except IOError:\n",
    "            do_ensemble_recalibration = False\n",
    "            _recalibration_correction_ensemble = None\n",
    "    else:\n",
    "        do_ensemble_recalibration = False\n",
    "        _recalibration_correction_ensemble = None\n",
    "        \n",
    "    try:\n",
    "        _recalibration_correction_uncertainty = _load('recalibration_uncertainty_' + suffix, folder)\n",
    "        do_recalibration_uncertainty = True\n",
    "    except IOError:\n",
    "        _recalibration_correction_uncertainty = None\n",
    "        do_recalibration_uncertainty = False\n",
    "    \n",
    "    try:\n",
    "        _r_roam = _load('r_roam_' + suffix, folder)\n",
    "        do_roaming = True\n",
    "    except IOError:\n",
    "        _r_roam = None\n",
    "        do_roaming = False\n",
    "        \n",
    "    try:\n",
    "        _mle_thetas = _load('neyman_mle_' + suffix, folder)\n",
    "        do_mle = True\n",
    "    except IOError:\n",
    "        _mle_thetas = None\n",
    "        do_mle = False\n",
    "        \n",
    "    labels.append(label)\n",
    "    suffices.append(suffix)\n",
    "    \n",
    "    expected_llr.append(_expected_llr)\n",
    "    expected_llr_ensemble.append(_expected_llr_ensemble)\n",
    "    mse_log_r.append(_mse_log_r)\n",
    "    trimmed_mse_log_r.append(_trimmed_mse_log_r)\n",
    "    p_values.append(_p_values)\n",
    "    q_medians.append(_q_medians)\n",
    "    q_threshold_uncertainties.append(_q_threshold_uncertainties)\n",
    "    q_thresholds.append(_q_thresholds)\n",
    "    mle_thetas.append(_mle_thetas)\n",
    "    r_benchmark.append(_r_benchmark)\n",
    "    r_benchmark_uncalibrated.append(_r_benchmark_uncalibrated)\n",
    "    r_roam.append(_r_roam)\n",
    "    recalibration_correction.append(_recalibration_correction)\n",
    "    recalibration_correction_ensemble.append(_recalibration_correction_ensemble)\n",
    "    recalibration_correction_uncertainty.append(_recalibration_correction_uncertainty)\n",
    "    \n",
    "    index = len(labels) - 1\n",
    "    if is_truth:\n",
    "        truth_index = index\n",
    "    if panel >= 0 and panel < 3:\n",
    "        panel_indices[panel].append(index)\n",
    "    in_pbp_param_aware_plots.append(in_pbp_param_aware_plot)\n",
    "    in_main_plots.append(in_main_plot)\n",
    "    \n",
    "    zorders.append(zorder)\n",
    "        \n",
    "    if do_neyman or do_recalibration or do_ensemble_recalibration or do_recalibration_uncertainty or do_roaming or do_mle or do_diagnostics or do_calibration:\n",
    "        supported = []\n",
    "        if do_diagnostics:\n",
    "            supported.append('ensemble')\n",
    "        if do_recalibration:\n",
    "            supported.append('recalibration')\n",
    "        if do_ensemble_recalibration:\n",
    "            supported.append('ens. rec.')\n",
    "        if do_recalibration_uncertainty:\n",
    "            supported.append('recalibration uncertainty')\n",
    "        if do_neyman:\n",
    "            supported.append('NC')\n",
    "        if do_mle:\n",
    "            supported.append('MLE')\n",
    "        if do_roaming:\n",
    "            supported.append('theta dependence')\n",
    "        if do_calibration:\n",
    "            supported.append('calibration')\n",
    "        supported = ', '.join(supported)\n",
    "            \n",
    "        print('Loaded strategy {}: {} ({})'.format(len(labels) - 1, label, supported))\n",
    "        \n",
    "    else:\n",
    "        print('Loaded strategy {}: {}'.format(len(labels) - 1, label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded strategy 0: Truth (ensemble, NC, MLE, theta dependence, calibration)\n",
      "Loaded strategy 1: Histogram (ensemble)\n",
      "Loaded strategy 2: CARL (ensemble, recalibration, ens. rec., recalibration uncertainty, NC, theta dependence, calibration)\n",
      "Loaded strategy 3: Local score regression (ensemble, recalibration, ens. rec., NC, calibration)\n",
      "Loaded strategy 4: Ratio regression (ensemble, recalibration, ens. rec., recalibration uncertainty, theta dependence, calibration)\n",
      "Loaded strategy 5: CARL + score regr. (ensemble, recalibration, ens. rec., recalibration uncertainty, NC, theta dependence, calibration)\n",
      "Loaded strategy 6: Ratio + score regr. (ensemble, recalibration, ens. rec., recalibration uncertainty, theta dependence, calibration)\n",
      "\n",
      "Loaded strategy 7: CARL point by point\n",
      "Loaded strategy 8: CARL parameterized (recalibration, recalibration uncertainty, NC, theta dependence)\n",
      "Loaded strategy 9: CARL morphing-aware (theta dependence)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "suffices = []\n",
    "folders = []\n",
    "\n",
    "truth_index = 0\n",
    "panel_indices = ([], [])\n",
    "panel_indices = ([], [], [])\n",
    "in_pbp_param_aware_plots = []\n",
    "in_main_plots = []\n",
    "\n",
    "expected_llr = []\n",
    "expected_llr_ensemble = []\n",
    "mse_log_r = []\n",
    "trimmed_mse_log_r = []\n",
    "p_values = []\n",
    "q_medians = []\n",
    "q_thresholds = []\n",
    "q_threshold_uncertainties = []\n",
    "mle_thetas = []\n",
    "r_benchmark = []\n",
    "r_benchmark_uncalibrated = []\n",
    "r_roam = []\n",
    "recalibration_correction = []\n",
    "recalibration_correction_ensemble = []\n",
    "recalibration_correction_uncertainty = []\n",
    "\n",
    "zorders = []\n",
    "\n",
    "add_strategy('Truth', 'truth', 'truth', 'truth_denom%i', 'truth_calibrated', is_truth=True)\n",
    "\n",
    "add_strategy('Histogram', 'histo_2d', 'histo', 'histo_2d_denom%i', panel=0)\n",
    "add_strategy('CARL', 'carl_calibrated_shallow', 'parameterized', 'carl_calibrated_shallow_denom%i', 'carl_shallow', panel=0)\n",
    "add_strategy('Local score regression', 'scoreregression_score_deep', 'score_regression', 'scoreregression_score_deep_denom%i', 'scoreregression_deep', panel=1, exponentiate_uncalibrated=True)\n",
    "add_strategy('Ratio regression', 'regression_calibrated', 'parameterized', 'regression_calibrated_denom%i', 'regression', panel=1)\n",
    "add_strategy('CARL + score regr.', 'combined_calibrated_deep', 'parameterized', 'combined_calibrated_deep_denom%i', 'combined_deep', panel=2)\n",
    "add_strategy('Ratio + score regr.', 'combinedregression_calibrated_deep', 'parameterized', 'combinedregression_calibrated_deep_denom%i', 'combinedregression_deep', panel=2)\n",
    "\n",
    "print('')\n",
    "\n",
    "if use_regression_as_pbp_param_aware_example:\n",
    "    add_strategy('Ratio regr. point by point', 'regression_calibrated', 'point_by_point',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=2)\n",
    "    add_strategy('Ratio regr. parameterized', 'regression_calibrated', 'parameterized',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=3)\n",
    "    add_strategy('Ratio regr. morphing-aware', 'regression_calibrated_aware', 'parameterized',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=1)\n",
    "else:\n",
    "    add_strategy('CARL point by point', 'carl_calibrated', 'point_by_point',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=2)\n",
    "    add_strategy('CARL parameterized', 'carl_calibrated_shallow', 'parameterized',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=3)\n",
    "    add_strategy('CARL morphing-aware', 'carl_calibrated_aware_shallow', 'parameterized',\n",
    "                 panel=-1, in_pbp_param_aware_plot=True, in_main_plot=False, zorder=1)\n",
    "\n",
    "n_strategies = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannbrehmer/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / np.sqrt(D.sum(2))[:, :, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# grid\n",
    "thetas_filtered = thetas[:]\n",
    "xi = np.linspace(-1.0, 1.0, 200)\n",
    "yi = np.linspace(-1.0, 1.0, 200)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "# One run\n",
    "interpolated_expected_llr_mle = []\n",
    "interpolated_expected_llr = []\n",
    "interpolated_expected_llr_rc_error = []\n",
    "\n",
    "# Ensemble\n",
    "interpolated_expected_llr_median = []\n",
    "interpolated_expected_llr_min = []\n",
    "interpolated_expected_llr_max = []\n",
    "\n",
    "for llr, llr_ensemble, rc, rc_ensemble, rc_error in zip(expected_llr, expected_llr_ensemble,\n",
    "                                                        recalibration_correction,\n",
    "                                                        recalibration_correction_ensemble,\n",
    "                                                        recalibration_correction_uncertainty):\n",
    "    \n",
    "    if rc is None:\n",
    "        rc = np.zeros_like(llr)\n",
    "    if rc_error is None:\n",
    "        rc_error = np.zeros_like(llr)\n",
    "    if rc_ensemble is None:\n",
    "        rc_ensemble = [rc for i in range(4)]\n",
    "    rc_ensemble = np.asarray(rc_ensemble)\n",
    "    if not use_recalibration:\n",
    "        rc[:] = 0.\n",
    "        rc_error[:] = 0.\n",
    "        rc_ensemble[:,:] = 0.\n",
    "        \n",
    "    _llr, _mle = interpolate(thetas, llr + rc, xx, yy, method=interpolation_method, subtract_min=False)\n",
    "    _llr -= llr[settings.theta_observed] + rc[settings.theta_observed]\n",
    "    \n",
    "    _rc_error, _  = interpolate(thetas, rc_error, xx, yy, method=interpolation_method, subtract_min=False)\n",
    "    \n",
    "    if llr_ensemble is not None:\n",
    "        _llr_ensemble = [_llr]\n",
    "        \n",
    "        for i, (llr_this_run, rc_this_run) in enumerate(zip(llr_ensemble, rc_ensemble)):\n",
    "            _llr_this_run, _ = interpolate(thetas, llr_this_run + rc_this_run, xx, yy,\n",
    "                                      method=interpolation_method, subtract_min=False)\n",
    "            _llr_this_run -= llr_this_run[settings.theta_observed] + rc_this_run[settings.theta_observed]\n",
    "            _llr_ensemble.append(_llr_this_run)\n",
    "        _llr_ensemble = np.asarray(_llr_ensemble)\n",
    "        \n",
    "        _llr_median = np.median(_llr_ensemble, axis=0)\n",
    "        _llr_min = np.min(_llr_ensemble, axis=0)\n",
    "        _llr_max = np.max(_llr_ensemble, axis=0)\n",
    "            \n",
    "    else:\n",
    "        _llr_median = _llr\n",
    "        _llr_min = _llr\n",
    "        _llr_max = _llr\n",
    "        \n",
    "    interpolated_expected_llr.append(_llr)\n",
    "    interpolated_expected_llr_mle.append(_mle)\n",
    "    interpolated_expected_llr_median.append(_llr_median)\n",
    "    interpolated_expected_llr_min.append(_llr_min)\n",
    "    interpolated_expected_llr_max.append(_llr_max)\n",
    "    interpolated_expected_llr_rc_error.append(_rc_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neyman_plots:\n",
    "    interpolated_q_medians = []\n",
    "    interpolated_q_thresholds = []\n",
    "    interpolated_cl_excluded = []\n",
    "\n",
    "    for i, (qmed, qthresh, qthresh_err) in enumerate(zip(q_medians, q_thresholds, q_threshold_uncertainties)):\n",
    "            \n",
    "        print('Starting strategy {} / {}'.format(i + 1, n_strategies))\n",
    "\n",
    "        if qmed is None or qthresh is None or qthresh_err is None:\n",
    "            interpolated_q_medians.append(None)\n",
    "            interpolated_q_thresholds.append(None)\n",
    "            interpolated_cl_excluded.append(None)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            cut = np.all(np.isfinite(qthresh),axis=1) & (np.isfinite(qmed)) & np.all(np.isfinite(qthresh_err),axis=1)\n",
    "            \n",
    "            _qmed, _ = interpolate(thetas[cut], qmed[cut], xx, yy,\n",
    "                                  method='gp',\n",
    "                                  length_scale_default=0.1, length_scale_min=0.01, length_scale_max=1.,\n",
    "                                  matern_exponent=2.5,\n",
    "                                  noise_level=0.01)\n",
    "            \n",
    "            _qthreshs = []\n",
    "            for j in range(len(settings.confidence_levels)):\n",
    "                _qthresh, _ = interpolate(thetas[cut], qthresh[cut,j], xx, yy,\n",
    "                                         z_uncertainties_thetas=2*qthresh_err[cut,j],\n",
    "                                         method='gp',\n",
    "                                         length_scale_default=1., length_scale_min=0.5, length_scale_max=2.,\n",
    "                                         matern_exponent=2.5,\n",
    "                                         noise_level=0.01)\n",
    "                _qthreshs.append(copy.deepcopy(_qthresh))\n",
    "            _qthreshs = np.asarray(_qthreshs)\n",
    "\n",
    "            _excludeds = np.asarray([_qmed - _qthreshs[j] for j in range(_qthreshs.shape[0])])\n",
    "\n",
    "            interpolated_q_medians.append(_qmed)\n",
    "            interpolated_q_thresholds.append(_qthreshs)\n",
    "            interpolated_cl_excluded.append(_excludeds)\n",
    "            \n",
    "            # Debug plot\n",
    "            zmin, zmax = -20.,20.\n",
    "            plt.figure(figsize=(10,8))\n",
    "\n",
    "            plt.subplot(2,2,1)\n",
    "            zi = np.clip(_qmed,zmin,zmax)\n",
    "            cs = plt.contourf(xi, yi, zi, 100, cmap='viridis_r', vmin=zmin, vmax=zmax)\n",
    "            plt.scatter(thetas[:,0], thetas[:,1], c=qmed[:],\n",
    "                        s=30., lw=0.5, cmap='viridis_r', edgecolors='k', vmin=zmin, vmax=zmax)\n",
    "            cbar = plt.colorbar()\n",
    "            cs = plt.contour(xi, yi, zi, [settings.q_threshold],\n",
    "                             linewidths=1.5, colors='w',\n",
    "                             linestyles='solid')\n",
    "            plt.xlim(-1.,1.)\n",
    "            plt.ylim(-1.,1.)\n",
    "            plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "            plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "            cbar.set_label('Median observed $q$')\n",
    "            \n",
    "            for j in range(len(settings.confidence_levels)):\n",
    "                plt.subplot(2,2,j+2)\n",
    "                zi = np.clip(_qthreshs[j], zmin, zmax)\n",
    "                cs = plt.contourf(xi, yi, zi, 100, cmap='viridis_r', vmin=zmin, vmax=zmax)\n",
    "                plt.scatter(thetas[:,0], thetas[:,1], c=qthresh[:,j],\n",
    "                            s=30., lw=0.5, cmap='viridis_r', edgecolors='k', vmin=zmin, vmax=zmax)\n",
    "                cbar = plt.colorbar()\n",
    "                plt.xlim(-1.,1.)\n",
    "                plt.ylim(-1.,1.)\n",
    "                plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "                plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "                cbar.set_label('$q$ threshold')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"../figures/neyman/cl_interpolation_\" + suffices[i] + \".pdf\")\n",
    "\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "            interpolated_q_medians.append(None)\n",
    "            interpolated_q_thresholds.append(None)\n",
    "            interpolated_cl_excluded.append(None)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate p values from Asimov data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One run\n",
    "interpolated_p_values_asymptotics = []\n",
    "interpolated_p_values_asymptotics_minus_rc_error = []\n",
    "interpolated_p_values_asymptotics_plus_rc_error = []\n",
    "\n",
    "# Ensemble\n",
    "interpolated_p_values_asymptotics_median = []\n",
    "interpolated_p_values_asymptotics_lower_bound = []\n",
    "interpolated_p_values_asymptotics_upper_bound = []\n",
    "\n",
    "for i, (llrs, rc_errors) in enumerate(zip(interpolated_expected_llr, interpolated_expected_llr_rc_error)):\n",
    "    print('Starting', i+1, '/', len(interpolated_expected_llr))\n",
    "    \n",
    "    pvals = []\n",
    "    pvals_plus = []\n",
    "    pvals_minus = []\n",
    "    \n",
    "    for llr, rc_error in zip(llrs.flatten(), rc_errors.flatten()):\n",
    "        pvals.append(asymptotic_p_value(llr, use_median_rather_than_asimov=True))\n",
    "        pvals_plus.append(asymptotic_p_value(llr + rc_error, use_median_rather_than_asimov=True))\n",
    "        pvals_minus.append(asymptotic_p_value(llr - rc_error, use_median_rather_than_asimov=True))\n",
    "        \n",
    "    pvals = np.asarray(pvals)\n",
    "    pvals_plus = np.asarray(pvals_plus)\n",
    "    pvals_minus = np.asarray(pvals_minus)\n",
    "    \n",
    "    pvals = pvals.reshape(llrs.shape)\n",
    "    pvals_plus = pvals_plus.reshape(llrs.shape)\n",
    "    pvals_minus = pvals_minus.reshape(llrs.shape)\n",
    "    \n",
    "    interpolated_p_values_asymptotics.append(pvals)\n",
    "    interpolated_p_values_asymptotics_plus_rc_error.append(pvals_plus)\n",
    "    interpolated_p_values_asymptotics_minus_rc_error.append(pvals_minus)\n",
    "    \n",
    "for i, (medians, mins, maxs) in enumerate(zip(interpolated_expected_llr_median,\n",
    "                                              interpolated_expected_llr_min, interpolated_expected_llr_max)):\n",
    "    print('Starting', i+1, '/', len(interpolated_expected_llr_median))\n",
    "    \n",
    "    pvals_median = []\n",
    "    pvals_lower = []\n",
    "    pvals_upper = []\n",
    "                         \n",
    "    for median, lmin, lmax in zip(medians.flatten(), mins.flatten(), maxs.flatten()):\n",
    "        pvals_median.append(asymptotic_p_value(median, use_median_rather_than_asimov=True))\n",
    "        pvals_lower.append(asymptotic_p_value(lmin, use_median_rather_than_asimov=True))\n",
    "        pvals_upper.append(asymptotic_p_value(lmax, use_median_rather_than_asimov=True))\n",
    "                         \n",
    "    pvals_median = np.asarray(pvals_median)\n",
    "    pvals_lower = np.asarray(pvals_lower)\n",
    "    pvals_upper = np.asarray(pvals_upper)\n",
    "                         \n",
    "    pvals_median = pvals_median.reshape(medians.shape)\n",
    "    pvals_lower = pvals_lower.reshape(medians.shape)\n",
    "    pvals_upper = pvals_upper.reshape(medians.shape)\n",
    "                         \n",
    "    interpolated_p_values_asymptotics_median.append(pvals_median)\n",
    "    interpolated_p_values_asymptotics_lower_bound.append(pvals_lower)\n",
    "    interpolated_p_values_asymptotics_upper_bound.append(pvals_upper)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PbP vs parameterized vs aware plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8., calculate_height(2,8.)))\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "xmin, xmax = -3., 0.6\n",
    "skip = 100\n",
    "\n",
    "plt.plot([-100.,100.],[-100.,100.], ls='dashed', lw=1., c='0.5')\n",
    "\n",
    "for s in range(n_strategies):\n",
    "    if in_pbp_param_aware_plots[s]:\n",
    "        plt.scatter(np.log(r_benchmark[truth_index][::skip]),\n",
    "                    np.log(r_benchmark[s][::skip]),\n",
    "                    marker='o', alpha=1., s=10., c=colors[s], lw=0.,\n",
    "                    zorder=zorders[s],\n",
    "                    label=labels[s])\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(xmin,xmax)\n",
    "plt.xlabel(r\"True $\\log \\, r(x| \\theta_0,\\,\\theta_1)$\")\n",
    "plt.ylabel(r\"Learned $\\log \\, \\hat{r}(x| \\theta_0,\\,\\theta_1)$\")\n",
    "\n",
    "\n",
    "    \n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "xmin, xmax = -8., 30.\n",
    "skip = 2\n",
    "    \n",
    "plt.plot([-100.,100.],[-100.,100.], ls='dashed', lw=1., c='0.5')\n",
    "\n",
    "for s in range(n_strategies):\n",
    "    if in_pbp_param_aware_plots[s]:\n",
    "        plt.scatter(expected_llr[truth_index][::skip], expected_llr[s][::skip],\n",
    "                    marker='o', color=colors[s], alpha=scatter_alpha, \n",
    "                    s=8., lw=0.,\n",
    "                    zorder=zorders[s],\n",
    "                    label=labels[s])\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.xlim(xmin, xmax)\n",
    "plt.ylim(xmin, xmax)\n",
    "plt.xlabel(r\"True $E[\\log \\, r(x | \\theta,\\,\\theta_1)|\\theta_{SM}]$\")\n",
    "plt.ylabel(r\"Learned $E[\\log \\, \\hat{r}(x | \\theta,\\,\\theta_1)|\\theta_{SM}]$\")\n",
    "\n",
    "\n",
    "\n",
    "if False:\n",
    "    ax = plt.subplot(2, 2, 3)\n",
    "\n",
    "    event = 2\n",
    "    rmin, rmax = None, 1.5\n",
    "    r_lines = np.array([1.,4.,9.,16.])/8.\n",
    "\n",
    "    n_thetas_roam = 101\n",
    "    xi = np.linspace(-1.0, 1.0, n_thetas_roam)\n",
    "    yi = np.linspace(-1.0, 1.0, n_thetas_roam)\n",
    "    xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "    for s, (r, l) in enumerate(zip(r_roam, labels)):\n",
    "        if r is not None and (s == truth_index or in_pbp_param_aware_plots[s]):\n",
    "            yi = -2. * np.log(r[event].reshape((n_thetas_roam, n_thetas_roam))[:,50])\n",
    "            plt.plot(xi, yi,\n",
    "                     c=colors[s], ls=linestyles[s],\n",
    "                     label=l, \n",
    "                     zorder=zorders[s])\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.xlim(-1.0, 1.0)\n",
    "    plt.ylim(-0.8, 0.25)\n",
    "    plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "    plt.ylabel(r\"$-2\\, \\log \\, \\hat{r}(x_e \\, | \\, \\theta, \\theta_1)$\")\n",
    "\n",
    "\n",
    "\n",
    "    ax = plt.subplot(2, 2, 4)\n",
    "\n",
    "    thetas_filtered = thetas[:]\n",
    "    xi = np.linspace(-1.0, 1.0, 200)\n",
    "    yi = np.linspace(-1.0, 1.0, 200)\n",
    "    xx, yy = np.meshgrid(xi, yi)\n",
    "    llr_lines = [1.,4.]\n",
    "\n",
    "    for s in range(n_strategies):\n",
    "        if s == truth_index or in_pbp_param_aware_plots[s]:\n",
    "            cs = plt.contour(xi, yi, interpolated_expected_llr[s], llr_lines,\n",
    "                             linewidths=linewidths[s], colors=colors[s],\n",
    "                             linestyles=linestyles[s])\n",
    "            cs.collections[0].set_label(labels[s])\n",
    "\n",
    "    for s in range(n_strategies):\n",
    "        if s == truth_index or in_pbp_param_aware_plots[s]:\n",
    "            plt.scatter([xi[interpolated_expected_llr_mle[s][1]]],\n",
    "                        [yi[interpolated_expected_llr_mle[s][0]]],\n",
    "                        marker='o', c=colors[s], s=50, lw=0, zorder=10)\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    plt.xlim(-1., 0.65)\n",
    "    plt.ylim(-0.65, 1.)\n",
    "    plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "    plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "\n",
    "\n",
    "\n",
    "adjust_margins(2,8.)\n",
    "plt.savefig(\"../figures/paper/pbp_parameterized_aware.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -6, 1.\n",
    "skip = 100\n",
    "\n",
    "fig = plt.figure(figsize=(9., calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "\n",
    "    plt.plot([-100.,100.],[-100.,100.], ls='dashed', lw=1., c='0.5')\n",
    "    \n",
    "    for s in [truth_index]*(panel==0) + panel_indices[panel]:\n",
    "        if r_benchmark_uncalibrated[s] is None:\n",
    "            continue\n",
    "        \n",
    "        order = r_benchmark_uncalibrated[s].argsort()\n",
    "        \n",
    "        if s == 3:\n",
    "            plt.scatter(np.log(r_benchmark_uncalibrated[s])[::50],\n",
    "                        np.log(r_benchmark[s])[::50],\n",
    "                        s=8., alpha=scatter_alpha,\n",
    "                        c=colors[s], label=labels[s])\n",
    "        else:\n",
    "            plt.plot(np.log(r_benchmark_uncalibrated[s][order]),\n",
    "                     np.log(r_benchmark[s][order]),\n",
    "                     c=colors[s], lw=1.5, ls='-', label=labels[s])\n",
    "        \n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(xmin,xmax)\n",
    "    plt.xlabel(r\"Raw $\\log \\, \\hat{r}(x| \\theta_0,\\,\\theta_1)$\")\n",
    "    if panel == 0:\n",
    "        plt.ylabel(r\"Calibrated $\\log \\, \\hat{r}(x| \\theta_0,\\,\\theta_1)$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/calibration.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark theta: approximate vs exact r(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -3., 0.6\n",
    "skip = 100\n",
    "\n",
    "fig = plt.figure(figsize=(9., calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "\n",
    "    plt.plot([-100.,100.],[-100.,100.], ls='dashed', lw=1., c='0.5')\n",
    "    \n",
    "    for i, s in enumerate(panel_indices[panel]):\n",
    "        plt.scatter(np.log(r_benchmark[truth_index][::skip]),\n",
    "                    np.log(r_benchmark[s][::skip]),\n",
    "                    marker='o', alpha=1., s=10., c=colors[s], lw=0.,\n",
    "                    label=labels[s])\n",
    "        \n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(xmin,xmax)\n",
    "    plt.xlabel(r\"True $\\log \\, r(x| \\theta_0,\\,\\theta_1)$\")\n",
    "    if panel == 0:\n",
    "        plt.ylabel(r\"Learned $\\log \\, \\hat{r}(x| \\theta_0,\\,\\theta_1)$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/r_scatter.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact vs approximate expected log likelihood ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = -8., 32.\n",
    "skip = 2\n",
    "\n",
    "fig = plt.figure(figsize=(9.,calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "    \n",
    "    plt.plot([-100.,100.],[-100.,100.], ls='dashed', lw=1., c='0.5')\n",
    "    \n",
    "    for s in panel_indices[panel]:\n",
    "        plt.scatter(expected_llr[truth_index][::skip], expected_llr[s][::skip],\n",
    "                    marker='o', color=colors[s], alpha=scatter_alpha, \n",
    "                    s=8., lw=0.,\n",
    "                    label=labels[s])\n",
    "        \n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(xmin, xmax)\n",
    "    plt.xlabel(r\"True $E[\\log \\, r(x | \\theta,\\,\\theta_1)|\\theta_{SM}]$\")\n",
    "    if panel == 0:\n",
    "        plt.ylabel(r\"Learned $E[\\log \\, \\hat{r}(x | \\theta,\\,\\theta_1)|\\theta_{SM}]$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/expected_likelihood_scatter.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theta dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_event = 25\n",
    "events = list(range(start_event,start_event + 36))\n",
    "\n",
    "rmin, rmax = None, 1.5\n",
    "r_lines = np.array([1., 4., 9.])\n",
    "\n",
    "fig = plt.figure(figsize=(8., calculate_height(2,8.)))\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "n_thetas_roam = 101\n",
    "xi = np.linspace(-1.0, 1.0, n_thetas_roam)\n",
    "yi = np.linspace(-1.0, 1.0, n_thetas_roam)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "#zi_truth = -2. * np.log(r_roam[truth_index][event].reshape((n_thetas_roam, n_thetas_roam)))\n",
    "#cs = plt.contourf(xi, yi, zi_truth,\n",
    "#                  100, cmap=\"Greys\", alpha=1., vmin=rmin, vmax=rmax)\n",
    "#cbar = plt.colorbar()\n",
    "\n",
    "plt.plot([0.,0.],[-1.,1.],lw=2.,ls=':',c='0.5')\n",
    "\n",
    "for s, (r, l) in enumerate(zip(r_roam, labels)):\n",
    "    if r is not None and in_main_plots[s]:\n",
    "        q = -2. * np.sum(np.log(r[events]),axis=0)\n",
    "        zi = q.reshape((n_thetas_roam, n_thetas_roam))\n",
    "        if s == 0:\n",
    "            zi_truth = zi\n",
    "        plt.contour(xi, yi, zi,\n",
    "                    np.min(zi_truth) + r_lines,\n",
    "                    linewidths=linewidths[s], colors=colors[s],\n",
    "                    linestyles=linestyles[s])\n",
    "\n",
    "        mle = np.argmin(zi)\n",
    "        plt.scatter([xx.flatten()[mle]],\n",
    "                    [yy.flatten()[mle]],\n",
    "                    marker='o', c=colors[s], s=50, lw=0, zorder=10)\n",
    "\n",
    "plt.xlim(-1.0, 1.0)\n",
    "plt.ylim(-1.0, 1.0)\n",
    "plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "#cbar.set_label(r'$-2 \\, \\log \\, r(x_i | \\theta, \\theta_1)$ (' + l + ')')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "ax = plt.subplot(1, 2, 2)\n",
    "\n",
    "i = 0\n",
    "for s, (r, l) in enumerate(zip(r_roam, labels)):\n",
    "    if r is not None and in_main_plots[s]:\n",
    "        q = -2. * np.sum(np.log(r[events]), axis=0)\n",
    "        yi = q.reshape((n_thetas_roam, n_thetas_roam))[:,50]\n",
    "        plt.plot(xi, yi, c=colors[s], label=l, ls=linestyles[s])\n",
    "        i += 1\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(-1.0, 1.0)\n",
    "#plt.ylim(-1.0, 1.0)\n",
    "plt.xlabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "plt.ylabel(r\"$-2\\, \\sum_e \\, \\log \\; \\hat{r}(x_e \\, | \\, \\theta, \\theta_1)$\")\n",
    "    \n",
    "    \n",
    "adjust_margins(2,8.)\n",
    "plt.savefig(\"../figures/paper/theta_dependence.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL contours from asymptotics (ensemble errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grid\n",
    "thetas_filtered = thetas[:]\n",
    "xi = np.linspace(-1.0, 1.0, 200)\n",
    "yi = np.linspace(-1.0, 1.0, 200)\n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "# Error band function\n",
    "def plot_errorbands(xi, yi, zi_upper, zi_lower, color):\n",
    "    for threshold in np.sort(1. - settings.confidence_levels):\n",
    "        band = (zi_upper > threshold) * (zi_lower < threshold) + (zi_upper < threshold) * (zi_lower > threshold)\n",
    "        plt.contourf(xi, yi, band, [0.5,2.5],\n",
    "                     colors=color,\n",
    "                     alpha=0.2)\n",
    "\n",
    "fig = plt.figure(figsize=(9.,calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    # Axis (shared y axis)\n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "        \n",
    "    # Error bands (envelope)\n",
    "    for s in panel_indices[panel]:\n",
    "        #if s < 2:\n",
    "        #    continue\n",
    "        if s == 3:\n",
    "            continue\n",
    "        plot_errorbands(xi, yi,\n",
    "                        interpolated_p_values_asymptotics_upper_bound[s],\n",
    "                        interpolated_p_values_asymptotics_lower_bound[s], \n",
    "                        colors[s])\n",
    "        #cs = plt.contour(xi, yi, interpolated_p_values_asymptotics_upper_bound[s], \n",
    "        #                 np.sort(1. - settings.confidence_levels),\n",
    "        #                 linewidths=0.5, colors=colors[s], alpha=0.5,\n",
    "        #                 linestyles='-')\n",
    "        #cs = plt.contour(xi, yi, interpolated_p_values_asymptotics_lower_bound[s], \n",
    "        #                 np.sort(1. - settings.confidence_levels),\n",
    "        #                 linewidths=0.5, colors=colors[s], alpha=0.5,\n",
    "        #                 linestyles='-')\n",
    "        \n",
    "    # CL contours (median)\n",
    "    for s in [truth_index] + panel_indices[panel]:\n",
    "        if s == 3:\n",
    "            continue\n",
    "        cs = plt.contour(xi, yi, interpolated_p_values_asymptotics_median[s], \n",
    "                         np.sort(1. - settings.confidence_levels),\n",
    "                         linewidths=linewidths[s], colors=colors[s],\n",
    "                         linestyles=linestyles[s])\n",
    "        cs.collections[0].set_label(labels[s])\n",
    "\n",
    "    # MLE\n",
    "    plt.scatter([xi[interpolated_expected_llr_mle[truth_index][1]]],\n",
    "                [yi[interpolated_expected_llr_mle[truth_index][0]]],\n",
    "                marker='o', c=colors[truth_index], s=50, lw=0, zorder=10)\n",
    "    for s in panel_indices[panel]:\n",
    "        if s == 3:\n",
    "            continue\n",
    "        plt.scatter([xi[interpolated_expected_llr_mle[s][1]]],\n",
    "                    [yi[interpolated_expected_llr_mle[s][0]]],\n",
    "                    marker='o', c=colors[s], s=50, lw=0, zorder=10)\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "    # Axis details\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "    if panel==0:\n",
    "        plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/cl_contours_asymptotics.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid\n",
    "xi = np.linspace(-1.0, 1.0, 200)\n",
    "\n",
    "# Error band function\n",
    "def plot_errorbands(xi, yi_upper, yi_lower, color):\n",
    "    plt.fill_between(xi, yi_upper, yi_lower,\n",
    "                     color=color, alpha=0.2)\n",
    "\n",
    "fig = plt.figure(figsize=(9.,calculate_height(3,9.)))\n",
    "\n",
    "for panel in range(3):\n",
    "    \n",
    "    # Axis (shared y axis)\n",
    "    if panel == 0:\n",
    "        ax0 = plt.subplot(1, 3, panel+1)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "    \n",
    "    # Error bands (envelope)\n",
    "    for s in panel_indices[panel]:\n",
    "        if s < 2:\n",
    "            continue\n",
    "            \n",
    "        yi_min = np.diag(interpolated_expected_llr_min[s])\n",
    "        yi_max = np.diag(interpolated_expected_llr_max[s])\n",
    "    \n",
    "        plot_errorbands(xi, yi_min, yi_max,\n",
    "                        colors[s])\n",
    "        #plt.plot(xi, yi_min,\n",
    "        #         lw=0.5, color=colors[s], alpha=0.5,\n",
    "        #         ls='-')\n",
    "        #plt.plot(xi, yi_max,\n",
    "        #         lw=0.5, color=colors[s], alpha=0.5,\n",
    "        #         ls='-')\n",
    "        \n",
    "    # CL contours (median)\n",
    "    for s in [truth_index] + panel_indices[panel]:\n",
    "        yi_median = np.diag(interpolated_expected_llr_median[s])\n",
    "        plt.plot(xi, yi_median,\n",
    "                 lw=linewidths[s], color=colors[s],\n",
    "                 ls=linestyles[s], label=labels[s])\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Axis details\n",
    "    plt.xlim(-1., 1.)\n",
    "    plt.ylim(0., 28.)\n",
    "    plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2 \\, = \\, f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "    if panel==0:\n",
    "        plt.ylabel(r\"$q'(\\theta)$\")\n",
    "    else:\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "adjust_margins(3,9.)\n",
    "plt.savefig(\"../figures/paper/expected_llr_diagonal.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymptotic CL contours (E[r] errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Grid\n",
    "    thetas_filtered = thetas[:]\n",
    "    xi = np.linspace(-1.0, 1.0, 200)\n",
    "    yi = np.linspace(-1.0, 1.0, 200)\n",
    "    xx, yy = np.meshgrid(xi, yi)\n",
    "\n",
    "    # Error band function\n",
    "    def plot_errorbands(xi, yi, zi_upper, zi_lower, color, alpha):\n",
    "        for threshold in np.sort(1. - settings.confidence_levels):\n",
    "            band = (zi_upper > threshold) * (zi_lower < threshold) + (zi_upper < threshold) * (zi_lower > threshold)\n",
    "            plt.contourf(xi, yi, band, [0.5,2.5],\n",
    "                         colors=color,\n",
    "                         alpha=alpha)\n",
    "\n",
    "    fig = plt.figure(figsize=(9.,calculate_height(3,9.)))\n",
    "\n",
    "    for panel in range(3):\n",
    "\n",
    "        # Axis (shared y axis)\n",
    "        if panel == 0:\n",
    "            ax0 = plt.subplot(1, 3, panel+1)\n",
    "        else:\n",
    "            ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "\n",
    "        # Error bands (envelope)\n",
    "        for s in [truth_index] + panel_indices[panel]:\n",
    "            plot_errorbands(xi, yi,\n",
    "                            interpolated_p_values_asymptotics_plus_rc_error[s],\n",
    "                            interpolated_p_values_asymptotics_minus_rc_error[s], \n",
    "                            colors[s], band_alpha[s])\n",
    "\n",
    "        # CL contours (median)\n",
    "        for s in [truth_index] + panel_indices[panel]:\n",
    "            cs = plt.contour(xi, yi, interpolated_p_values_asymptotics[s], \n",
    "                             np.sort(1. - settings.confidence_levels),\n",
    "                             linewidths=linewidths[s], colors=colors[s],\n",
    "                             linestyles=linestyles[s])\n",
    "            cs.collections[0].set_label(labels[s])\n",
    "\n",
    "        # MLE\n",
    "        plt.scatter([xi[interpolated_expected_llr_mle[truth_index][1]]],\n",
    "                    [yi[interpolated_expected_llr_mle[truth_index][0]]],\n",
    "                    marker='o', c=colors[truth_index], s=50, lw=0, zorder=10)\n",
    "        for s in panel_indices[panel]:\n",
    "            plt.scatter([xi[interpolated_expected_llr_mle[s][1]]],\n",
    "                        [yi[interpolated_expected_llr_mle[s][0]]],\n",
    "                        marker='o', c=colors[s], s=50, lw=0, zorder=10)\n",
    "\n",
    "        # Legend\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Axis details\n",
    "        plt.xlim(-1, 1)\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "        if panel==0:\n",
    "            plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "        else:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "    adjust_margins(3,9.)\n",
    "    plt.savefig(\"../figures/paper/cl_contours_asymptotics_expected_r_errors.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CL contours from Neyman construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if neyman_plots:\n",
    "    fig = plt.figure(figsize=(9.,calculate_height(3,9.)))\n",
    "\n",
    "    for panel in range(3):\n",
    "\n",
    "        if panel == 0:\n",
    "            ax0 = plt.subplot(1, 3, panel+1)\n",
    "        else:\n",
    "            ax = plt.subplot(1, 3, panel+1, sharey=ax0)\n",
    "\n",
    "        for cl in range(len(interpolated_cl_excluded[truth_index])):\n",
    "            cs = plt.contour(xi, yi, interpolated_cl_excluded[truth_index][cl], [0.],\n",
    "                             linewidths=1.5, colors=colors[truth_index],\n",
    "                             linestyles=linestyles[truth_index])\n",
    "            if cl==0:\n",
    "                cs.collections[0].set_label(labels[truth_index])\n",
    "\n",
    "        for s in panel_indices[panel]:\n",
    "            if interpolated_cl_excluded[s] is None:\n",
    "                continue\n",
    "\n",
    "            for cl in range(len(interpolated_cl_excluded[truth_index])):\n",
    "                cs = plt.contour(xi, yi, interpolated_cl_excluded[s][cl], [0.],\n",
    "                                 linewidths=linewidths[s], colors=colors[s],\n",
    "                                 linestyles=linestyles[s])\n",
    "                if cl==0:\n",
    "                    cs.collections[0].set_label(labels[s])\n",
    "\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        plt.xlim(-1.0, 1.0)\n",
    "        plt.ylim(-1.0, 1.0)\n",
    "        plt.xlabel(r\"$f_{W} \\, v^2 / \\Lambda^2$\")\n",
    "        if panel==0:\n",
    "            plt.ylabel(r\"$f_{WW} \\, v^2 / \\Lambda^2$\")\n",
    "        else:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "    adjust_margins(3,9.)\n",
    "    plt.savefig(\"../figures/paper/cl_contours_nc.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best fit thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0 # Fixed strategy for now\n",
    "mle = thetas[mle_thetas[s]]\n",
    "\n",
    "nullfmt = NullFormatter()         # no labels\n",
    "\n",
    "# definitions for the axes\n",
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "bottom_h = left_h = left + width + 0.02\n",
    "\n",
    "rect_scatter = [left, bottom, width, height]\n",
    "rect_histx = [left, bottom_h, width, 0.2]\n",
    "rect_histy = [left_h, bottom, 0.2, height]\n",
    "\n",
    "# start with a rectangular Figure\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "\n",
    "axScatter = plt.axes(rect_scatter)\n",
    "axHistx = plt.axes(rect_histx)\n",
    "axHisty = plt.axes(rect_histy)\n",
    "\n",
    "# no labels\n",
    "axHistx.xaxis.set_major_formatter(nullfmt)\n",
    "axHisty.yaxis.set_major_formatter(nullfmt)\n",
    "\n",
    "# the scatter plot:\n",
    "axScatter.hist2d(mle[:,0], mle[:,1], range=[[-1.,1.],[-1.,1.]], bins=(21,21), normed=True, cmap='viridis')\n",
    "\n",
    "# now determine nice limits by hand:\n",
    "binwidth = 0.05\n",
    "xymax = np.max([np.max(np.fabs(mle[:,0])), np.max(np.fabs(mle[:,1]))])\n",
    "lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "axScatter.set_xlim((-lim, lim))\n",
    "axScatter.set_ylim((-lim, lim))\n",
    "\n",
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "axHistx.hist(mle[:,0], bins=bins)\n",
    "axHisty.hist(mle[:,1], bins=bins, orientation='horizontal')\n",
    "\n",
    "axHistx.set_xlim(axScatter.get_xlim())\n",
    "axHisty.set_ylim(axScatter.get_ylim())\n",
    "\n",
    "plt.savefig(\"../figures/results/mle_scatter_truth.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
