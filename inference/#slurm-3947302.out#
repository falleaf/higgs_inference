Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   1

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-12 19:35:44.031209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 19:35:44.039560: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 19:35:44.039576: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 19:35:44.039582: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 19:35:44.039586: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 19:35:44.349380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-12 19:35:44.349417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-12 19:35:44.349423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-12 19:35:44.349433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
15s - loss: 0.6681 - val_loss: 0.8388
Epoch 2/20
10s - loss: 0.6639 - val_loss: 0.8625
Epoch 3/20
10s - loss: 0.6625 - val_loss: 0.8529
Epoch 4/20
10s - loss: 0.6618 - val_loss: 0.8342
Epoch 5/20
10s - loss: 0.6615 - val_loss: 0.8455
Epoch 6/20
10s - loss: 0.6609 - val_loss: 0.8728
Epoch 7/20
10s - loss: 0.6601 - val_loss: 0.8514
Epoch 8/20
10s - loss: 0.6594 - val_loss: 0.8729
Epoch 00007: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6433 - val_loss: 0.8193
Epoch 2/20
10s - loss: 0.6256 - val_loss: 0.7838
Epoch 3/20
10s - loss: 0.6226 - val_loss: 0.7864
Epoch 4/20
10s - loss: 0.6202 - val_loss: 0.7978
Epoch 5/20
10s - loss: 0.6185 - val_loss: 0.7869
Epoch 6/20
10s - loss: 0.6169 - val_loss: 0.8054
Epoch 00005: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6361 - val_loss: 0.7998
Epoch 2/20
10s - loss: 0.6184 - val_loss: 0.7672
Epoch 3/20
10s - loss: 0.6119 - val_loss: 0.7828
Epoch 4/20
10s - loss: 0.6088 - val_loss: 0.7654
Epoch 5/20
10s - loss: 0.6071 - val_loss: 0.7704
Epoch 6/20
10s - loss: 0.6057 - val_loss: 0.7731
Epoch 7/20
10s - loss: 0.6040 - val_loss: 0.7866
Epoch 8/20
10s - loss: 0.6027 - val_loss: 0.7583
Epoch 9/20
10s - loss: 0.6014 - val_loss: 0.7181
Epoch 10/20
10s - loss: 0.6002 - val_loss: 0.7377
Epoch 11/20
10s - loss: 0.5993 - val_loss: 0.8658
Epoch 12/20
10s - loss: 0.5984 - val_loss: 0.7696
Epoch 13/20
10s - loss: 0.5976 - val_loss: 0.8108
Epoch 00012: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6107 - val_loss: 0.7501
Epoch 2/20
10s - loss: 0.6024 - val_loss: 0.7271
Epoch 3/20
10s - loss: 0.5981 - val_loss: 0.7231
Epoch 4/20
10s - loss: 0.5960 - val_loss: 0.7693
Epoch 5/20
10s - loss: 0.5938 - val_loss: 0.7129
Epoch 6/20
10s - loss: 0.5926 - val_loss: 0.7761
Epoch 7/20
10s - loss: 0.5914 - val_loss: 0.7313
Epoch 8/20
10s - loss: 0.5902 - val_loss: 0.7431
Epoch 9/20
10s - loss: 0.5895 - val_loss: 0.7512
Epoch 00008: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6668 - val_loss: 0.8598
Epoch 2/20
10s - loss: 0.6619 - val_loss: 0.8486
Epoch 3/20
10s - loss: 0.6608 - val_loss: 0.8579
Epoch 4/20
10s - loss: 0.6599 - val_loss: 0.8929
Epoch 5/20
10s - loss: 0.6597 - val_loss: 0.8902
Epoch 6/20
10s - loss: 0.6593 - val_loss: 0.8595
Epoch 00005: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6571 - val_loss: 0.8235
Epoch 2/20
10s - loss: 0.6506 - val_loss: 0.8274
Epoch 3/20
10s - loss: 0.6475 - val_loss: 0.8540
Epoch 4/20
10s - loss: 0.6461 - val_loss: 0.8177
Epoch 5/20
10s - loss: 0.6447 - val_loss: 0.8263
Epoch 6/20
10s - loss: 0.6440 - val_loss: 0.8250
Epoch 7/20
10s - loss: 0.6431 - val_loss: 0.7999
Epoch 8/20
10s - loss: 0.6421 - val_loss: 0.8586
Epoch 9/20
10s - loss: 0.6416 - val_loss: 0.8731
Epoch 10/20
10s - loss: 0.6410 - val_loss: 0.8424
Epoch 11/20
10s - loss: 0.6398 - val_loss: 0.8321
Epoch 00010: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6623 - val_loss: 0.9157
Epoch 2/20
10s - loss: 0.6552 - val_loss: 0.8821
Epoch 3/20
10s - loss: 0.6526 - val_loss: 0.8735
Epoch 4/20
10s - loss: 0.6515 - val_loss: 0.8378
Epoch 5/20
10s - loss: 0.6504 - val_loss: 0.8709
Epoch 6/20
10s - loss: 0.6490 - val_loss: 0.8921
Epoch 7/20
10s - loss: 0.6480 - val_loss: 0.8533
Epoch 8/20
10s - loss: 0.6471 - val_loss: 0.8455
Epoch 00007: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6413 - val_loss: 0.7866
Epoch 2/20
10s - loss: 0.6350 - val_loss: 0.7947
Epoch 3/20
10s - loss: 0.6328 - val_loss: 0.8413
Epoch 4/20
10s - loss: 0.6312 - val_loss: 0.8183
Epoch 5/20
10s - loss: 0.6298 - val_loss: 0.7951
Epoch 00004: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6853 - val_loss: 0.8896
Epoch 2/20
10s - loss: 0.6810 - val_loss: 0.8759
Epoch 3/20
10s - loss: 0.6794 - val_loss: 0.8837
Epoch 4/20
10s - loss: 0.6789 - val_loss: 0.8629
Epoch 5/20
10s - loss: 0.6787 - val_loss: 0.8667
Epoch 6/20
10s - loss: 0.6786 - val_loss: 0.8730
Epoch 7/20
10s - loss: 0.6783 - val_loss: 0.8534
Epoch 8/20
10s - loss: 0.6780 - val_loss: 0.8785
Epoch 9/20
10s - loss: 0.6775 - val_loss: 0.8733
Epoch 10/20
10s - loss: 0.6772 - val_loss: 0.8912
Epoch 11/20
10s - loss: 0.6767 - val_loss: 0.8640
Epoch 00010: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6553 - val_loss: 0.8232
Epoch 2/20
10s - loss: 0.6480 - val_loss: 0.8128
Epoch 3/20
10s - loss: 0.6457 - val_loss: 0.8192
Epoch 4/20
10s - loss: 0.6441 - val_loss: 0.8272
Epoch 5/20
10s - loss: 0.6424 - val_loss: 0.8271
Epoch 6/20
10s - loss: 0.6412 - val_loss: 0.8319
Epoch 00005: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6685 - val_loss: 0.8558
Epoch 2/20
10s - loss: 0.6631 - val_loss: 0.8506
Epoch 3/20
10s - loss: 0.6611 - val_loss: 0.8477
Epoch 4/20
10s - loss: 0.6595 - val_loss: 0.8687
Epoch 5/20
10s - loss: 0.6583 - val_loss: 0.8594
Epoch 6/20
10s - loss: 0.6577 - val_loss: 0.8557
Epoch 7/20
10s - loss: 0.6566 - val_loss: 0.8205
Epoch 8/20
10s - loss: 0.6563 - val_loss: 0.8297
Epoch 9/20
10s - loss: 0.6555 - val_loss: 0.8495
Epoch 10/20
10s - loss: 0.6549 - val_loss: 0.8390
Epoch 11/20
10s - loss: 0.6543 - val_loss: 0.8444
Epoch 00010: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6842 - val_loss: 0.8781
Epoch 2/20
10s - loss: 0.6785 - val_loss: 0.8775
Epoch 3/20
10s - loss: 0.6775 - val_loss: 0.8678
Epoch 4/20
10s - loss: 0.6769 - val_loss: 0.8711
Epoch 5/20
10s - loss: 0.6767 - val_loss: 0.8671
Epoch 6/20
10s - loss: 0.6763 - val_loss: 0.8921
Epoch 7/20
10s - loss: 0.6761 - val_loss: 0.8842
Epoch 8/20
10s - loss: 0.6759 - val_loss: 0.8762
Epoch 9/20
10s - loss: 0.6755 - val_loss: 0.8768
Epoch 00008: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6857 - val_loss: 0.9056
Epoch 2/20
10s - loss: 0.6810 - val_loss: 0.8672
Epoch 3/20
10s - loss: 0.6799 - val_loss: 0.8545
Epoch 4/20
10s - loss: 0.6793 - val_loss: 0.8593
Epoch 5/20
10s - loss: 0.6789 - val_loss: 0.8592
Epoch 6/20
10s - loss: 0.6787 - val_loss: 0.8643
Epoch 7/20
10s - loss: 0.6782 - val_loss: 0.8752
Epoch 00006: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6631 - val_loss: 0.8573
Epoch 2/20
10s - loss: 0.6573 - val_loss: 0.8760
Epoch 3/20
10s - loss: 0.6557 - val_loss: 0.8665
Epoch 4/20
10s - loss: 0.6542 - val_loss: 0.8169
Epoch 5/20
10s - loss: 0.6529 - val_loss: 0.8450
Epoch 6/20
10s - loss: 0.6521 - val_loss: 0.8426
Epoch 7/20
10s - loss: 0.6514 - val_loss: 0.8552
Epoch 8/20
10s - loss: 0.6504 - val_loss: 0.8802
Epoch 00007: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6560 - val_loss: 0.8459
Epoch 2/20
10s - loss: 0.6497 - val_loss: 0.8094
Epoch 3/20
10s - loss: 0.6477 - val_loss: 0.8574
Epoch 4/20
10s - loss: 0.6463 - val_loss: 0.8037
Epoch 5/20
10s - loss: 0.6451 - val_loss: 0.8262
Epoch 6/20
10s - loss: 0.6437 - val_loss: 0.8687
Epoch 7/20
10s - loss: 0.6428 - val_loss: 0.8497
Epoch 8/20
10s - loss: 0.6421 - val_loss: 0.8310
Epoch 00007: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6571 - val_loss: 0.8614
Epoch 2/20
10s - loss: 0.6514 - val_loss: 0.8434
Epoch 3/20
10s - loss: 0.6499 - val_loss: 0.8610
Epoch 4/20
10s - loss: 0.6487 - val_loss: 0.8675
Epoch 5/20
10s - loss: 0.6476 - val_loss: 0.8754
Epoch 6/20
10s - loss: 0.6467 - val_loss: 0.8610
Epoch 00005: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6577 - val_loss: 0.8244
Epoch 2/20
10s - loss: 0.6495 - val_loss: 0.8232
Epoch 3/20
10s - loss: 0.6460 - val_loss: 0.8535
Epoch 4/20
10s - loss: 0.6436 - val_loss: 0.8101
Epoch 5/20
10s - loss: 0.6419 - val_loss: 0.8341
Epoch 6/20
10s - loss: 0.6407 - val_loss: 0.8268
Epoch 7/20
10s - loss: 0.6395 - val_loss: 0.8431
Epoch 8/20
10s - loss: 0.6383 - val_loss: 0.8356
Epoch 00007: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6702 - val_loss: 0.8449
Epoch 2/20
10s - loss: 0.6646 - val_loss: 0.8757
Epoch 3/20
10s - loss: 0.6630 - val_loss: 0.8692
Epoch 4/20
10s - loss: 0.6615 - val_loss: 0.8924
Epoch 5/20
10s - loss: 0.6602 - val_loss: 0.8633
Epoch 00004: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6269 - val_loss: 0.7963
Epoch 2/20
10s - loss: 0.6199 - val_loss: 0.7771
Epoch 3/20
10s - loss: 0.6165 - val_loss: 0.8289
Epoch 4/20
10s - loss: 0.6148 - val_loss: 0.7745
Epoch 5/20
10s - loss: 0.6130 - val_loss: 0.7593
Epoch 6/20
10s - loss: 0.6116 - val_loss: 0.7795
Epoch 7/20
10s - loss: 0.6102 - val_loss: 0.8038
Epoch 8/20
10s - loss: 0.6092 - val_loss: 0.7942
Epoch 9/20
10s - loss: 0.6079 - val_loss: 0.7429
Epoch 10/20
10s - loss: 0.6075 - val_loss: 0.7666
Epoch 11/20
10s - loss: 0.6068 - val_loss: 0.7928
Epoch 12/20
10s - loss: 0.6060 - val_loss: 0.7662
Epoch 13/20
10s - loss: 0.6055 - val_loss: 0.7632
Epoch 00012: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6504 - val_loss: 0.7970
Epoch 2/20
10s - loss: 0.6435 - val_loss: 0.8365
Epoch 3/20
10s - loss: 0.6404 - val_loss: 0.8338
Epoch 4/20
10s - loss: 0.6388 - val_loss: 0.7809
Epoch 5/20
10s - loss: 0.6364 - val_loss: 0.8121
Epoch 6/20
10s - loss: 0.6354 - val_loss: 0.8204
Epoch 7/20
10s - loss: 0.6341 - val_loss: 0.8406
Epoch 8/20
10s - loss: 0.6334 - val_loss: 0.8186
Epoch 00007: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6733 - val_loss: 0.8610
Epoch 2/20
10s - loss: 0.6686 - val_loss: 0.8738
Epoch 3/20
10s - loss: 0.6677 - val_loss: 0.8646
Epoch 4/20
10s - loss: 0.6668 - val_loss: 0.8476
Epoch 5/20
10s - loss: 0.6664 - val_loss: 0.8356
Epoch 6/20
10s - loss: 0.6657 - val_loss: 0.8954
Epoch 7/20
10s - loss: 0.6652 - val_loss: 0.8749
Epoch 8/20
10s - loss: 0.6646 - val_loss: 0.8775
Epoch 9/20
10s - loss: 0.6643 - val_loss: 0.8497
Epoch 00008: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6532 - val_loss: 0.8347
Epoch 2/20
10s - loss: 0.6409 - val_loss: 0.7992
Epoch 3/20
10s - loss: 0.6349 - val_loss: 0.7933
Epoch 4/20
10s - loss: 0.6318 - val_loss: 0.8103
Epoch 5/20
10s - loss: 0.6299 - val_loss: 0.7968
Epoch 6/20
10s - loss: 0.6287 - val_loss: 0.8442
Epoch 7/20
10s - loss: 0.6274 - val_loss: 0.8208
Epoch 00006: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6554 - val_loss: 0.7994
Epoch 2/20
10s - loss: 0.6457 - val_loss: 0.8735
Epoch 3/20
10s - loss: 0.6435 - val_loss: 0.8235
Epoch 4/20
10s - loss: 0.6420 - val_loss: 0.8271
Epoch 5/20
10s - loss: 0.6403 - val_loss: 0.8027
Epoch 00004: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6661 - val_loss: 0.8550
Epoch 2/20
10s - loss: 0.6611 - val_loss: 0.8528
Epoch 3/20
10s - loss: 0.6596 - val_loss: 0.8266
Epoch 4/20
10s - loss: 0.6587 - val_loss: 0.8559
Epoch 5/20
10s - loss: 0.6579 - val_loss: 0.8385
Epoch 6/20
10s - loss: 0.6571 - val_loss: 0.8385
Epoch 7/20
10s - loss: 0.6567 - val_loss: 0.8364
Epoch 00006: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6659 - val_loss: 0.8683
Epoch 2/20
10s - loss: 0.6608 - val_loss: 0.8491
Epoch 3/20
10s - loss: 0.6591 - val_loss: 0.8646
Epoch 4/20
10s - loss: 0.6578 - val_loss: 0.8593
Epoch 5/20
10s - loss: 0.6572 - val_loss: 0.8445
Epoch 6/20
10s - loss: 0.6563 - val_loss: 0.8628
Epoch 7/20
10s - loss: 0.6555 - val_loss: 0.8915
Epoch 8/20
10s - loss: 0.6550 - val_loss: 0.8300
Epoch 9/20
10s - loss: 0.6544 - val_loss: 0.8436
Epoch 10/20
10s - loss: 0.6539 - val_loss: 0.8623
Epoch 11/20
10s - loss: 0.6531 - val_loss: 0.8874
Epoch 12/20
10s - loss: 0.6525 - val_loss: 0.8210
Epoch 13/20
10s - loss: 0.6520 - val_loss: 0.8624
Epoch 14/20
10s - loss: 0.6516 - val_loss: 0.8722
Epoch 15/20
10s - loss: 0.6510 - val_loss: 0.8882
Epoch 16/20
10s - loss: 0.6505 - val_loss: 0.8722
Epoch 00015: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6511 - val_loss: 0.8292
Epoch 2/20
10s - loss: 0.6432 - val_loss: 0.8284
Epoch 3/20
10s - loss: 0.6410 - val_loss: 0.8189
Epoch 4/20
10s - loss: 0.6392 - val_loss: 0.7875
Epoch 5/20
10s - loss: 0.6384 - val_loss: 0.8087
Epoch 6/20
10s - loss: 0.6372 - val_loss: 0.8145
Epoch 7/20
10s - loss: 0.6363 - val_loss: 0.8274
Epoch 8/20
10s - loss: 0.6356 - val_loss: 0.8003
Epoch 00007: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6838 - val_loss: 0.8866
Epoch 2/20
10s - loss: 0.6793 - val_loss: 0.8378
Epoch 3/20
10s - loss: 0.6783 - val_loss: 0.8849
Epoch 4/20
10s - loss: 0.6779 - val_loss: 0.8824
Epoch 5/20
10s - loss: 0.6775 - val_loss: 0.8872
Epoch 6/20
10s - loss: 0.6771 - val_loss: 0.8647
Epoch 00005: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6516 - val_loss: 0.8311
Epoch 2/20
10s - loss: 0.6417 - val_loss: 0.8197
Epoch 3/20
10s - loss: 0.6371 - val_loss: 0.8242
Epoch 4/20
10s - loss: 0.6343 - val_loss: 0.7561
Epoch 5/20
10s - loss: 0.6328 - val_loss: 0.7827
Epoch 6/20
10s - loss: 0.6315 - val_loss: 0.8462
Epoch 7/20
10s - loss: 0.6306 - val_loss: 0.8061
Epoch 8/20
10s - loss: 0.6295 - val_loss: 0.8126
Epoch 00007: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6775 - val_loss: 0.8359
Epoch 2/20
10s - loss: 0.6724 - val_loss: 0.8444
Epoch 3/20
10s - loss: 0.6712 - val_loss: 0.8614
Epoch 4/20
10s - loss: 0.6702 - val_loss: 0.8521
Epoch 5/20
10s - loss: 0.6698 - val_loss: 0.8583
Epoch 00004: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6330 - val_loss: 0.7969
Epoch 2/20
10s - loss: 0.6258 - val_loss: 0.7733
Epoch 3/20
10s - loss: 0.6233 - val_loss: 0.8272
Epoch 4/20
10s - loss: 0.6216 - val_loss: 0.8040
Epoch 5/20
10s - loss: 0.6202 - val_loss: 0.8120
Epoch 6/20
10s - loss: 0.6188 - val_loss: 0.7870
Epoch 00005: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6673 - val_loss: 0.8407
Epoch 2/20
10s - loss: 0.6610 - val_loss: 0.7955
Epoch 3/20
10s - loss: 0.6580 - val_loss: 0.8584
Epoch 4/20
10s - loss: 0.6560 - val_loss: 0.8707
Epoch 5/20
10s - loss: 0.6546 - val_loss: 0.8553
Epoch 6/20
10s - loss: 0.6531 - val_loss: 0.8642
Epoch 00005: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6505 - val_loss: 0.8186
Epoch 2/20
10s - loss: 0.6395 - val_loss: 0.7987
Epoch 3/20
10s - loss: 0.6379 - val_loss: 0.7913
Epoch 4/20
10s - loss: 0.6359 - val_loss: 0.8755
Epoch 5/20
10s - loss: 0.6339 - val_loss: 0.8071
Epoch 6/20
10s - loss: 0.6327 - val_loss: 0.8219
Epoch 7/20
10s - loss: 0.6314 - val_loss: 0.8401
Epoch 00006: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6706 - val_loss: 0.8499
Epoch 2/20
10s - loss: 0.6658 - val_loss: 0.8376
Epoch 3/20
10s - loss: 0.6646 - val_loss: 0.8526
Epoch 4/20
10s - loss: 0.6638 - val_loss: 0.8784
Epoch 5/20
10s - loss: 0.6630 - val_loss: 0.8552
Epoch 6/20
10s - loss: 0.6620 - val_loss: 0.8739
Epoch 00005: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6593 - val_loss: 0.8484
Epoch 2/20
10s - loss: 0.6526 - val_loss: 0.8500
Epoch 3/20
10s - loss: 0.6509 - val_loss: 0.8277
Epoch 4/20
10s - loss: 0.6499 - val_loss: 0.8134
Epoch 5/20
10s - loss: 0.6488 - val_loss: 0.8491
Epoch 6/20
10s - loss: 0.6479 - val_loss: 0.8222
Epoch 7/20
10s - loss: 0.6474 - val_loss: 0.8701
Epoch 8/20
10s - loss: 0.6467 - val_loss: 0.8407
Epoch 00007: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6372 - val_loss: 0.7983
Epoch 2/20
10s - loss: 0.6286 - val_loss: 0.7536
Epoch 3/20
10s - loss: 0.6254 - val_loss: 0.7928
Epoch 4/20
10s - loss: 0.6231 - val_loss: 0.7770
Epoch 5/20
10s - loss: 0.6215 - val_loss: 0.7484
Epoch 6/20
10s - loss: 0.6199 - val_loss: 0.7616
Epoch 7/20
10s - loss: 0.6188 - val_loss: 0.8156
Epoch 8/20
10s - loss: 0.6179 - val_loss: 0.8202
Epoch 9/20
10s - loss: 0.6170 - val_loss: 0.8094
Epoch 00008: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6590 - val_loss: 0.8437
Epoch 2/20
10s - loss: 0.6514 - val_loss: 0.8212
Epoch 3/20
10s - loss: 0.6491 - val_loss: 0.8598
Epoch 4/20
10s - loss: 0.6479 - val_loss: 0.8357
Epoch 5/20
10s - loss: 0.6466 - val_loss: 0.8314
Epoch 6/20
11s - loss: 0.6451 - val_loss: 0.8544
Epoch 00005: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6534 - val_loss: 0.8313
Epoch 2/20
10s - loss: 0.6462 - val_loss: 0.8200
Epoch 3/20
10s - loss: 0.6433 - val_loss: 0.8073
Epoch 4/20
10s - loss: 0.6422 - val_loss: 0.8403
Epoch 5/20
10s - loss: 0.6402 - val_loss: 0.8078
Epoch 6/20
10s - loss: 0.6392 - val_loss: 0.8418
Epoch 7/20
10s - loss: 0.6380 - val_loss: 0.8350
Epoch 00006: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6616 - val_loss: 0.8379
Epoch 2/20
10s - loss: 0.6549 - val_loss: 0.8079
Epoch 3/20
11s - loss: 0.6526 - val_loss: 0.8336
Epoch 4/20
10s - loss: 0.6508 - val_loss: 0.8350
Epoch 5/20
10s - loss: 0.6494 - val_loss: 0.8087
Epoch 6/20
11s - loss: 0.6483 - val_loss: 0.8422
Epoch 00005: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6518 - val_loss: 0.8441
Epoch 2/20
10s - loss: 0.6428 - val_loss: 0.8173
Epoch 3/20
10s - loss: 0.6389 - val_loss: 0.8095
Epoch 4/20
10s - loss: 0.6370 - val_loss: 0.8186
Epoch 5/20
10s - loss: 0.6348 - val_loss: 0.8288
Epoch 6/20
10s - loss: 0.6337 - val_loss: 0.8324
Epoch 7/20
10s - loss: 0.6325 - val_loss: 0.8300
Epoch 00006: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6856 - val_loss: 0.8777
Epoch 2/20
10s - loss: 0.6805 - val_loss: 0.8547
Epoch 3/20
11s - loss: 0.6791 - val_loss: 0.8691
Epoch 4/20
10s - loss: 0.6786 - val_loss: 0.8587
Epoch 5/20
10s - loss: 0.6783 - val_loss: 0.9000
Epoch 6/20
11s - loss: 0.6782 - val_loss: 0.8573
Epoch 00005: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6470 - val_loss: 0.8342
Epoch 2/20
11s - loss: 0.6386 - val_loss: 0.8235
Epoch 3/20
11s - loss: 0.6368 - val_loss: 0.8457
Epoch 4/20
10s - loss: 0.6350 - val_loss: 0.8533
Epoch 5/20
11s - loss: 0.6338 - val_loss: 0.8102
Epoch 6/20
10s - loss: 0.6327 - val_loss: 0.8030
Epoch 7/20
10s - loss: 0.6315 - val_loss: 0.8219
Epoch 8/20
11s - loss: 0.6308 - val_loss: 0.8384
Epoch 9/20
11s - loss: 0.6299 - val_loss: 0.7989
Epoch 10/20
11s - loss: 0.6290 - val_loss: 0.8282
Epoch 11/20
11s - loss: 0.6280 - val_loss: 0.8189
Epoch 12/20
11s - loss: 0.6275 - val_loss: 0.8489
Epoch 13/20
10s - loss: 0.6269 - val_loss: 0.8277
Epoch 00012: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6680 - val_loss: 0.8789
Epoch 2/20
11s - loss: 0.6619 - val_loss: 0.8710
Epoch 3/20
10s - loss: 0.6601 - val_loss: 0.8275
Epoch 4/20
11s - loss: 0.6588 - val_loss: 0.8729
Epoch 5/20
10s - loss: 0.6575 - val_loss: 0.8606
Epoch 6/20
11s - loss: 0.6567 - val_loss: 0.8535
Epoch 7/20
10s - loss: 0.6555 - val_loss: 0.8340
Epoch 00006: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6618 - val_loss: 0.8351
Epoch 2/20
11s - loss: 0.6545 - val_loss: 0.8563
Epoch 3/20
11s - loss: 0.6517 - val_loss: 0.8415
Epoch 4/20
11s - loss: 0.6497 - val_loss: 0.8526
Epoch 5/20
10s - loss: 0.6485 - val_loss: 0.8480
Epoch 00004: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6575 - val_loss: 0.8243
Epoch 2/20
11s - loss: 0.6518 - val_loss: 0.8096
Epoch 3/20
11s - loss: 0.6501 - val_loss: 0.8345
Epoch 4/20
11s - loss: 0.6492 - val_loss: 0.8543
Epoch 5/20
11s - loss: 0.6480 - val_loss: 0.8207
Epoch 6/20
11s - loss: 0.6473 - val_loss: 0.8328
Epoch 00005: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6589 - val_loss: 0.8213
Epoch 2/20
11s - loss: 0.6492 - val_loss: 0.8499
Epoch 3/20
11s - loss: 0.6456 - val_loss: 0.8331
Epoch 4/20
11s - loss: 0.6432 - val_loss: 0.8202
Epoch 5/20
11s - loss: 0.6410 - val_loss: 0.8298
Epoch 6/20
11s - loss: 0.6397 - val_loss: 0.8431
Epoch 7/20
11s - loss: 0.6385 - val_loss: 0.8436
Epoch 8/20
11s - loss: 0.6372 - val_loss: 0.8355
Epoch 00007: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6488 - val_loss: 0.7795
Epoch 2/20
11s - loss: 0.6396 - val_loss: 0.7976
Epoch 3/20
11s - loss: 0.6380 - val_loss: 0.8140
Epoch 4/20
11s - loss: 0.6364 - val_loss: 0.7989
Epoch 5/20
11s - loss: 0.6349 - val_loss: 0.8691
Epoch 00004: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6737 - val_loss: 0.8452
Epoch 2/20
11s - loss: 0.6691 - val_loss: 0.8574
Epoch 3/20
11s - loss: 0.6676 - val_loss: 0.8341
Epoch 4/20
11s - loss: 0.6672 - val_loss: 0.8779
Epoch 5/20
11s - loss: 0.6667 - val_loss: 0.8495
Epoch 6/20
11s - loss: 0.6662 - val_loss: 0.8815
Epoch 7/20
11s - loss: 0.6656 - val_loss: 0.8610
Epoch 00006: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6662 - val_loss: 0.8397
Epoch 2/20
11s - loss: 0.6615 - val_loss: 0.8827
Epoch 3/20
11s - loss: 0.6600 - val_loss: 0.8544
Epoch 4/20
11s - loss: 0.6600 - val_loss: 0.8557
Epoch 5/20
11s - loss: 0.6592 - val_loss: 0.8680
Epoch 00004: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6815 - val_loss: 0.8865
Epoch 2/20
11s - loss: 0.6764 - val_loss: 0.8817
Epoch 3/20
11s - loss: 0.6752 - val_loss: 0.8451
Epoch 4/20
11s - loss: 0.6744 - val_loss: 0.8447
Epoch 5/20
11s - loss: 0.6742 - val_loss: 0.8603
Epoch 6/20
11s - loss: 0.6737 - val_loss: 0.8559
Epoch 7/20
11s - loss: 0.6731 - val_loss: 0.8528
Epoch 8/20
11s - loss: 0.6726 - val_loss: 0.8702
Epoch 00007: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6602 - val_loss: 0.8408
Epoch 2/20
11s - loss: 0.6551 - val_loss: 0.8209
Epoch 3/20
11s - loss: 0.6535 - val_loss: 0.8469
Epoch 4/20
11s - loss: 0.6531 - val_loss: 0.8257
Epoch 5/20
11s - loss: 0.6522 - val_loss: 0.8164
Epoch 6/20
11s - loss: 0.6514 - val_loss: 0.8338
Epoch 7/20
11s - loss: 0.6509 - val_loss: 0.8260
Epoch 8/20
11s - loss: 0.6502 - val_loss: 0.8498
Epoch 9/20
11s - loss: 0.6496 - val_loss: 0.8420
Epoch 00008: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6746 - val_loss: 0.8395
Epoch 2/20
11s - loss: 0.6695 - val_loss: 0.8689
Epoch 3/20
11s - loss: 0.6683 - val_loss: 0.8749
Epoch 4/20
11s - loss: 0.6673 - val_loss: 0.8858
Epoch 5/20
11s - loss: 0.6662 - val_loss: 0.8694
Epoch 00004: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6661 - val_loss: 0.8472
Epoch 2/20
11s - loss: 0.6607 - val_loss: 0.8535
Epoch 3/20
11s - loss: 0.6587 - val_loss: 0.8429
Epoch 4/20
11s - loss: 0.6577 - val_loss: 0.8453
Epoch 5/20
11s - loss: 0.6566 - val_loss: 0.8589
Epoch 6/20
11s - loss: 0.6555 - val_loss: 0.8584
Epoch 7/20
11s - loss: 0.6548 - val_loss: 0.8447
Epoch 00006: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6500 - val_loss: 0.8164
Epoch 2/20
11s - loss: 0.6378 - val_loss: 0.8039
Epoch 3/20
11s - loss: 0.6356 - val_loss: 0.7870
Epoch 4/20
11s - loss: 0.6334 - val_loss: 0.7725
Epoch 5/20
11s - loss: 0.6321 - val_loss: 0.8360
Epoch 6/20
11s - loss: 0.6308 - val_loss: 0.8398
Epoch 7/20
11s - loss: 0.6292 - val_loss: 0.8056
Epoch 8/20
11s - loss: 0.6284 - val_loss: 0.8241
Epoch 00007: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6472 - val_loss: 0.8678
Epoch 2/20
11s - loss: 0.6357 - val_loss: 0.8417
Epoch 3/20
11s - loss: 0.6326 - val_loss: 0.8152
Epoch 4/20
11s - loss: 0.6308 - val_loss: 0.9029
Epoch 5/20
11s - loss: 0.6287 - val_loss: 0.8472
Epoch 6/20
11s - loss: 0.6273 - val_loss: 0.8633
Epoch 7/20
11s - loss: 0.6262 - val_loss: 0.7971
Epoch 8/20
11s - loss: 0.6251 - val_loss: 0.7921
Epoch 9/20
11s - loss: 0.6237 - val_loss: 0.8482
Epoch 10/20
11s - loss: 0.6232 - val_loss: 0.8403
Epoch 11/20
11s - loss: 0.6222 - val_loss: 0.7942
Epoch 12/20
11s - loss: 0.6210 - val_loss: 0.8866
Epoch 00011: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6797 - val_loss: 0.8395
Epoch 2/20
11s - loss: 0.6750 - val_loss: 0.8795
Epoch 3/20
11s - loss: 0.6739 - val_loss: 0.8940
Epoch 4/20
11s - loss: 0.6732 - val_loss: 0.8601
Epoch 5/20
11s - loss: 0.6725 - val_loss: 0.8650
Epoch 00004: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6621 - val_loss: 0.8381
Epoch 2/20
11s - loss: 0.6552 - val_loss: 0.8411
Epoch 3/20
11s - loss: 0.6529 - val_loss: 0.8414
Epoch 4/20
11s - loss: 0.6514 - val_loss: 0.8356
Epoch 5/20
11s - loss: 0.6496 - val_loss: 0.8256
Epoch 6/20
11s - loss: 0.6481 - val_loss: 0.8546
Epoch 7/20
11s - loss: 0.6472 - val_loss: 0.8461
Epoch 8/20
11s - loss: 0.6459 - val_loss: 0.8041
Epoch 9/20
11s - loss: 0.6447 - val_loss: 0.8351
Epoch 10/20
11s - loss: 0.6436 - val_loss: 0.8642
Epoch 11/20
11s - loss: 0.6425 - val_loss: 0.8323
Epoch 12/20
11s - loss: 0.6418 - val_loss: 0.8607
Epoch 00011: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6641 - val_loss: 0.8578
Epoch 2/20
11s - loss: 0.6561 - val_loss: 0.8112
Epoch 3/20
11s - loss: 0.6528 - val_loss: 0.8253
Epoch 4/20
11s - loss: 0.6504 - val_loss: 0.8296
Epoch 5/20
11s - loss: 0.6483 - val_loss: 0.8180
Epoch 6/20
11s - loss: 0.6467 - val_loss: 0.8380
Epoch 00005: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6577 - val_loss: 0.8090
Epoch 2/20
11s - loss: 0.6529 - val_loss: 0.8698
Epoch 3/20
11s - loss: 0.6508 - val_loss: 0.8323
Epoch 4/20
11s - loss: 0.6500 - val_loss: 0.8364
Epoch 5/20
11s - loss: 0.6480 - val_loss: 0.8448
Epoch 00004: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6580 - val_loss: 0.8218
Epoch 2/20
11s - loss: 0.6534 - val_loss: 0.8627
Epoch 3/20
11s - loss: 0.6522 - val_loss: 0.8557
Epoch 4/20
11s - loss: 0.6513 - val_loss: 0.8565
Epoch 5/20
11s - loss: 0.6503 - val_loss: 0.8199
Epoch 6/20
11s - loss: 0.6494 - val_loss: 0.8442
Epoch 7/20
11s - loss: 0.6490 - val_loss: 0.8413
Epoch 8/20
11s - loss: 0.6483 - val_loss: 0.8474
Epoch 9/20
11s - loss: 0.6475 - val_loss: 0.8366
Epoch 00008: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6614 - val_loss: 0.8452
Epoch 2/20
11s - loss: 0.6544 - val_loss: 0.8318
Epoch 3/20
11s - loss: 0.6527 - val_loss: 0.8500
Epoch 4/20
11s - loss: 0.6508 - val_loss: 0.8241
Epoch 5/20
11s - loss: 0.6495 - val_loss: 0.8123
Epoch 6/20
11s - loss: 0.6479 - val_loss: 0.8833
Epoch 7/20
11s - loss: 0.6469 - val_loss: 0.8133
Epoch 8/20
11s - loss: 0.6458 - val_loss: 0.8382
Epoch 9/20
11s - loss: 0.6444 - val_loss: 0.8490
Epoch 00008: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6574 - val_loss: 0.8384
Epoch 2/20
11s - loss: 0.6472 - val_loss: 0.8140
Epoch 3/20
11s - loss: 0.6443 - val_loss: 0.8169
Epoch 4/20
11s - loss: 0.6421 - val_loss: 0.8004
Epoch 5/20
11s - loss: 0.6399 - val_loss: 0.8030
Epoch 6/20
11s - loss: 0.6382 - val_loss: 0.8468
Epoch 7/20
11s - loss: 0.6369 - val_loss: 0.8165
Epoch 8/20
11s - loss: 0.6360 - val_loss: 0.8476
Epoch 00007: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6608 - val_loss: 0.8668
Epoch 2/20
11s - loss: 0.6541 - val_loss: 0.8517
Epoch 3/20
11s - loss: 0.6520 - val_loss: 0.8801
Epoch 4/20
11s - loss: 0.6507 - val_loss: 0.8475
Epoch 5/20
11s - loss: 0.6496 - val_loss: 0.8435
Epoch 6/20
11s - loss: 0.6483 - val_loss: 0.8578
Epoch 7/20
11s - loss: 0.6473 - val_loss: 0.8621
Epoch 8/20
11s - loss: 0.6465 - val_loss: 0.8444
Epoch 9/20
11s - loss: 0.6460 - val_loss: 0.8147
Epoch 10/20
11s - loss: 0.6451 - val_loss: 0.8225
Epoch 11/20
11s - loss: 0.6444 - val_loss: 0.8479
Epoch 12/20
11s - loss: 0.6436 - val_loss: 0.8153
Epoch 13/20
11s - loss: 0.6426 - val_loss: 0.8614
Epoch 00012: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6794 - val_loss: 0.9059
Epoch 2/20
11s - loss: 0.6747 - val_loss: 0.8856
Epoch 3/20
11s - loss: 0.6738 - val_loss: 0.8492
Epoch 4/20
11s - loss: 0.6733 - val_loss: 0.8830
Epoch 5/20
11s - loss: 0.6730 - val_loss: 0.8676
Epoch 6/20
11s - loss: 0.6727 - val_loss: 0.8854
Epoch 7/20
11s - loss: 0.6723 - val_loss: 0.8645
Epoch 00006: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6771 - val_loss: 0.8812
Epoch 2/20
11s - loss: 0.6721 - val_loss: 0.8623
Epoch 3/20
11s - loss: 0.6710 - val_loss: 0.8755
Epoch 4/20
11s - loss: 0.6705 - val_loss: 0.8660
Epoch 5/20
11s - loss: 0.6704 - val_loss: 0.8603
Epoch 6/20
11s - loss: 0.6697 - val_loss: 0.8364
Epoch 7/20
11s - loss: 0.6695 - val_loss: 0.8280
Epoch 8/20
11s - loss: 0.6691 - val_loss: 0.8695
Epoch 9/20
11s - loss: 0.6686 - val_loss: 0.8451
Epoch 10/20
11s - loss: 0.6684 - val_loss: 0.8561
Epoch 11/20
11s - loss: 0.6679 - val_loss: 0.8344
Epoch 00010: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6808 - val_loss: 0.8653
Epoch 2/20
11s - loss: 0.6765 - val_loss: 0.9030
Epoch 3/20
11s - loss: 0.6746 - val_loss: 0.8815
Epoch 4/20
11s - loss: 0.6742 - val_loss: 0.8451
Epoch 5/20
11s - loss: 0.6742 - val_loss: 0.8749
Epoch 6/20
11s - loss: 0.6736 - val_loss: 0.8488
Epoch 7/20
11s - loss: 0.6734 - val_loss: 0.8661
Epoch 8/20
11s - loss: 0.6729 - val_loss: 0.8626
Epoch 00007: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6670 - val_loss: 0.8507
Epoch 2/20
11s - loss: 0.6623 - val_loss: 0.8449
Epoch 3/20
11s - loss: 0.6615 - val_loss: 0.8861
Epoch 4/20
11s - loss: 0.6606 - val_loss: 0.8642
Epoch 5/20
11s - loss: 0.6597 - val_loss: 0.8411
Epoch 6/20
11s - loss: 0.6589 - val_loss: 0.8790
Epoch 7/20
11s - loss: 0.6583 - val_loss: 0.8964
Epoch 8/20
11s - loss: 0.6570 - val_loss: 0.8761
Epoch 9/20
11s - loss: 0.6562 - val_loss: 0.8743
Epoch 00008: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6506 - val_loss: 0.8451
Epoch 2/20
11s - loss: 0.6431 - val_loss: 0.8092
Epoch 3/20
11s - loss: 0.6413 - val_loss: 0.8199
Epoch 4/20
11s - loss: 0.6400 - val_loss: 0.8936
Epoch 5/20
11s - loss: 0.6387 - val_loss: 0.8607
Epoch 6/20
11s - loss: 0.6375 - val_loss: 0.8685
Epoch 00005: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6552 - val_loss: 0.7984
Epoch 2/20
11s - loss: 0.6473 - val_loss: 0.8380
Epoch 3/20
11s - loss: 0.6455 - val_loss: 0.7954
Epoch 4/20
11s - loss: 0.6439 - val_loss: 0.8446
Epoch 5/20
11s - loss: 0.6426 - val_loss: 0.8123
Epoch 6/20
11s - loss: 0.6417 - val_loss: 0.8259
Epoch 7/20
11s - loss: 0.6407 - val_loss: 0.8699
Epoch 00006: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6365 - val_loss: 0.8033
Epoch 2/20
11s - loss: 0.6292 - val_loss: 0.8501
Epoch 3/20
11s - loss: 0.6267 - val_loss: 0.8110
Epoch 4/20
11s - loss: 0.6247 - val_loss: 0.7720
Epoch 5/20
11s - loss: 0.6227 - val_loss: 0.7819
Epoch 6/20
11s - loss: 0.6215 - val_loss: 0.8025
Epoch 7/20
11s - loss: 0.6206 - val_loss: 0.7749
Epoch 8/20
11s - loss: 0.6195 - val_loss: 0.8108
Epoch 00007: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6605 - val_loss: 0.8641
Epoch 2/20
11s - loss: 0.6520 - val_loss: 0.8354
Epoch 3/20
11s - loss: 0.6497 - val_loss: 0.8725
Epoch 4/20
11s - loss: 0.6476 - val_loss: 0.8575
Epoch 5/20
11s - loss: 0.6464 - val_loss: 0.8328
Epoch 6/20
11s - loss: 0.6450 - val_loss: 0.8320
Epoch 7/20
11s - loss: 0.6439 - val_loss: 0.8450
Epoch 8/20
11s - loss: 0.6430 - val_loss: 0.8463
Epoch 9/20
11s - loss: 0.6420 - val_loss: 0.8173
Epoch 10/20
11s - loss: 0.6408 - val_loss: 0.8299
Epoch 11/20
11s - loss: 0.6400 - val_loss: 0.8976
Epoch 12/20
11s - loss: 0.6392 - val_loss: 0.8455
Epoch 13/20
11s - loss: 0.6383 - val_loss: 0.8652
Epoch 00012: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6528 - val_loss: 0.8114
Epoch 2/20
11s - loss: 0.6433 - val_loss: 0.8019
Epoch 3/20
11s - loss: 0.6401 - val_loss: 0.8209
Epoch 4/20
11s - loss: 0.6382 - val_loss: 0.8353
Epoch 5/20
11s - loss: 0.6362 - val_loss: 0.8009
Epoch 6/20
11s - loss: 0.6349 - val_loss: 0.8370
Epoch 7/20
11s - loss: 0.6336 - val_loss: 0.8665
Epoch 8/20
11s - loss: 0.6323 - val_loss: 0.8196
Epoch 9/20
11s - loss: 0.6313 - val_loss: 0.8587
Epoch 00008: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6843 - val_loss: 0.8767
Epoch 2/20
11s - loss: 0.6797 - val_loss: 0.8700
Epoch 3/20
11s - loss: 0.6781 - val_loss: 0.8913
Epoch 4/20
11s - loss: 0.6776 - val_loss: 0.8739
Epoch 5/20
11s - loss: 0.6774 - val_loss: 0.8767
Epoch 6/20
11s - loss: 0.6773 - val_loss: 0.8857
Epoch 00005: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6688 - val_loss: 0.8563
Epoch 2/20
11s - loss: 0.6649 - val_loss: 0.8774
Epoch 3/20
11s - loss: 0.6637 - val_loss: 0.8449
Epoch 4/20
11s - loss: 0.6631 - val_loss: 0.8526
Epoch 5/20
11s - loss: 0.6626 - val_loss: 0.8481
Epoch 6/20
11s - loss: 0.6620 - val_loss: 0.8628
Epoch 7/20
11s - loss: 0.6615 - val_loss: 0.8333
Epoch 8/20
11s - loss: 0.6613 - val_loss: 0.8560
Epoch 9/20
11s - loss: 0.6608 - val_loss: 0.8741
Epoch 10/20
11s - loss: 0.6603 - val_loss: 0.8799
Epoch 11/20
11s - loss: 0.6601 - val_loss: 0.8474
Epoch 00010: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6469 - val_loss: 0.7660
Epoch 2/20
11s - loss: 0.6313 - val_loss: 0.7788
Epoch 3/20
11s - loss: 0.6282 - val_loss: 0.8057
Epoch 4/20
11s - loss: 0.6265 - val_loss: 0.8001
Epoch 5/20
11s - loss: 0.6254 - val_loss: 0.8084
Epoch 00004: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6627 - val_loss: 0.8698
Epoch 2/20
11s - loss: 0.6573 - val_loss: 0.8325
Epoch 3/20
11s - loss: 0.6555 - val_loss: 0.8677
Epoch 4/20
11s - loss: 0.6545 - val_loss: 0.8332
Epoch 5/20
11s - loss: 0.6539 - val_loss: 0.8242
Epoch 6/20
11s - loss: 0.6526 - val_loss: 0.8536
Epoch 7/20
11s - loss: 0.6524 - val_loss: 0.7960
Epoch 8/20
11s - loss: 0.6518 - val_loss: 0.8173
Epoch 9/20
11s - loss: 0.6511 - val_loss: 0.8562
Epoch 10/20
11s - loss: 0.6503 - val_loss: 0.8014
Epoch 11/20
11s - loss: 0.6501 - val_loss: 0.8442
Epoch 00010: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6777 - val_loss: 0.8792
Epoch 2/20
11s - loss: 0.6731 - val_loss: 0.8637
Epoch 3/20
11s - loss: 0.6717 - val_loss: 0.8775
Epoch 4/20
11s - loss: 0.6709 - val_loss: 0.8603
Epoch 5/20
11s - loss: 0.6706 - val_loss: 0.8744
Epoch 6/20
11s - loss: 0.6700 - val_loss: 0.8519
Epoch 7/20
11s - loss: 0.6694 - val_loss: 0.8854
Epoch 8/20
11s - loss: 0.6689 - val_loss: 0.8625
Epoch 9/20
11s - loss: 0.6684 - val_loss: 0.8539
Epoch 10/20
11s - loss: 0.6677 - val_loss: 0.8722
Epoch 00009: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6604 - val_loss: 0.8586
Epoch 2/20
11s - loss: 0.6541 - val_loss: 0.8669
Epoch 3/20
11s - loss: 0.6520 - val_loss: 0.8511
Epoch 4/20
11s - loss: 0.6503 - val_loss: 0.8490
Epoch 5/20
11s - loss: 0.6489 - val_loss: 0.7792
Epoch 6/20
11s - loss: 0.6478 - val_loss: 0.8309
Epoch 7/20
11s - loss: 0.6469 - val_loss: 0.8118
Epoch 8/20
11s - loss: 0.6462 - val_loss: 0.8585
Epoch 9/20
11s - loss: 0.6457 - val_loss: 0.8363
Epoch 00008: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6599 - val_loss: 0.8614
Epoch 2/20
11s - loss: 0.6498 - val_loss: 0.8324
Epoch 3/20
11s - loss: 0.6471 - val_loss: 0.8398
Epoch 4/20
11s - loss: 0.6449 - val_loss: 0.8170
Epoch 5/20
11s - loss: 0.6436 - val_loss: 0.8657
Epoch 6/20
11s - loss: 0.6426 - val_loss: 0.7935
Epoch 7/20
11s - loss: 0.6413 - val_loss: 0.8373
Epoch 8/20
11s - loss: 0.6405 - val_loss: 0.8533
Epoch 9/20
11s - loss: 0.6397 - val_loss: 0.8082
Epoch 10/20
11s - loss: 0.6389 - val_loss: 0.8601
Epoch 00009: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6673 - val_loss: 0.8673
Epoch 2/20
11s - loss: 0.6625 - val_loss: 0.8718
Epoch 3/20
11s - loss: 0.6611 - val_loss: 0.8710
Epoch 4/20
11s - loss: 0.6603 - val_loss: 0.8762
Epoch 5/20
11s - loss: 0.6591 - val_loss: 0.8792
Epoch 00004: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6719 - val_loss: 0.8532
Epoch 2/20
11s - loss: 0.6664 - val_loss: 0.8444
Epoch 3/20
11s - loss: 0.6645 - val_loss: 0.8901
Epoch 4/20
11s - loss: 0.6636 - val_loss: 0.8654
Epoch 5/20
11s - loss: 0.6622 - val_loss: 0.8475
Epoch 6/20
11s - loss: 0.6613 - val_loss: 0.8357
Epoch 7/20
11s - loss: 0.6606 - val_loss: 0.8864
Epoch 8/20
11s - loss: 0.6597 - val_loss: 0.8621
Epoch 9/20
11s - loss: 0.6593 - val_loss: 0.8601
Epoch 10/20
11s - loss: 0.6583 - val_loss: 0.8626
Epoch 00009: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6790 - val_loss: 0.8670
Epoch 2/20
11s - loss: 0.6742 - val_loss: 0.8576
Epoch 3/20
11s - loss: 0.6727 - val_loss: 0.8634
Epoch 4/20
11s - loss: 0.6723 - val_loss: 0.8566
Epoch 5/20
11s - loss: 0.6717 - val_loss: 0.8533
Epoch 6/20
11s - loss: 0.6715 - val_loss: 0.8680
Epoch 7/20
11s - loss: 0.6710 - val_loss: 0.8738
Epoch 8/20
11s - loss: 0.6707 - val_loss: 0.8628
Epoch 9/20
11s - loss: 0.6704 - val_loss: 0.8829
Epoch 00008: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6776 - val_loss: 0.8779
Epoch 2/20
11s - loss: 0.6728 - val_loss: 0.8691
Epoch 3/20
11s - loss: 0.6714 - val_loss: 0.8642
Epoch 4/20
11s - loss: 0.6706 - val_loss: 0.8607
Epoch 5/20
11s - loss: 0.6701 - val_loss: 0.8778
Epoch 6/20
11s - loss: 0.6695 - val_loss: 0.8761
Epoch 7/20
11s - loss: 0.6686 - val_loss: 0.8682
Epoch 8/20
11s - loss: 0.6681 - val_loss: 0.8905
Epoch 00007: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6213 - val_loss: 0.7580
Epoch 2/20
11s - loss: 0.6134 - val_loss: 0.7493
Epoch 3/20
11s - loss: 0.6104 - val_loss: 0.7536
Epoch 4/20
11s - loss: 0.6082 - val_loss: 0.7835
Epoch 5/20
11s - loss: 0.6067 - val_loss: 0.7707
Epoch 6/20
11s - loss: 0.6052 - val_loss: 0.7665
Epoch 00005: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6571 - val_loss: 0.8336
Epoch 2/20
11s - loss: 0.6517 - val_loss: 0.8518
Epoch 3/20
11s - loss: 0.6500 - val_loss: 0.8584
Epoch 4/20
11s - loss: 0.6490 - val_loss: 0.8597
Epoch 5/20
11s - loss: 0.6477 - val_loss: 0.8230
Epoch 6/20
11s - loss: 0.6469 - val_loss: 0.8301
Epoch 7/20
11s - loss: 0.6461 - val_loss: 0.8628
Epoch 8/20
11s - loss: 0.6452 - val_loss: 0.8781
Epoch 9/20
11s - loss: 0.6447 - val_loss: 0.8655
Epoch 00008: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6739 - val_loss: 0.8661
Epoch 2/20
11s - loss: 0.6689 - val_loss: 0.8434
Epoch 3/20
11s - loss: 0.6674 - val_loss: 0.8520
Epoch 4/20
11s - loss: 0.6661 - val_loss: 0.8534
Epoch 5/20
11s - loss: 0.6653 - val_loss: 0.8913
Epoch 6/20
11s - loss: 0.6647 - val_loss: 0.8545
Epoch 00005: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6560 - val_loss: 0.8368
Epoch 2/20
11s - loss: 0.6501 - val_loss: 0.8730
Epoch 3/20
11s - loss: 0.6481 - val_loss: 0.8467
Epoch 4/20
11s - loss: 0.6466 - val_loss: 0.8219
Epoch 5/20
11s - loss: 0.6455 - val_loss: 0.8521
Epoch 6/20
11s - loss: 0.6445 - val_loss: 0.8369
Epoch 7/20
11s - loss: 0.6434 - val_loss: 0.8099
Epoch 8/20
11s - loss: 0.6425 - val_loss: 0.8556
Epoch 9/20
11s - loss: 0.6417 - val_loss: 0.8454
Epoch 10/20
11s - loss: 0.6409 - val_loss: 0.8681
Epoch 11/20
11s - loss: 0.6401 - val_loss: 0.8248
Epoch 00010: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6557 - val_loss: 0.8446
Epoch 2/20
11s - loss: 0.6479 - val_loss: 0.8357
Epoch 3/20
11s - loss: 0.6447 - val_loss: 0.8479
Epoch 4/20
11s - loss: 0.6424 - val_loss: 0.8555
Epoch 5/20
11s - loss: 0.6408 - val_loss: 0.8215
Epoch 6/20
11s - loss: 0.6399 - val_loss: 0.8373
Epoch 7/20
11s - loss: 0.6385 - val_loss: 0.8184
Epoch 8/20
11s - loss: 0.6381 - val_loss: 0.8241
Epoch 9/20
11s - loss: 0.6370 - val_loss: 0.7855
Epoch 10/20
11s - loss: 0.6365 - val_loss: 0.8110
Epoch 11/20
11s - loss: 0.6354 - val_loss: 0.8272
Epoch 12/20
11s - loss: 0.6349 - val_loss: 0.8417
Epoch 13/20
11s - loss: 0.6339 - val_loss: 0.8087
Epoch 00012: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6544 - val_loss: 0.8691
Epoch 2/20
11s - loss: 0.6471 - val_loss: 0.8353
Epoch 3/20
11s - loss: 0.6456 - val_loss: 0.8743
Epoch 4/20
11s - loss: 0.6447 - val_loss: 0.8374
Epoch 5/20
11s - loss: 0.6430 - val_loss: 0.8238
Epoch 6/20
11s - loss: 0.6418 - val_loss: 0.8342
Epoch 7/20
11s - loss: 0.6413 - val_loss: 0.8319
Epoch 8/20
11s - loss: 0.6407 - val_loss: 0.8474
Epoch 9/20
11s - loss: 0.6395 - val_loss: 0.8097
Epoch 10/20
11s - loss: 0.6391 - val_loss: 0.8577
Epoch 11/20
11s - loss: 0.6379 - val_loss: 0.8354
Epoch 12/20
11s - loss: 0.6375 - val_loss: 0.8510
Epoch 13/20
11s - loss: 0.6365 - val_loss: 0.8345
Epoch 00012: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6524 - val_loss: 0.8366
Epoch 2/20
11s - loss: 0.6390 - val_loss: 0.8318
Epoch 3/20
11s - loss: 0.6362 - val_loss: 0.8196
Epoch 4/20
11s - loss: 0.6342 - val_loss: 0.8115
Epoch 5/20
11s - loss: 0.6331 - val_loss: 0.7768
Epoch 6/20
11s - loss: 0.6314 - val_loss: 0.8460
Epoch 7/20
11s - loss: 0.6301 - val_loss: 0.8563
Epoch 8/20
11s - loss: 0.6288 - val_loss: 0.8182
Epoch 9/20
11s - loss: 0.6280 - val_loss: 0.8509
Epoch 00008: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6608 - val_loss: 0.8917
Epoch 2/20
11s - loss: 0.6548 - val_loss: 0.8529
Epoch 3/20
11s - loss: 0.6530 - val_loss: 0.8329
Epoch 4/20
11s - loss: 0.6520 - val_loss: 0.8422
Epoch 5/20
11s - loss: 0.6507 - val_loss: 0.8401
Epoch 6/20
11s - loss: 0.6499 - val_loss: 0.8234
Epoch 7/20
11s - loss: 0.6491 - val_loss: 0.8404
Epoch 8/20
11s - loss: 0.6481 - val_loss: 0.8441
Epoch 9/20
11s - loss: 0.6474 - val_loss: 0.8669
Epoch 10/20
11s - loss: 0.6467 - val_loss: 0.8998
Epoch 00009: early stopping
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6520 - val_loss: 0.8541
Epoch 2/20
11s - loss: 0.6446 - val_loss: 0.8078
Epoch 3/20
11s - loss: 0.6426 - val_loss: 0.8671
Epoch 4/20
11s - loss: 0.6407 - val_loss: 0.8930
Epoch 5/20
11s - loss: 0.6393 - val_loss: 0.8027
Epoch 6/20
11s - loss: 0.6382 - val_loss: 0.8220
Epoch 7/20
11s - loss: 0.6371 - val_loss: 0.8458
Epoch 8/20
11s - loss: 0.6359 - val_loss: 0.8118
Epoch 9/20
11s - loss: 0.6352 - val_loss: 0.8073
Epoch 00008: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6692 - val_loss: 0.8283
Epoch 2/20
11s - loss: 0.6645 - val_loss: 0.8777
Epoch 3/20
11s - loss: 0.6637 - val_loss: 0.8387
Epoch 4/20
11s - loss: 0.6632 - val_loss: 0.8793
Epoch 5/20
11s - loss: 0.6625 - val_loss: 0.8621
Epoch 00004: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6740 - val_loss: 0.8670
Epoch 2/20
11s - loss: 0.6688 - val_loss: 0.8760
Epoch 3/20
11s - loss: 0.6672 - val_loss: 0.8914
Epoch 4/20
11s - loss: 0.6662 - val_loss: 0.8748
Epoch 5/20
11s - loss: 0.6655 - val_loss: 0.8788
Epoch 00004: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6551 - val_loss: 0.8250
Epoch 2/20
11s - loss: 0.6443 - val_loss: 0.8814
Epoch 3/20
11s - loss: 0.6401 - val_loss: 0.8292
Epoch 4/20
11s - loss: 0.6374 - val_loss: 0.8076
Epoch 5/20
11s - loss: 0.6354 - val_loss: 0.8177
Epoch 6/20
11s - loss: 0.6338 - val_loss: 0.8430
Epoch 7/20
11s - loss: 0.6327 - val_loss: 0.8362
Epoch 8/20
11s - loss: 0.6308 - val_loss: 0.8379
Epoch 00007: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6759 - val_loss: 0.8646
Epoch 2/20
11s - loss: 0.6710 - val_loss: 0.8533
Epoch 3/20
11s - loss: 0.6702 - val_loss: 0.8330
Epoch 4/20
11s - loss: 0.6697 - val_loss: 0.8488
Epoch 5/20
11s - loss: 0.6696 - val_loss: 0.8626
Epoch 6/20
11s - loss: 0.6688 - val_loss: 0.8784
Epoch 7/20
11s - loss: 0.6684 - val_loss: 0.8651
Epoch 00006: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6598 - val_loss: 0.8448
Epoch 2/20
11s - loss: 0.6508 - val_loss: 0.8512
Epoch 3/20
12s - loss: 0.6484 - val_loss: 0.8486
Epoch 4/20
11s - loss: 0.6464 - val_loss: 0.8492
Epoch 5/20
11s - loss: 0.6452 - val_loss: 0.8730
Epoch 00004: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6766 - val_loss: 0.9006
Epoch 2/20
11s - loss: 0.6718 - val_loss: 0.8746
Epoch 3/20
11s - loss: 0.6705 - val_loss: 0.8429
Epoch 4/20
11s - loss: 0.6692 - val_loss: 0.8660
Epoch 5/20
11s - loss: 0.6691 - val_loss: 0.8823
Epoch 6/20
11s - loss: 0.6682 - val_loss: 0.8602
Epoch 7/20
11s - loss: 0.6678 - val_loss: 0.8830
Epoch 00006: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6494 - val_loss: 0.7917
Epoch 2/20
11s - loss: 0.6418 - val_loss: 0.7995
Epoch 3/20
11s - loss: 0.6389 - val_loss: 0.8067
Epoch 4/20
11s - loss: 0.6359 - val_loss: 0.8289
Epoch 5/20
11s - loss: 0.6345 - val_loss: 0.8369
Epoch 00004: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6563 - val_loss: 0.9013
Epoch 2/20
11s - loss: 0.6509 - val_loss: 0.8683
Epoch 3/20
11s - loss: 0.6495 - val_loss: 0.8337
Epoch 4/20
11s - loss: 0.6480 - val_loss: 0.8729
Epoch 5/20
11s - loss: 0.6470 - val_loss: 0.8360
Epoch 6/20
11s - loss: 0.6460 - val_loss: 0.8244
Epoch 7/20
11s - loss: 0.6448 - val_loss: 0.8565
Epoch 8/20
11s - loss: 0.6439 - val_loss: 0.8947
Epoch 9/20
11s - loss: 0.6430 - val_loss: 0.8772
Epoch 10/20
11s - loss: 0.6426 - val_loss: 0.8173
Epoch 11/20
11s - loss: 0.6417 - val_loss: 0.8161
Epoch 12/20
11s - loss: 0.6408 - val_loss: 0.8061
Epoch 13/20
11s - loss: 0.6405 - val_loss: 0.8202
Epoch 14/20
11s - loss: 0.6397 - val_loss: 0.8440
Epoch 15/20
11s - loss: 0.6393 - val_loss: 0.8170
Epoch 16/20
11s - loss: 0.6390 - val_loss: 0.8333
Epoch 00015: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6587 - val_loss: 0.8648
Epoch 2/20
11s - loss: 0.6528 - val_loss: 0.8101
Epoch 3/20
11s - loss: 0.6515 - val_loss: 0.8368
Epoch 4/20
11s - loss: 0.6501 - val_loss: 0.8120
Epoch 5/20
12s - loss: 0.6494 - val_loss: 0.8174
Epoch 6/20
11s - loss: 0.6484 - val_loss: 0.8093
Epoch 7/20
11s - loss: 0.6475 - val_loss: 0.8359
Epoch 8/20
12s - loss: 0.6468 - val_loss: 0.8606
Epoch 9/20
11s - loss: 0.6461 - val_loss: 0.8040
Epoch 10/20
 11s - loss: 0.6454 - val_loss: 0.8546
Epoch 11/20
12s - loss: 0.6449 - val_loss: 0.8529
Epoch 12/20
11s - loss: 0.6438 - val_loss: 0.8266
Epoch 13/20
12s - loss: 0.6435 - val_loss: 0.8539
Epoch 00012: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  5.96945611e+000,  -7.42659219e-214]), 'nit': 0, 'funcalls': 21}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 33554437.99979693,        -0.        ]), 'nit': 4, 'funcalls': 78}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.07046326e+07,  -4.33109821e+01]), 'nit': 2, 'funcalls': 56}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.07234096e+08,  -7.20026206e+05]), 'nit': 2, 'funcalls': 72}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.73360692e+07,  -9.64398952e+02]), 'nit': 3, 'funcalls': 65}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 5.99972258, -0.        ]), 'nit': 5, 'funcalls': 69}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  6.71088700e+07,  -2.14438481e-68]), 'nit': 2, 'funcalls': 51}
  " state: %s" % convergence_dict)
Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   1

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-12 22:15:18.968412: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 22:15:18.969628: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 22:15:18.969638: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 22:15:18.969642: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 22:15:18.969646: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-12 22:15:19.263389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-12 22:15:19.263424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-12 22:15:19.263430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-12 22:15:19.263439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
11s - loss: 0.6683 - val_loss: 0.8513
Epoch 2/20
10s - loss: 0.6637 - val_loss: 0.8516
Epoch 3/20
10s - loss: 0.6627 - val_loss: 0.8892
Epoch 4/20
10s - loss: 0.6622 - val_loss: 0.8419
Epoch 5/20
10s - loss: 0.6614 - val_loss: 0.8774
Epoch 6/20
10s - loss: 0.6607 - val_loss: 0.8492
Epoch 7/20
10s - loss: 0.6602 - val_loss: 0.8474
Epoch 8/20
10s - loss: 0.6593 - val_loss: 0.8517
Epoch 00007: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6457 - val_loss: 0.8090
Epoch 2/20
10s - loss: 0.6260 - val_loss: 0.8206
Epoch 3/20
10s - loss: 0.6223 - val_loss: 0.8326
Epoch 4/20
10s - loss: 0.6202 - val_loss: 0.7826
Epoch 5/20
10s - loss: 0.6184 - val_loss: 0.7677
Epoch 6/20
10s - loss: 0.6167 - val_loss: 0.7950
Epoch 7/20
10s - loss: 0.6159 - val_loss: 0.7872
Epoch 8/20
10s - loss: 0.6141 - val_loss: 0.8076
Epoch 9/20
10s - loss: 0.6131 - val_loss: 0.7875
Epoch 00008: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6346 - val_loss: 0.7965
Epoch 2/20
10s - loss: 0.6175 - val_loss: 0.8075
Epoch 3/20
10s - loss: 0.6116 - val_loss: 0.7913
Epoch 4/20
10s - loss: 0.6086 - val_loss: 0.8120
Epoch 5/20
10s - loss: 0.6064 - val_loss: 0.8068
Epoch 6/20
10s - loss: 0.6048 - val_loss: 0.7319
Epoch 7/20
10s - loss: 0.6033 - val_loss: 0.7802
Epoch 8/20
10s - loss: 0.6018 - val_loss: 0.7647
Epoch 9/20
10s - loss: 0.6006 - val_loss: 0.7853
Epoch 10/20
10s - loss: 0.5993 - val_loss: 0.7926
Epoch 00009: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6101 - val_loss: 0.7446
Epoch 2/20
10s - loss: 0.6022 - val_loss: 0.7717
Epoch 3/20
10s - loss: 0.5983 - val_loss: 0.7742
Epoch 4/20
10s - loss: 0.5955 - val_loss: 0.7396
Epoch 5/20
10s - loss: 0.5941 - val_loss: 0.7564
Epoch 6/20
10s - loss: 0.5925 - val_loss: 0.7487
Epoch 7/20
10s - loss: 0.5913 - val_loss: 0.7407
Epoch 8/20
10s - loss: 0.5904 - val_loss: 0.7657
Epoch 00007: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6661 - val_loss: 0.8263
Epoch 2/20
10s - loss: 0.6616 - val_loss: 0.8279
Epoch 3/20
10s - loss: 0.6604 - val_loss: 0.8661
Epoch 4/20
10s - loss: 0.6601 - val_loss: 0.8239
Epoch 5/20
10s - loss: 0.6594 - val_loss: 0.8308
Epoch 6/20
10s - loss: 0.6591 - val_loss: 0.8548
Epoch 7/20
10s - loss: 0.6588 - val_loss: 0.8344
Epoch 8/20
10s - loss: 0.6583 - val_loss: 0.8516
Epoch 00007: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6563 - val_loss: 0.8519
Epoch 2/20
10s - loss: 0.6499 - val_loss: 0.8376
Epoch 3/20
10s - loss: 0.6476 - val_loss: 0.8391
Epoch 4/20
10s - loss: 0.6462 - val_loss: 0.8662
Epoch 5/20
10s - loss: 0.6453 - val_loss: 0.8167
Epoch 6/20
10s - loss: 0.6442 - val_loss: 0.8684
Epoch 7/20
10s - loss: 0.6435 - val_loss: 0.7998
Epoch 8/20
10s - loss: 0.6425 - val_loss: 0.8167
Epoch 9/20
10s - loss: 0.6422 - val_loss: 0.8473
Epoch 10/20
10s - loss: 0.6411 - val_loss: 0.8302
Epoch 11/20
10s - loss: 0.6407 - val_loss: 0.8186
Epoch 00010: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6613 - val_loss: 0.8512
Epoch 2/20
10s - loss: 0.6552 - val_loss: 0.8627
Epoch 3/20
10s - loss: 0.6529 - val_loss: 0.8641
Epoch 4/20
10s - loss: 0.6514 - val_loss: 0.8268
Epoch 5/20
10s - loss: 0.6503 - val_loss: 0.8321
Epoch 6/20
10s - loss: 0.6490 - val_loss: 0.8489
Epoch 7/20
10s - loss: 0.6478 - val_loss: 0.8397
Epoch 8/20
10s - loss: 0.6471 - val_loss: 0.8233
Epoch 9/20
10s - loss: 0.6459 - val_loss: 0.8077
Epoch 10/20
10s - loss: 0.6452 - val_loss: 0.8550
Epoch 11/20
10s - loss: 0.6446 - val_loss: 0.8508
Epoch 12/20
10s - loss: 0.6434 - val_loss: 0.8282
Epoch 13/20
10s - loss: 0.6428 - val_loss: 0.8253
Epoch 00012: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6412 - val_loss: 0.8181
Epoch 2/20
10s - loss: 0.6348 - val_loss: 0.8217
Epoch 3/20
10s - loss: 0.6327 - val_loss: 0.7979
Epoch 4/20
10s - loss: 0.6312 - val_loss: 0.8145
Epoch 5/20
10s - loss: 0.6295 - val_loss: 0.8045
Epoch 6/20
10s - loss: 0.6284 - val_loss: 0.7989
Epoch 7/20
10s - loss: 0.6275 - val_loss: 0.8435
Epoch 00006: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6849 - val_loss: 0.8725
Epoch 2/20
10s - loss: 0.6807 - val_loss: 0.8670
Epoch 3/20
10s - loss: 0.6795 - val_loss: 0.8814
Epoch 4/20
10s - loss: 0.6790 - val_loss: 0.8564
Epoch 5/20
10s - loss: 0.6789 - val_loss: 0.8682
Epoch 6/20
10s - loss: 0.6786 - val_loss: 0.8606
Epoch 7/20
10s - loss: 0.6787 - val_loss: 0.8712
Epoch 8/20
10s - loss: 0.6782 - val_loss: 0.8556
Epoch 9/20
10s - loss: 0.6778 - val_loss: 0.8418
Epoch 10/20
10s - loss: 0.6775 - val_loss: 0.8902
Epoch 11/20
10s - loss: 0.6770 - val_loss: 0.8503
Epoch 12/20
10s - loss: 0.6770 - val_loss: 0.8626
Epoch 13/20
10s - loss: 0.6766 - val_loss: 0.8653
Epoch 00012: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6551 - val_loss: 0.8410
Epoch 2/20
10s - loss: 0.6481 - val_loss: 0.8448
Epoch 3/20
10s - loss: 0.6457 - val_loss: 0.8601
Epoch 4/20
10s - loss: 0.6439 - val_loss: 0.8605
Epoch 5/20
10s - loss: 0.6423 - val_loss: 0.8155
Epoch 6/20
10s - loss: 0.6414 - val_loss: 0.8414
Epoch 7/20
10s - loss: 0.6401 - val_loss: 0.8412
Epoch 8/20
10s - loss: 0.6393 - val_loss: 0.8349
Epoch 9/20
10s - loss: 0.6388 - val_loss: 0.8567
Epoch 00008: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6691 - val_loss: 0.8299
Epoch 2/20
10s - loss: 0.6629 - val_loss: 0.8750
Epoch 3/20
10s - loss: 0.6610 - val_loss: 0.8390
Epoch 4/20
10s - loss: 0.6598 - val_loss: 0.8467
Epoch 5/20
10s - loss: 0.6589 - val_loss: 0.8632
Epoch 00004: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6834 - val_loss: 0.8824
Epoch 2/20
10s - loss: 0.6786 - val_loss: 0.8877
Epoch 3/20
10s - loss: 0.6772 - val_loss: 0.8488
Epoch 4/20
10s - loss: 0.6771 - val_loss: 0.8726
Epoch 5/20
10s - loss: 0.6767 - val_loss: 0.8875
Epoch 6/20
10s - loss: 0.6764 - val_loss: 0.8781
Epoch 7/20
10s - loss: 0.6763 - val_loss: 0.8744
Epoch 00006: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6855 - val_loss: 0.8821
Epoch 2/20
10s - loss: 0.6810 - val_loss: 0.9156
Epoch 3/20
10s - loss: 0.6794 - val_loss: 0.8493
Epoch 4/20
10s - loss: 0.6792 - val_loss: 0.8832
Epoch 5/20
10s - loss: 0.6789 - val_loss: 0.8786
Epoch 6/20
10s - loss: 0.6788 - val_loss: 0.8779
Epoch 7/20
10s - loss: 0.6786 - val_loss: 0.8870
Epoch 00006: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6634 - val_loss: 0.8240
Epoch 2/20
10s - loss: 0.6574 - val_loss: 0.8447
Epoch 3/20
10s - loss: 0.6559 - val_loss: 0.8526
Epoch 4/20
10s - loss: 0.6545 - val_loss: 0.8234
Epoch 5/20
10s - loss: 0.6534 - val_loss: 0.8314
Epoch 6/20
10s - loss: 0.6524 - val_loss: 0.8205
Epoch 7/20
10s - loss: 0.6518 - val_loss: 0.8175
Epoch 8/20
10s - loss: 0.6508 - val_loss: 0.8355
Epoch 9/20
10s - loss: 0.6506 - val_loss: 0.8383
Epoch 10/20
10s - loss: 0.6495 - val_loss: 0.8537
Epoch 11/20
10s - loss: 0.6490 - val_loss: 0.8305
Epoch 00010: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6554 - val_loss: 0.8389
Epoch 2/20
10s - loss: 0.6495 - val_loss: 0.8846
Epoch 3/20
10s - loss: 0.6481 - val_loss: 0.8560
Epoch 4/20
10s - loss: 0.6469 - val_loss: 0.8320
Epoch 5/20
10s - loss: 0.6454 - val_loss: 0.8263
Epoch 6/20
10s - loss: 0.6443 - val_loss: 0.8194
Epoch 7/20
10s - loss: 0.6433 - val_loss: 0.7925
Epoch 8/20
10s - loss: 0.6423 - val_loss: 0.8637
Epoch 9/20
10s - loss: 0.6415 - val_loss: 0.8131
Epoch 10/20
10s - loss: 0.6407 - val_loss: 0.8043
Epoch 11/20
10s - loss: 0.6399 - val_loss: 0.8090
Epoch 00010: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6573 - val_loss: 0.8801
Epoch 2/20
10s - loss: 0.6518 - val_loss: 0.8153
Epoch 3/20
10s - loss: 0.6502 - val_loss: 0.8395
Epoch 4/20
10s - loss: 0.6487 - val_loss: 0.8265
Epoch 5/20
10s - loss: 0.6475 - val_loss: 0.8426
Epoch 6/20
10s - loss: 0.6466 - val_loss: 0.8381
Epoch 00005: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6581 - val_loss: 0.8411
Epoch 2/20
10s - loss: 0.6491 - val_loss: 0.8460
Epoch 3/20
10s - loss: 0.6458 - val_loss: 0.8531
Epoch 4/20
10s - loss: 0.6436 - val_loss: 0.8501
Epoch 5/20
10s - loss: 0.6417 - val_loss: 0.8537
Epoch 00004: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6697 - val_loss: 0.8703
Epoch 2/20
10s - loss: 0.6644 - val_loss: 0.8541
Epoch 3/20
10s - loss: 0.6627 - val_loss: 0.8384
Epoch 4/20
10s - loss: 0.6612 - val_loss: 0.8590
Epoch 5/20
10s - loss: 0.6602 - val_loss: 0.8613
Epoch 6/20
10s - loss: 0.6589 - val_loss: 0.9028
Epoch 7/20
10s - loss: 0.6580 - val_loss: 0.8612
Epoch 00006: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6261 - val_loss: 0.7960
Epoch 2/20
10s - loss: 0.6196 - val_loss: 0.7645
Epoch 3/20
10s - loss: 0.6160 - val_loss: 0.7705
Epoch 4/20
10s - loss: 0.6141 - val_loss: 0.7669
Epoch 5/20
10s - loss: 0.6125 - val_loss: 0.7957
Epoch 6/20
10s - loss: 0.6110 - val_loss: 0.8220
Epoch 00005: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6510 - val_loss: 0.8225
Epoch 2/20
10s - loss: 0.6429 - val_loss: 0.8529
Epoch 3/20
10s - loss: 0.6396 - val_loss: 0.8195
Epoch 4/20
10s - loss: 0.6377 - val_loss: 0.8078
Epoch 5/20
10s - loss: 0.6357 - val_loss: 0.8061
Epoch 6/20
10s - loss: 0.6349 - val_loss: 0.8597
Epoch 7/20
10s - loss: 0.6340 - val_loss: 0.8640
Epoch 8/20
10s - loss: 0.6331 - val_loss: 0.7920
Epoch 9/20
10s - loss: 0.6322 - val_loss: 0.8181
Epoch 10/20
10s - loss: 0.6316 - val_loss: 0.8274
Epoch 11/20
10s - loss: 0.6314 - val_loss: 0.8159
Epoch 12/20
10s - loss: 0.6301 - val_loss: 0.8244
Epoch 00011: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6742 - val_loss: 0.8705
Epoch 2/20
10s - loss: 0.6690 - val_loss: 0.8686
Epoch 3/20
10s - loss: 0.6676 - val_loss: 0.8343
Epoch 4/20
10s - loss: 0.6670 - val_loss: 0.8439
Epoch 5/20
10s - loss: 0.6661 - val_loss: 0.8547
Epoch 6/20
10s - loss: 0.6658 - val_loss: 0.8816
Epoch 7/20
10s - loss: 0.6652 - val_loss: 0.8575
Epoch 00006: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
10s - loss: 0.6537 - val_loss: 0.8180
Epoch 2/20
10s - loss: 0.6407 - val_loss: 0.8227
Epoch 3/20
10s - loss: 0.6348 - val_loss: 0.7667
Epoch 4/20
10s - loss: 0.6320 - val_loss: 0.8443
Epoch 5/20
10s - loss: 0.6300 - val_loss: 0.7812
Epoch 6/20
10s - loss: 0.6282 - val_loss: 0.8289
Epoch 7/20
10s - loss: 0.6271 - val_loss: 0.7709
Epoch 00006: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6553 - val_loss: 0.7817
Epoch 2/20
10s - loss: 0.6456 - val_loss: 0.8055
Epoch 3/20
10s - loss: 0.6435 - val_loss: 0.8105
Epoch 4/20
10s - loss: 0.6416 - val_loss: 0.8108
Epoch 5/20
10s - loss: 0.6404 - val_loss: 0.8930
Epoch 00004: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6657 - val_loss: 0.8187
Epoch 2/20
10s - loss: 0.6608 - val_loss: 0.8612
Epoch 3/20
10s - loss: 0.6594 - val_loss: 0.8492
Epoch 4/20
10s - loss: 0.6583 - val_loss: 0.8610
Epoch 5/20
10s - loss: 0.6576 - val_loss: 0.8626
Epoch 00004: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6651 - val_loss: 0.8450
Epoch 2/20
10s - loss: 0.6604 - val_loss: 0.8652
Epoch 3/20
10s - loss: 0.6589 - val_loss: 0.8692
Epoch 4/20
10s - loss: 0.6583 - val_loss: 0.8468
Epoch 5/20
10s - loss: 0.6572 - val_loss: 0.8789
Epoch 00004: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6503 - val_loss: 0.8555
Epoch 2/20
10s - loss: 0.6435 - val_loss: 0.8663
Epoch 3/20
10s - loss: 0.6416 - val_loss: 0.8156
Epoch 4/20
10s - loss: 0.6398 - val_loss: 0.8313
Epoch 5/20
10s - loss: 0.6385 - val_loss: 0.8362
Epoch 6/20
10s - loss: 0.6377 - val_loss: 0.8247
Epoch 7/20
10s - loss: 0.6364 - val_loss: 0.8017
Epoch 8/20
10s - loss: 0.6357 - val_loss: 0.8269
Epoch 9/20
10s - loss: 0.6350 - val_loss: 0.7947
Epoch 10/20
10s - loss: 0.6338 - val_loss: 0.8161
Epoch 11/20
10s - loss: 0.6333 - val_loss: 0.8375
Epoch 12/20
10s - loss: 0.6330 - val_loss: 0.8074
Epoch 13/20
10s - loss: 0.6322 - val_loss: 0.8438
Epoch 00012: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6833 - val_loss: 0.8596
Epoch 2/20
10s - loss: 0.6795 - val_loss: 0.8594
Epoch 3/20
10s - loss: 0.6779 - val_loss: 0.8987
Epoch 4/20
10s - loss: 0.6778 - val_loss: 0.8464
Epoch 5/20
10s - loss: 0.6775 - val_loss: 0.8659
Epoch 6/20
10s - loss: 0.6772 - val_loss: 0.8695
Epoch 7/20
10s - loss: 0.6768 - val_loss: 0.8858
Epoch 8/20
10s - loss: 0.6764 - val_loss: 0.8862
Epoch 00007: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6513 - val_loss: 0.7883
Epoch 2/20
10s - loss: 0.6419 - val_loss: 0.8054
Epoch 3/20
10s - loss: 0.6380 - val_loss: 0.8695
Epoch 4/20
10s - loss: 0.6356 - val_loss: 0.8638
Epoch 5/20
10s - loss: 0.6337 - val_loss: 0.8239
Epoch 00004: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6773 - val_loss: 0.8490
Epoch 2/20
10s - loss: 0.6720 - val_loss: 0.8668
Epoch 3/20
10s - loss: 0.6711 - val_loss: 0.8785
Epoch 4/20
10s - loss: 0.6706 - val_loss: 0.8846
Epoch 5/20
10s - loss: 0.6697 - val_loss: 0.8484
Epoch 6/20
10s - loss: 0.6692 - val_loss: 0.8644
Epoch 7/20
10s - loss: 0.6686 - val_loss: 0.8519
Epoch 8/20
10s - loss: 0.6679 - val_loss: 0.9155
Epoch 9/20
10s - loss: 0.6674 - val_loss: 0.8610
Epoch 00008: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6325 - val_loss: 0.8071
Epoch 2/20
10s - loss: 0.6262 - val_loss: 0.8098
Epoch 3/20
10s - loss: 0.6236 - val_loss: 0.7933
Epoch 4/20
10s - loss: 0.6220 - val_loss: 0.8187
Epoch 5/20
10s - loss: 0.6202 - val_loss: 0.7961
Epoch 6/20
10s - loss: 0.6189 - val_loss: 0.7813
Epoch 7/20
10s - loss: 0.6178 - val_loss: 0.7754
Epoch 8/20
10s - loss: 0.6171 - val_loss: 0.7991
Epoch 9/20
10s - loss: 0.6162 - val_loss: 0.8094
Epoch 10/20
10s - loss: 0.6153 - val_loss: 0.7877
Epoch 11/20
10s - loss: 0.6147 - val_loss: 0.7921
Epoch 00010: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6676 - val_loss: 0.8327
Epoch 2/20
10s - loss: 0.6616 - val_loss: 0.8677
Epoch 3/20
10s - loss: 0.6590 - val_loss: 0.8168
Epoch 4/20
10s - loss: 0.6564 - val_loss: 0.8596
Epoch 5/20
10s - loss: 0.6549 - val_loss: 0.8648
Epoch 6/20
10s - loss: 0.6535 - val_loss: 0.7949
Epoch 7/20
10s - loss: 0.6521 - val_loss: 0.8689
Epoch 8/20
10s - loss: 0.6514 - val_loss: 0.8663
Epoch 9/20
10s - loss: 0.6501 - val_loss: 0.8629
Epoch 10/20
10s - loss: 0.6493 - val_loss: 0.8626
Epoch 00009: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6491 - val_loss: 0.7686
Epoch 2/20
10s - loss: 0.6390 - val_loss: 0.8335
Epoch 3/20
10s - loss: 0.6374 - val_loss: 0.8576
Epoch 4/20
10s - loss: 0.6353 - val_loss: 0.8361
Epoch 5/20
10s - loss: 0.6338 - val_loss: 0.8488
Epoch 00004: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6711 - val_loss: 0.8351
Epoch 2/20
10s - loss: 0.6662 - val_loss: 0.8715
Epoch 3/20
10s - loss: 0.6652 - val_loss: 0.8468
Epoch 4/20
10s - loss: 0.6640 - val_loss: 0.8611
Epoch 5/20
10s - loss: 0.6632 - val_loss: 0.8501
Epoch 00004: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6581 - val_loss: 0.8280
Epoch 2/20
10s - loss: 0.6529 - val_loss: 0.8420
Epoch 3/20
10s - loss: 0.6513 - val_loss: 0.8269
Epoch 4/20
10s - loss: 0.6503 - val_loss: 0.8242
Epoch 5/20
10s - loss: 0.6492 - val_loss: 0.8502
Epoch 6/20
10s - loss: 0.6484 - val_loss: 0.7983
Epoch 7/20
10s - loss: 0.6475 - val_loss: 0.8261
Epoch 8/20
10s - loss: 0.6469 - val_loss: 0.8481
Epoch 9/20
10s - loss: 0.6463 - val_loss: 0.8658
Epoch 10/20
10s - loss: 0.6455 - val_loss: 0.8291
Epoch 00009: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6377 - val_loss: 0.8022
Epoch 2/20
10s - loss: 0.6291 - val_loss: 0.7689
Epoch 3/20
10s - loss: 0.6255 - val_loss: 0.8089
Epoch 4/20
10s - loss: 0.6231 - val_loss: 0.7513
Epoch 5/20
10s - loss: 0.6215 - val_loss: 0.7924
Epoch 6/20
10s - loss: 0.6195 - val_loss: 0.7499
Epoch 7/20
10s - loss: 0.6187 - val_loss: 0.7602
Epoch 8/20
10s - loss: 0.6176 - val_loss: 0.7592
Epoch 9/20
10s - loss: 0.6167 - val_loss: 0.8259
Epoch 10/20
10s - loss: 0.6159 - val_loss: 0.7903
Epoch 00009: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6589 - val_loss: 0.8613
Epoch 2/20
10s - loss: 0.6516 - val_loss: 0.8451
Epoch 3/20
11s - loss: 0.6495 - val_loss: 0.8139
Epoch 4/20
10s - loss: 0.6474 - val_loss: 0.8613
Epoch 5/20
10s - loss: 0.6464 - val_loss: 0.8213
Epoch 6/20
10s - loss: 0.6448 - val_loss: 0.8251
Epoch 7/20
10s - loss: 0.6437 - val_loss: 0.8384
Epoch 00006: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6538 - val_loss: 0.8308
Epoch 2/20
10s - loss: 0.6462 - val_loss: 0.7965
Epoch 3/20
10s - loss: 0.6442 - val_loss: 0.8434
Epoch 4/20
10s - loss: 0.6424 - val_loss: 0.8408
Epoch 5/20
10s - loss: 0.6410 - val_loss: 0.8560
Epoch 6/20
10s - loss: 0.6394 - val_loss: 0.8331
Epoch 00005: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6624 - val_loss: 0.8687
Epoch 2/20
10s - loss: 0.6549 - val_loss: 0.8538
Epoch 3/20
10s - loss: 0.6531 - val_loss: 0.8340
Epoch 4/20
10s - loss: 0.6513 - val_loss: 0.8246
Epoch 5/20
10s - loss: 0.6501 - val_loss: 0.8279
Epoch 6/20
11s - loss: 0.6485 - val_loss: 0.8264
Epoch 7/20
10s - loss: 0.6471 - val_loss: 0.8447
Epoch 8/20
10s - loss: 0.6459 - val_loss: 0.8445
Epoch 00007: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6521 - val_loss: 0.8317
Epoch 2/20
10s - loss: 0.6427 - val_loss: 0.8055
Epoch 3/20
11s - loss: 0.6389 - val_loss: 0.8148
Epoch 4/20
10s - loss: 0.6367 - val_loss: 0.8103
Epoch 5/20
10s - loss: 0.6346 - val_loss: 0.7956
Epoch 6/20
11s - loss: 0.6329 - val_loss: 0.8002
Epoch 7/20
10s - loss: 0.6314 - val_loss: 0.8414
Epoch 8/20
11s - loss: 0.6307 - val_loss: 0.8550
Epoch 9/20
11s - loss: 0.6301 - val_loss: 0.8147
Epoch 00008: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6847 - val_loss: 0.8761
Epoch 2/20
11s - loss: 0.6801 - val_loss: 0.8581
Epoch 3/20
11s - loss: 0.6791 - val_loss: 0.8797
Epoch 4/20
11s - loss: 0.6787 - val_loss: 0.8784
Epoch 5/20
11s - loss: 0.6784 - val_loss: 0.8894
Epoch 6/20
11s - loss: 0.6780 - val_loss: 0.8806
Epoch 00005: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6466 - val_loss: 0.8448
Epoch 2/20
11s - loss: 0.6386 - val_loss: 0.8228
Epoch 3/20
11s - loss: 0.6365 - val_loss: 0.7734
Epoch 4/20
11s - loss: 0.6351 - val_loss: 0.8703
Epoch 5/20
10s - loss: 0.6336 - val_loss: 0.8735
Epoch 6/20
11s - loss: 0.6325 - val_loss: 0.8270
Epoch 7/20
11s - loss: 0.6315 - val_loss: 0.8201
Epoch 00006: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6676 - val_loss: 0.8650
Epoch 2/20
11s - loss: 0.6620 - val_loss: 0.8428
Epoch 3/20
11s - loss: 0.6597 - val_loss: 0.8621
Epoch 4/20
11s - loss: 0.6585 - val_loss: 0.8739
Epoch 5/20
11s - loss: 0.6572 - val_loss: 0.8551
Epoch 6/20
11s - loss: 0.6558 - val_loss: 0.8569
Epoch 00005: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6623 - val_loss: 0.8766
Epoch 2/20
11s - loss: 0.6544 - val_loss: 0.8312
Epoch 3/20
11s - loss: 0.6516 - val_loss: 0.8531
Epoch 4/20
11s - loss: 0.6493 - val_loss: 0.8599
Epoch 5/20
11s - loss: 0.6482 - val_loss: 0.8541
Epoch 6/20
11s - loss: 0.6465 - val_loss: 0.8321
Epoch 00005: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6566 - val_loss: 0.8410
Epoch 2/20
11s - loss: 0.6514 - val_loss: 0.8288
Epoch 3/20
11s - loss: 0.6499 - val_loss: 0.8593
Epoch 4/20
11s - loss: 0.6491 - val_loss: 0.8343
Epoch 5/20
11s - loss: 0.6478 - val_loss: 0.8180
Epoch 6/20
11s - loss: 0.6472 - val_loss: 0.8399
Epoch 7/20
11s - loss: 0.6462 - val_loss: 0.8356
Epoch 8/20
11s - loss: 0.6456 - val_loss: 0.8380
Epoch 9/20
11s - loss: 0.6453 - val_loss: 0.8187
Epoch 00008: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6578 - val_loss: 0.8356
Epoch 2/20
11s - loss: 0.6489 - val_loss: 0.8441
Epoch 3/20
11s - loss: 0.6452 - val_loss: 0.8136
Epoch 4/20
11s - loss: 0.6433 - val_loss: 0.8230
Epoch 5/20
11s - loss: 0.6412 - val_loss: 0.8479
Epoch 6/20
11s - loss: 0.6395 - val_loss: 0.8344
Epoch 7/20
11s - loss: 0.6382 - val_loss: 0.8203
Epoch 00006: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6487 - val_loss: 0.8233
Epoch 2/20
11s - loss: 0.6400 - val_loss: 0.7854
Epoch 3/20
11s - loss: 0.6378 - val_loss: 0.8123
Epoch 4/20
11s - loss: 0.6363 - val_loss: 0.8366
Epoch 5/20
11s - loss: 0.6351 - val_loss: 0.8273
Epoch 6/20
11s - loss: 0.6337 - val_loss: 0.7994
Epoch 00005: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6736 - val_loss: 0.8482
Epoch 2/20
11s - loss: 0.6688 - val_loss: 0.8387
Epoch 3/20
11s - loss: 0.6677 - val_loss: 0.8842
Epoch 4/20
11s - loss: 0.6671 - val_loss: 0.8396
Epoch 5/20
11s - loss: 0.6665 - val_loss: 0.8693
Epoch 6/20
11s - loss: 0.6659 - val_loss: 0.8419
Epoch 00005: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6658 - val_loss: 0.8899
Epoch 2/20
11s - loss: 0.6614 - val_loss: 0.8720
Epoch 3/20
11s - loss: 0.6602 - val_loss: 0.8392
Epoch 4/20
11s - loss: 0.6597 - val_loss: 0.8788
Epoch 5/20
11s - loss: 0.6591 - val_loss: 0.8465
Epoch 6/20
11s - loss: 0.6587 - val_loss: 0.8503
Epoch 7/20
11s - loss: 0.6583 - val_loss: 0.8593
Epoch 00006: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6803 - val_loss: 0.8655
Epoch 2/20
11s - loss: 0.6761 - val_loss: 0.8863
Epoch 3/20
11s - loss: 0.6752 - val_loss: 0.8717
Epoch 4/20
11s - loss: 0.6745 - val_loss: 0.8694
Epoch 5/20
11s - loss: 0.6741 - val_loss: 0.8548
Epoch 6/20
11s - loss: 0.6737 - val_loss: 0.8362
Epoch 7/20
11s - loss: 0.6731 - val_loss: 0.8512
Epoch 8/20
11s - loss: 0.6729 - val_loss: 0.8732
Epoch 9/20
11s - loss: 0.6722 - val_loss: 0.8590
Epoch 10/20
11s - loss: 0.6715 - val_loss: 0.8768
Epoch 00009: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6599 - val_loss: 0.8260
Epoch 2/20
11s - loss: 0.6547 - val_loss: 0.8327
Epoch 3/20
11s - loss: 0.6536 - val_loss: 0.8320
Epoch 4/20
11s - loss: 0.6527 - val_loss: 0.8410
Epoch 5/20
11s - loss: 0.6516 - val_loss: 0.8436
Epoch 00004: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6746 - val_loss: 0.8903
Epoch 2/20
11s - loss: 0.6695 - val_loss: 0.8526
Epoch 3/20
11s - loss: 0.6676 - val_loss: 0.8706
Epoch 4/20
11s - loss: 0.6670 - val_loss: 0.8828
Epoch 5/20
11s - loss: 0.6664 - val_loss: 0.8601
Epoch 6/20
11s - loss: 0.6657 - val_loss: 0.8846
Epoch 00005: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6664 - val_loss: 0.8454
Epoch 2/20
11s - loss: 0.6607 - val_loss: 0.8384
Epoch 3/20
11s - loss: 0.6591 - val_loss: 0.8299
Epoch 4/20
11s - loss: 0.6578 - val_loss: 0.8675
Epoch 5/20
11s - loss: 0.6567 - val_loss: 0.8258
Epoch 6/20
11s - loss: 0.6555 - val_loss: 0.8452
Epoch 7/20
11s - loss: 0.6546 - val_loss: 0.8419
Epoch 8/20
11s - loss: 0.6539 - val_loss: 0.8646
Epoch 9/20
11s - loss: 0.6534 - val_loss: 0.8865
Epoch 00008: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6501 - val_loss: 0.8215
Epoch 2/20
11s - loss: 0.6380 - val_loss: 0.8409
Epoch 3/20
11s - loss: 0.6357 - val_loss: 0.8183
Epoch 4/20
11s - loss: 0.6342 - val_loss: 0.7871
Epoch 5/20
11s - loss: 0.6322 - val_loss: 0.7963
Epoch 6/20
11s - loss: 0.6308 - val_loss: 0.8198
Epoch 7/20
11s - loss: 0.6296 - val_loss: 0.8305
Epoch 8/20
11s - loss: 0.6285 - val_loss: 0.7784
Epoch 9/20
11s - loss: 0.6274 - val_loss: 0.8036
Epoch 10/20
11s - loss: 0.6264 - val_loss: 0.8413
Epoch 11/20
11s - loss: 0.6256 - val_loss: 0.8268
Epoch 12/20
11s - loss: 0.6249 - val_loss: 0.8724
Epoch 00011: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6478 - val_loss: 0.8047
Epoch 2/20
11s - loss: 0.6362 - val_loss: 0.8439
Epoch 3/20
11s - loss: 0.6337 - val_loss: 0.8384
Epoch 4/20
11s - loss: 0.6313 - val_loss: 0.8094
Epoch 5/20
11s - loss: 0.6296 - val_loss: 0.7686
Epoch 6/20
11s - loss: 0.6284 - val_loss: 0.8363
Epoch 7/20
11s - loss: 0.6267 - val_loss: 0.7998
Epoch 8/20
11s - loss: 0.6254 - val_loss: 0.8192
Epoch 9/20
11s - loss: 0.6247 - val_loss: 0.7699
Epoch 00008: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6798 - val_loss: 0.8430
Epoch 2/20
11s - loss: 0.6749 - val_loss: 0.8544
Epoch 3/20
11s - loss: 0.6739 - val_loss: 0.8499
Epoch 4/20
11s - loss: 0.6734 - val_loss: 0.8839
Epoch 5/20
11s - loss: 0.6729 - val_loss: 0.8928
Epoch 00004: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6606 - val_loss: 0.8689
Epoch 2/20
11s - loss: 0.6546 - val_loss: 0.8435
Epoch 3/20
11s - loss: 0.6529 - val_loss: 0.8463
Epoch 4/20
11s - loss: 0.6507 - val_loss: 0.8770
Epoch 5/20
11s - loss: 0.6492 - val_loss: 0.8802
Epoch 6/20
11s - loss: 0.6478 - val_loss: 0.8028
Epoch 7/20
11s - loss: 0.6467 - val_loss: 0.8365
Epoch 8/20
11s - loss: 0.6455 - val_loss: 0.8523
Epoch 9/20
11s - loss: 0.6442 - val_loss: 0.8089
Epoch 10/20
11s - loss: 0.6435 - val_loss: 0.8621
Epoch 00009: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6630 - val_loss: 0.8115
Epoch 2/20
11s - loss: 0.6559 - val_loss: 0.8653
Epoch 3/20
11s - loss: 0.6532 - val_loss: 0.8556
Epoch 4/20
11s - loss: 0.6508 - val_loss: 0.8492
Epoch 5/20
11s - loss: 0.6484 - val_loss: 0.8666
Epoch 00004: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6567 - val_loss: 0.8644
Epoch 2/20
11s - loss: 0.6519 - val_loss: 0.8774
Epoch 3/20
11s - loss: 0.6504 - val_loss: 0.8482
Epoch 4/20
11s - loss: 0.6488 - val_loss: 0.8694
Epoch 5/20
11s - loss: 0.6479 - val_loss: 0.8366
Epoch 6/20
11s - loss: 0.6471 - val_loss: 0.8323
Epoch 7/20
11s - loss: 0.6458 - val_loss: 0.8310
Epoch 8/20
11s - loss: 0.6451 - val_loss: 0.8682
Epoch 9/20
11s - loss: 0.6443 - val_loss: 0.8143
Epoch 10/20
11s - loss: 0.6435 - val_loss: 0.8897
Epoch 11/20
11s - loss: 0.6426 - val_loss: 0.8547
Epoch 12/20
11s - loss: 0.6423 - val_loss: 0.8452
Epoch 13/20
11s - loss: 0.6414 - val_loss: 0.8339
Epoch 00012: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6579 - val_loss: 0.8749
Epoch 2/20
11s - loss: 0.6535 - val_loss: 0.8427
Epoch 3/20
11s - loss: 0.6520 - val_loss: 0.8184
Epoch 4/20
11s - loss: 0.6513 - val_loss: 0.8457
Epoch 5/20
11s - loss: 0.6506 - val_loss: 0.8392
Epoch 6/20
11s - loss: 0.6499 - val_loss: 0.8646
Epoch 7/20
11s - loss: 0.6492 - val_loss: 0.8621
Epoch 00006: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6615 - val_loss: 0.8290
Epoch 2/20
11s - loss: 0.6546 - val_loss: 0.8336
Epoch 3/20
11s - loss: 0.6523 - val_loss: 0.8115
Epoch 4/20
11s - loss: 0.6509 - val_loss: 0.8235
Epoch 5/20
11s - loss: 0.6494 - val_loss: 0.8399
Epoch 6/20
11s - loss: 0.6477 - val_loss: 0.8437
Epoch 7/20
11s - loss: 0.6464 - val_loss: 0.8543
Epoch 00006: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6583 - val_loss: 0.8369
Epoch 2/20
11s - loss: 0.6470 - val_loss: 0.8147
Epoch 3/20
11s - loss: 0.6441 - val_loss: 0.8233
Epoch 4/20
11s - loss: 0.6420 - val_loss: 0.8627
Epoch 5/20
11s - loss: 0.6399 - val_loss: 0.8399
Epoch 6/20
11s - loss: 0.6385 - val_loss: 0.7794
Epoch 7/20
11s - loss: 0.6371 - val_loss: 0.8241
Epoch 8/20
11s - loss: 0.6363 - val_loss: 0.8642
Epoch 9/20
11s - loss: 0.6353 - val_loss: 0.7885
Epoch 10/20
11s - loss: 0.6342 - val_loss: 0.7888
Epoch 00009: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6602 - val_loss: 0.8520
Epoch 2/20
11s - loss: 0.6541 - val_loss: 0.8811
Epoch 3/20
11s - loss: 0.6522 - val_loss: 0.8607
Epoch 4/20
11s - loss: 0.6508 - val_loss: 0.8195
Epoch 5/20
11s - loss: 0.6495 - val_loss: 0.8777
Epoch 6/20
11s - loss: 0.6483 - val_loss: 0.8735
Epoch 7/20
11s - loss: 0.6472 - val_loss: 0.8104
Epoch 8/20
11s - loss: 0.6462 - val_loss: 0.8851
Epoch 9/20
11s - loss: 0.6456 - val_loss: 0.8005
Epoch 10/20
11s - loss: 0.6449 - val_loss: 0.8164
Epoch 11/20
11s - loss: 0.6440 - val_loss: 0.8248
Epoch 12/20
11s - loss: 0.6433 - val_loss: 0.8340
Epoch 13/20
11s - loss: 0.6427 - val_loss: 0.8198
Epoch 00012: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6792 - val_loss: 0.8637
Epoch 2/20
11s - loss: 0.6750 - val_loss: 0.8607
Epoch 3/20
11s - loss: 0.6736 - val_loss: 0.8390
Epoch 4/20
11s - loss: 0.6732 - val_loss: 0.8665
Epoch 5/20
11s - loss: 0.6728 - val_loss: 0.8649
Epoch 6/20
11s - loss: 0.6724 - val_loss: 0.8836
Epoch 7/20
11s - loss: 0.6721 - val_loss: 0.8973
Epoch 00006: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6772 - val_loss: 0.8548
Epoch 2/20
11s - loss: 0.6723 - val_loss: 0.8440
Epoch 3/20
11s - loss: 0.6712 - val_loss: 0.8749
Epoch 4/20
11s - loss: 0.6707 - val_loss: 0.8410
Epoch 5/20
11s - loss: 0.6704 - val_loss: 0.8679
Epoch 6/20
11s - loss: 0.6699 - val_loss: 0.8498
Epoch 7/20
11s - loss: 0.6696 - val_loss: 0.8688
Epoch 8/20
11s - loss: 0.6694 - val_loss: 0.8449
Epoch 00007: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6810 - val_loss: 0.8538
Epoch 2/20
11s - loss: 0.6760 - val_loss: 0.8553
Epoch 3/20
11s - loss: 0.6747 - val_loss: 0.8810
Epoch 4/20
11s - loss: 0.6743 - val_loss: 0.8453
Epoch 5/20
11s - loss: 0.6740 - val_loss: 0.8667
Epoch 6/20
11s - loss: 0.6735 - val_loss: 0.8637
Epoch 7/20
11s - loss: 0.6732 - val_loss: 0.8669
Epoch 8/20
11s - loss: 0.6728 - val_loss: 0.8814
Epoch 00007: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6670 - val_loss: 0.8399
Epoch 2/20
11s - loss: 0.6626 - val_loss: 0.8766
Epoch 3/20
11s - loss: 0.6611 - val_loss: 0.8664
Epoch 4/20
11s - loss: 0.6601 - val_loss: 0.8433
Epoch 5/20
11s - loss: 0.6592 - val_loss: 0.8486
Epoch 00004: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6508 - val_loss: 0.8531
Epoch 2/20
11s - loss: 0.6430 - val_loss: 0.7970
Epoch 3/20
11s - loss: 0.6414 - val_loss: 0.8053
Epoch 4/20
11s - loss: 0.6401 - val_loss: 0.7967
Epoch 5/20
11s - loss: 0.6384 - val_loss: 0.8463
Epoch 6/20
11s - loss: 0.6373 - val_loss: 0.8121
Epoch 7/20
11s - loss: 0.6363 - val_loss: 0.8495
Epoch 8/20
11s - loss: 0.6356 - val_loss: 0.8144
Epoch 00007: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6547 - val_loss: 0.8531
Epoch 2/20
11s - loss: 0.6474 - val_loss: 0.8150
Epoch 3/20
11s - loss: 0.6456 - val_loss: 0.8476
Epoch 4/20
11s - loss: 0.6441 - val_loss: 0.8352
Epoch 5/20
11s - loss: 0.6433 - val_loss: 0.8731
Epoch 6/20
11s - loss: 0.6426 - val_loss: 0.8456
Epoch 00005: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6373 - val_loss: 0.7862
Epoch 2/20
11s - loss: 0.6298 - val_loss: 0.7853
Epoch 3/20
11s - loss: 0.6270 - val_loss: 0.7915
Epoch 4/20
11s - loss: 0.6251 - val_loss: 0.7896
Epoch 5/20
11s - loss: 0.6236 - val_loss: 0.7983
Epoch 6/20
11s - loss: 0.6221 - val_loss: 0.7963
Epoch 00005: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6601 - val_loss: 0.8466
Epoch 2/20
11s - loss: 0.6523 - val_loss: 0.8643
Epoch 3/20
11s - loss: 0.6491 - val_loss: 0.8402
Epoch 4/20
11s - loss: 0.6470 - val_loss: 0.8644
Epoch 5/20
11s - loss: 0.6458 - val_loss: 0.8319
Epoch 6/20
11s - loss: 0.6445 - val_loss: 0.8340
Epoch 7/20
11s - loss: 0.6434 - val_loss: 0.8458
Epoch 8/20
11s - loss: 0.6423 - val_loss: 0.8437
Epoch 9/20
11s - loss: 0.6409 - val_loss: 0.8387
Epoch 00008: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6536 - val_loss: 0.7908
Epoch 2/20
11s - loss: 0.6429 - val_loss: 0.8220
Epoch 3/20
11s - loss: 0.6402 - val_loss: 0.8737
Epoch 4/20
11s - loss: 0.6382 - val_loss: 0.7793
Epoch 5/20
11s - loss: 0.6362 - val_loss: 0.7842
Epoch 6/20
11s - loss: 0.6348 - val_loss: 0.8156
Epoch 7/20
11s - loss: 0.6337 - val_loss: 0.8140
Epoch 8/20
11s - loss: 0.6323 - val_loss: 0.8492
Epoch 00007: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6834 - val_loss: 0.8932
Epoch 2/20
11s - loss: 0.6793 - val_loss: 0.8574
Epoch 3/20
11s - loss: 0.6781 - val_loss: 0.8867
Epoch 4/20
11s - loss: 0.6777 - val_loss: 0.8670
Epoch 5/20
11s - loss: 0.6774 - val_loss: 0.8674
Epoch 6/20
11s - loss: 0.6771 - val_loss: 0.8764
Epoch 00005: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6695 - val_loss: 0.8643
Epoch 2/20
11s - loss: 0.6646 - val_loss: 0.8755
Epoch 3/20
11s - loss: 0.6639 - val_loss: 0.8625
Epoch 4/20
11s - loss: 0.6632 - val_loss: 0.8486
Epoch 5/20
11s - loss: 0.6629 - val_loss: 0.8379
Epoch 6/20
11s - loss: 0.6623 - val_loss: 0.8323
Epoch 7/20
11s - loss: 0.6618 - val_loss: 0.8748
Epoch 8/20
11s - loss: 0.6612 - val_loss: 0.8612
Epoch 9/20
11s - loss: 0.6609 - val_loss: 0.8610
Epoch 10/20
11s - loss: 0.6602 - val_loss: 0.8441
Epoch 00009: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6453 - val_loss: 0.7702
Epoch 2/20
11s - loss: 0.6306 - val_loss: 0.8393
Epoch 3/20
11s - loss: 0.6282 - val_loss: 0.8013
Epoch 4/20
11s - loss: 0.6263 - val_loss: 0.8408
Epoch 5/20
11s - loss: 0.6243 - val_loss: 0.8435
Epoch 00004: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6632 - val_loss: 0.8391
Epoch 2/20
11s - loss: 0.6575 - val_loss: 0.8641
Epoch 3/20
11s - loss: 0.6561 - val_loss: 0.8409
Epoch 4/20
11s - loss: 0.6545 - val_loss: 0.8176
Epoch 5/20
11s - loss: 0.6535 - val_loss: 0.8774
Epoch 6/20
11s - loss: 0.6527 - val_loss: 0.8492
Epoch 7/20
11s - loss: 0.6521 - val_loss: 0.8042
Epoch 8/20
11s - loss: 0.6514 - val_loss: 0.8558
Epoch 9/20
11s - loss: 0.6510 - val_loss: 0.8624
Epoch 10/20
11s - loss: 0.6502 - val_loss: 0.8308
Epoch 11/20
11s - loss: 0.6499 - val_loss: 0.8381
Epoch 00010: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6775 - val_loss: 0.8942
Epoch 2/20
11s - loss: 0.6727 - val_loss: 0.8898
Epoch 3/20
11s - loss: 0.6718 - val_loss: 0.8651
Epoch 4/20
11s - loss: 0.6715 - val_loss: 0.8697
Epoch 5/20
11s - loss: 0.6706 - val_loss: 0.8765
Epoch 6/20
11s - loss: 0.6704 - val_loss: 0.8590
Epoch 7/20
11s - loss: 0.6695 - val_loss: 0.9067
Epoch 8/20
11s - loss: 0.6691 - val_loss: 0.8512
Epoch 9/20
11s - loss: 0.6684 - val_loss: 0.8499
Epoch 10/20
11s - loss: 0.6679 - val_loss: 0.8767
Epoch 11/20
11s - loss: 0.6671 - val_loss: 0.8560
Epoch 12/20
11s - loss: 0.6667 - val_loss: 0.8658
Epoch 13/20
11s - loss: 0.6661 - val_loss: 0.8868
Epoch 00012: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6607 - val_loss: 0.8286
Epoch 2/20
11s - loss: 0.6536 - val_loss: 0.8216
Epoch 3/20
11s - loss: 0.6519 - val_loss: 0.8651
Epoch 4/20
11s - loss: 0.6502 - val_loss: 0.8294
Epoch 5/20
11s - loss: 0.6488 - val_loss: 0.8297
Epoch 6/20
11s - loss: 0.6480 - val_loss: 0.8667
Epoch 00005: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6613 - val_loss: 0.8346
Epoch 2/20
11s - loss: 0.6505 - val_loss: 0.8579
Epoch 3/20
11s - loss: 0.6473 - val_loss: 0.8409
Epoch 4/20
11s - loss: 0.6453 - val_loss: 0.8309
Epoch 5/20
11s - loss: 0.6437 - val_loss: 0.8225
Epoch 6/20
11s - loss: 0.6424 - val_loss: 0.8387
Epoch 7/20
11s - loss: 0.6415 - val_loss: 0.8573
Epoch 8/20
11s - loss: 0.6405 - val_loss: 0.8535
Epoch 9/20
11s - loss: 0.6399 - val_loss: 0.8142
Epoch 10/20
11s - loss: 0.6390 - val_loss: 0.8505
Epoch 11/20
11s - loss: 0.6379 - val_loss: 0.8225
Epoch 12/20
11s - loss: 0.6373 - val_loss: 0.8533
Epoch 13/20
11s - loss: 0.6365 - val_loss: 0.9018
Epoch 00012: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6682 - val_loss: 0.8527
Epoch 2/20
11s - loss: 0.6627 - val_loss: 0.8732
Epoch 3/20
11s - loss: 0.6609 - val_loss: 0.8577
Epoch 4/20
11s - loss: 0.6603 - val_loss: 0.8350
Epoch 5/20
11s - loss: 0.6590 - val_loss: 0.8749
Epoch 6/20
11s - loss: 0.6581 - val_loss: 0.8868
Epoch 7/20
11s - loss: 0.6571 - val_loss: 0.8799
Epoch 8/20
11s - loss: 0.6559 - val_loss: 0.8637
Epoch 00007: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6716 - val_loss: 0.8513
Epoch 2/20
11s - loss: 0.6659 - val_loss: 0.8694
Epoch 3/20
11s - loss: 0.6639 - val_loss: 0.8723
Epoch 4/20
11s - loss: 0.6631 - val_loss: 0.8686
Epoch 5/20
11s - loss: 0.6625 - val_loss: 0.8313
Epoch 6/20
11s - loss: 0.6615 - val_loss: 0.8567
Epoch 7/20
11s - loss: 0.6606 - val_loss: 0.8817
Epoch 8/20
11s - loss: 0.6602 - val_loss: 0.8534
Epoch 9/20
11s - loss: 0.6592 - val_loss: 0.8363
Epoch 00008: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6781 - val_loss: 0.8835
Epoch 2/20
11s - loss: 0.6736 - val_loss: 0.8679
Epoch 3/20
11s - loss: 0.6725 - val_loss: 0.8687
Epoch 4/20
11s - loss: 0.6719 - val_loss: 0.8646
Epoch 5/20
11s - loss: 0.6717 - val_loss: 0.8703
Epoch 6/20
11s - loss: 0.6713 - val_loss: 0.8843
Epoch 7/20
11s - loss: 0.6713 - val_loss: 0.8527
Epoch 8/20
11s - loss: 0.6706 - val_loss: 0.8737
Epoch 9/20
11s - loss: 0.6704 - val_loss: 0.8841
Epoch 10/20
11s - loss: 0.6699 - val_loss: 0.8522
Epoch 11/20
11s - loss: 0.6695 - val_loss: 0.8523
Epoch 12/20
11s - loss: 0.6691 - val_loss: 0.8724
Epoch 13/20
11s - loss: 0.6687 - val_loss: 0.8691
Epoch 14/20
11s - loss: 0.6682 - val_loss: 0.8678
Epoch 00013: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6773 - val_loss: 0.8760
Epoch 2/20
11s - loss: 0.6726 - val_loss: 0.8738
Epoch 3/20
11s - loss: 0.6711 - val_loss: 0.8848
Epoch 4/20
11s - loss: 0.6707 - val_loss: 0.8848
Epoch 5/20
11s - loss: 0.6699 - val_loss: 0.8611
Epoch 6/20
11s - loss: 0.6692 - val_loss: 0.8894
Epoch 7/20
11s - loss: 0.6689 - val_loss: 0.8764
Epoch 8/20
11s - loss: 0.6682 - val_loss: 0.8610
Epoch 9/20
11s - loss: 0.6674 - val_loss: 0.8548
Epoch 10/20
11s - loss: 0.6668 - val_loss: 0.8351
Epoch 11/20
11s - loss: 0.6662 - val_loss: 0.8598
Epoch 12/20
11s - loss: 0.6655 - val_loss: 0.8581
Epoch 13/20
11s - loss: 0.6652 - val_loss: 0.8678
Epoch 14/20
11s - loss: 0.6647 - val_loss: 0.8613
Epoch 00013: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6208 - val_loss: 0.7703
Epoch 2/20
11s - loss: 0.6135 - val_loss: 0.7584
Epoch 3/20
11s - loss: 0.6104 - val_loss: 0.7694
Epoch 4/20
11s - loss: 0.6079 - val_loss: 0.7859
Epoch 5/20
11s - loss: 0.6062 - val_loss: 0.7677
Epoch 6/20
11s - loss: 0.6048 - val_loss: 0.7866
Epoch 00005: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6578 - val_loss: 0.8761
Epoch 2/20
11s - loss: 0.6518 - val_loss: 0.8601
Epoch 3/20
11s - loss: 0.6501 - val_loss: 0.8410
Epoch 4/20
11s - loss: 0.6487 - val_loss: 0.7960
Epoch 5/20
11s - loss: 0.6475 - val_loss: 0.8061
Epoch 6/20
11s - loss: 0.6466 - val_loss: 0.8280
Epoch 7/20
11s - loss: 0.6456 - val_loss: 0.8419
Epoch 8/20
11s - loss: 0.6450 - val_loss: 0.8581
Epoch 00007: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6745 - val_loss: 0.8445
Epoch 2/20
11s - loss: 0.6693 - val_loss: 0.9019
Epoch 3/20
11s - loss: 0.6676 - val_loss: 0.8967
Epoch 4/20
11s - loss: 0.6667 - val_loss: 0.8467
Epoch 5/20
11s - loss: 0.6657 - val_loss: 0.8585
Epoch 00004: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6558 - val_loss: 0.8535
Epoch 2/20
11s - loss: 0.6499 - val_loss: 0.8662
Epoch 3/20
11s - loss: 0.6482 - val_loss: 0.8280
Epoch 4/20
11s - loss: 0.6468 - val_loss: 0.8539
Epoch 5/20
11s - loss: 0.6457 - val_loss: 0.8375
Epoch 6/20
11s - loss: 0.6445 - val_loss: 0.8587
Epoch 7/20
11s - loss: 0.6439 - val_loss: 0.8588
Epoch 00006: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6561 - val_loss: 0.8109
Epoch 2/20
11s - loss: 0.6480 - val_loss: 0.8171
Epoch 3/20
11s - loss: 0.6449 - val_loss: 0.8241
Epoch 4/20
11s - loss: 0.6427 - val_loss: 0.8237
Epoch 5/20
11s - loss: 0.6410 - val_loss: 0.8841
Epoch 00004: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6542 - val_loss: 0.8615
Epoch 2/20
11s - loss: 0.6474 - val_loss: 0.8595
Epoch 3/20
11s - loss: 0.6451 - val_loss: 0.8553
Epoch 4/20
11s - loss: 0.6441 - val_loss: 0.8424
Epoch 5/20
11s - loss: 0.6427 - val_loss: 0.8692
Epoch 6/20
11s - loss: 0.6420 - val_loss: 0.8120
Epoch 7/20
11s - loss: 0.6409 - val_loss: 0.8333
Epoch 8/20
11s - loss: 0.6404 - val_loss: 0.8567
Epoch 9/20
11s - loss: 0.6392 - val_loss: 0.8349
Epoch 10/20
11s - loss: 0.6385 - val_loss: 0.7867
Epoch 11/20
11s - loss: 0.6376 - val_loss: 0.8001
Epoch 12/20
11s - loss: 0.6368 - val_loss: 0.8790
Epoch 13/20
11s - loss: 0.6363 - val_loss: 0.8358
Epoch 14/20
11s - loss: 0.6355 - val_loss: 0.8252
Epoch 00013: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6534 - val_loss: 0.8075
Epoch 2/20
11s - loss: 0.6399 - val_loss: 0.8079
Epoch 3/20
11s - loss: 0.6365 - val_loss: 0.8401
Epoch 4/20
11s - loss: 0.6344 - val_loss: 0.8278
Epoch 5/20
11s - loss: 0.6332 - val_loss: 0.7944
Epoch 6/20
11s - loss: 0.6314 - val_loss: 0.8110
Epoch 7/20
11s - loss: 0.6302 - val_loss: 0.7820
Epoch 8/20
11s - loss: 0.6292 - val_loss: 0.8681
Epoch 9/20
11s - loss: 0.6281 - val_loss: 0.8195
Epoch 10/20
11s - loss: 0.6271 - val_loss: 0.8469
Epoch 11/20
11s - loss: 0.6265 - val_loss: 0.8120
Epoch 00010: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6604 - val_loss: 0.8855
Epoch 2/20
11s - loss: 0.6548 - val_loss: 0.8602
Epoch 3/20
11s - loss: 0.6527 - val_loss: 0.8571
Epoch 4/20
11s - loss: 0.6518 - val_loss: 0.8568
Epoch 5/20
11s - loss: 0.6506 - val_loss: 0.8457
Epoch 6/20
11s - loss: 0.6496 - val_loss: 0.8547
Epoch 7/20
11s - loss: 0.6485 - val_loss: 0.8743
Epoch 8/20
11s - loss: 0.6480 - val_loss: 0.8742
Epoch 9/20
11s - loss: 0.6469 - val_loss: 0.8417
Epoch 10/20
11s - loss: 0.6461 - val_loss: 0.8335
Epoch 11/20
11s - loss: 0.6455 - val_loss: 0.8709
Epoch 12/20
11s - loss: 0.6449 - val_loss: 0.8305
Epoch 13/20
11s - loss: 0.6440 - val_loss: 0.8269
Epoch 14/20
11s - loss: 0.6431 - val_loss: 0.8359
Epoch 15/20
11s - loss: 0.6430 - val_loss: 0.8758
Epoch 16/20
11s - loss: 0.6420 - val_loss: 0.8692
Epoch 17/20
11s - loss: 0.6415 - val_loss: 0.8204
Epoch 18/20
11s - loss: 0.6408 - val_loss: 0.8475
Epoch 19/20
11s - loss: 0.6406 - val_loss: 0.8749
Epoch 20/20
11s - loss: 0.6400 - val_loss: 0.8312
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6509 - val_loss: 0.8292
Epoch 2/20
11s - loss: 0.6441 - val_loss: 0.8520
Epoch 3/20
11s - loss: 0.6417 - val_loss: 0.8182
Epoch 4/20
11s - loss: 0.6406 - val_loss: 0.7814
Epoch 5/20
11s - loss: 0.6393 - val_loss: 0.8105
Epoch 6/20
11s - loss: 0.6381 - val_loss: 0.8632
Epoch 7/20
11s - loss: 0.6368 - val_loss: 0.8451
Epoch 8/20
11s - loss: 0.6357 - val_loss: 0.8393
Epoch 00007: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6699 - val_loss: 0.8296
Epoch 2/20
11s - loss: 0.6650 - val_loss: 0.8711
Epoch 3/20
11s - loss: 0.6635 - val_loss: 0.8527
Epoch 4/20
11s - loss: 0.6631 - val_loss: 0.8580
Epoch 5/20
11s - loss: 0.6625 - val_loss: 0.8510
Epoch 00004: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6753 - val_loss: 0.8654
Epoch 2/20
11s - loss: 0.6693 - val_loss: 0.8892
Epoch 3/20
11s - loss: 0.6675 - val_loss: 0.8955
Epoch 4/20
11s - loss: 0.6667 - val_loss: 0.8668
Epoch 5/20
11s - loss: 0.6658 - val_loss: 0.8812
Epoch 00004: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6574 - val_loss: 0.7792
Epoch 2/20
11s - loss: 0.6450 - val_loss: 0.8279
Epoch 3/20
11s - loss: 0.6412 - val_loss: 0.7860
Epoch 4/20
11s - loss: 0.6381 - val_loss: 0.8284
Epoch 5/20
11s - loss: 0.6361 - val_loss: 0.8018
Epoch 00004: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6762 - val_loss: 0.8655
Epoch 2/20
11s - loss: 0.6716 - val_loss: 0.8810
Epoch 3/20
11s - loss: 0.6701 - val_loss: 0.8717
Epoch 4/20
11s - loss: 0.6699 - val_loss: 0.8428
Epoch 5/20
11s - loss: 0.6690 - val_loss: 0.8671
Epoch 6/20
11s - loss: 0.6685 - val_loss: 0.8762
Epoch 7/20
11s - loss: 0.6681 - val_loss: 0.8623
Epoch 8/20
11s - loss: 0.6677 - val_loss: 0.8325
Epoch 9/20
11s - loss: 0.6675 - val_loss: 0.8500
Epoch 10/20
11s - loss: 0.6668 - val_loss: 0.8447
Epoch 11/20
11s - loss: 0.6662 - val_loss: 0.8474
Epoch 12/20
11s - loss: 0.6661 - val_loss: 0.8516
Epoch 00011: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6595 - val_loss: 0.8788
Epoch 2/20
11s - loss: 0.6509 - val_loss: 0.8140
Epoch 3/20
11s - loss: 0.6482 - val_loss: 0.8506
Epoch 4/20
11s - loss: 0.6463 - val_loss: 0.8606
Epoch 5/20
11s - loss: 0.6452 - val_loss: 0.8784
Epoch 6/20
11s - loss: 0.6440 - val_loss: 0.8433
Epoch 00005: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6766 - val_loss: 0.8938
Epoch 2/20
11s - loss: 0.6721 - val_loss: 0.8595
Epoch 3/20
11s - loss: 0.6709 - val_loss: 0.8640
Epoch 4/20
11s - loss: 0.6698 - val_loss: 0.8555
Epoch 5/20
11s - loss: 0.6691 - val_loss: 0.8613
Epoch 6/20
11s - loss: 0.6683 - val_loss: 0.9005
Epoch 7/20
11s - loss: 0.6678 - val_loss: 0.8827
Epoch 8/20
11s - loss: 0.6676 - val_loss: 0.8525
Epoch 9/20
11s - loss: 0.6670 - val_loss: 0.8679
Epoch 10/20
11s - loss: 0.6662 - val_loss: 0.8624
Epoch 11/20
11s - loss: 0.6660 - val_loss: 0.8463
Epoch 12/20
11s - loss: 0.6656 - val_loss: 0.8641
Epoch 13/20
11s - loss: 0.6649 - val_loss: 0.8390
Epoch 14/20
11s - loss: 0.6648 - val_loss: 0.8813
Epoch 15/20
11s - loss: 0.6642 - val_loss: 0.8372
Epoch 16/20
11s - loss: 0.6638 - val_loss: 0.8614
Epoch 17/20
11s - loss: 0.6635 - val_loss: 0.8398
Epoch 18/20
11s - loss: 0.6631 - val_loss: 0.8559
Epoch 19/20
11s - loss: 0.6626 - val_loss: 0.8716
Epoch 00018: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6490 - val_loss: 0.8235
Epoch 2/20
11s - loss: 0.6418 - val_loss: 0.7685
Epoch 3/20
11s - loss: 0.6390 - val_loss: 0.8257
Epoch 4/20
11s - loss: 0.6371 - val_loss: 0.8319
Epoch 5/20
11s - loss: 0.6356 - val_loss: 0.8459
Epoch 6/20
11s - loss: 0.6339 - val_loss: 0.8214
Epoch 00005: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6564 - val_loss: 0.8640
Epoch 2/20
11s - loss: 0.6512 - val_loss: 0.8214
Epoch 3/20
11s - loss: 0.6494 - val_loss: 0.8376
Epoch 4/20
11s - loss: 0.6480 - val_loss: 0.8336
Epoch 5/20
11s - loss: 0.6468 - val_loss: 0.8416
Epoch 6/20
11s - loss: 0.6457 - val_loss: 0.8719
Epoch 00005: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6596 - val_loss: 0.8268
Epoch 2/20
11s - loss: 0.6534 - val_loss: 0.8519
Epoch 3/20
11s - loss: 0.6509 - val_loss: 0.8290
Epoch 4/20
11s - loss: 0.6497 - val_loss: 0.8520
Epoch 5/20
11s - loss: 0.6486 - val_loss: 0.8155
Epoch 6/20
11s - loss: 0.6476 - val_loss: 0.8262
Epoch 7/20
11s - loss: 0.6469 - val_loss: 0.8410
Epoch 8/20
11s - loss: 0.6460 - val_loss: 0.8463
Epoch 9/20
11s - loss: 0.6453 - val_loss: 0.8478
Epoch 00008: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.34217722e+08,  -4.82872531e-53]), 'nit': 2, 'funcalls': 46}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 8388613.99976845,       -0.        ]), 'nit': 5, 'funcalls': 104}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 16777221.99976897,        -0.        ]), 'nit': 4, 'funcalls': 71}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 12533026.25024601,   -115894.49410649]), 'nit': 3, 'funcalls': 84}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 8388613.99976227,       -0.        ]), 'nit': 4, 'funcalls': 64}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 8388613.99976859,       -0.        ]), 'nit': 3, 'funcalls': 71}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -4.21209302e+07,  -1.76388171e+02]), 'nit': 9, 'funcalls': 161}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 20971525.9994302,        -0.       ]), 'nit': 15, 'funcalls': 105}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-4194298.00028839,       -0.        ]), 'nit': 4, 'funcalls': 77}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 17060164.23898316,   -972585.93398275]), 'nit': 1, 'funcalls': 34}
  " state: %s" % convergence_dict)
Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   2

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-13 00:55:47.329374: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 00:55:47.331140: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 00:55:47.331149: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 00:55:47.331153: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 00:55:47.331157: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 00:55:47.632742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-13 00:55:47.632780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-13 00:55:47.632786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-13 00:55:47.632795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
13s - loss: 0.6709 - val_loss: 0.8747
Epoch 2/20
11s - loss: 0.6640 - val_loss: 0.8368
Epoch 3/20
11s - loss: 0.6629 - val_loss: 0.8722
Epoch 4/20
11s - loss: 0.6620 - val_loss: 0.8586
Epoch 5/20
11s - loss: 0.6612 - val_loss: 0.8558
Epoch 6/20
11s - loss: 0.6603 - val_loss: 0.8351
Epoch 7/20
11s - loss: 0.6591 - val_loss: 0.8937
Epoch 8/20
11s - loss: 0.6579 - val_loss: 0.8636
Epoch 9/20
11s - loss: 0.6567 - val_loss: 0.8968
Epoch 10/20
11s - loss: 0.6554 - val_loss: 0.8431
Epoch 00009: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6391 - val_loss: 0.7567
Epoch 2/20
11s - loss: 0.6233 - val_loss: 0.7610
Epoch 3/20
11s - loss: 0.6184 - val_loss: 0.8039
Epoch 4/20
11s - loss: 0.6160 - val_loss: 0.8319
Epoch 5/20
11s - loss: 0.6139 - val_loss: 0.8396
Epoch 00004: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6292 - val_loss: 0.7876
Epoch 2/20
11s - loss: 0.6125 - val_loss: 0.7975
Epoch 3/20
11s - loss: 0.6075 - val_loss: 0.7440
Epoch 4/20
11s - loss: 0.6047 - val_loss: 0.8583
Epoch 5/20
11s - loss: 0.6020 - val_loss: 0.8108
Epoch 6/20
11s - loss: 0.5998 - val_loss: 0.7408
Epoch 7/20
11s - loss: 0.5982 - val_loss: 0.6874
Epoch 8/20
11s - loss: 0.5959 - val_loss: 0.6823
Epoch 9/20
11s - loss: 0.5942 - val_loss: 0.8016
Epoch 10/20
11s - loss: 0.5920 - val_loss: 0.7640
Epoch 11/20
11s - loss: 0.5904 - val_loss: 0.8017
Epoch 12/20
11s - loss: 0.5885 - val_loss: 0.7807
Epoch 00011: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6098 - val_loss: 0.7328
Epoch 2/20
11s - loss: 0.5970 - val_loss: 0.7553
Epoch 3/20
11s - loss: 0.5931 - val_loss: 0.8055
Epoch 4/20
11s - loss: 0.5915 - val_loss: 0.8053
Epoch 5/20
11s - loss: 0.5906 - val_loss: 0.7279
Epoch 6/20
11s - loss: 0.5885 - val_loss: 0.7328
Epoch 7/20
11s - loss: 0.5880 - val_loss: 0.7740
Epoch 8/20
11s - loss: 0.5859 - val_loss: 0.7286
Epoch 9/20
11s - loss: 0.5848 - val_loss: 0.7320
Epoch 00008: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6663 - val_loss: 0.8329
Epoch 2/20
11s - loss: 0.6618 - val_loss: 0.8458
Epoch 3/20
11s - loss: 0.6605 - val_loss: 0.8469
Epoch 4/20
11s - loss: 0.6600 - val_loss: 0.8367
Epoch 5/20
11s - loss: 0.6596 - val_loss: 0.8555
Epoch 00004: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6578 - val_loss: 0.7953
Epoch 2/20
11s - loss: 0.6488 - val_loss: 0.8437
Epoch 3/20
11s - loss: 0.6462 - val_loss: 0.8346
Epoch 4/20
11s - loss: 0.6449 - val_loss: 0.7712
Epoch 5/20
11s - loss: 0.6434 - val_loss: 0.9024
Epoch 6/20
11s - loss: 0.6417 - val_loss: 0.8097
Epoch 7/20
11s - loss: 0.6411 - val_loss: 0.8703
Epoch 8/20
11s - loss: 0.6396 - val_loss: 0.8414
Epoch 00007: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6636 - val_loss: 0.8866
Epoch 2/20
11s - loss: 0.6540 - val_loss: 0.8446
Epoch 3/20
11s - loss: 0.6510 - val_loss: 0.9082
Epoch 4/20
11s - loss: 0.6491 - val_loss: 0.8346
Epoch 5/20
11s - loss: 0.6475 - val_loss: 0.8445
Epoch 6/20
11s - loss: 0.6465 - val_loss: 0.8582
Epoch 7/20
11s - loss: 0.6448 - val_loss: 0.8962
Epoch 8/20
11s - loss: 0.6436 - val_loss: 0.8383
Epoch 00007: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6442 - val_loss: 0.8266
Epoch 2/20
11s - loss: 0.6327 - val_loss: 0.7817
Epoch 3/20
11s - loss: 0.6301 - val_loss: 0.8108
Epoch 4/20
11s - loss: 0.6287 - val_loss: 0.7923
Epoch 5/20
11s - loss: 0.6274 - val_loss: 0.8115
Epoch 6/20
11s - loss: 0.6261 - val_loss: 0.8567
Epoch 00005: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6852 - val_loss: 0.8589
Epoch 2/20
11s - loss: 0.6800 - val_loss: 0.8612
Epoch 3/20
11s - loss: 0.6792 - val_loss: 0.8856
Epoch 4/20
11s - loss: 0.6789 - val_loss: 0.8650
Epoch 5/20
11s - loss: 0.6788 - val_loss: 0.8840
Epoch 00004: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6567 - val_loss: 0.8086
Epoch 2/20
12s - loss: 0.6460 - val_loss: 0.8250
Epoch 3/20
12s - loss: 0.6429 - val_loss: 0.8347
Epoch 4/20
11s - loss: 0.6413 - val_loss: 0.7841
Epoch 5/20
11s - loss: 0.6402 - val_loss: 0.8190
Epoch 6/20
11s - loss: 0.6391 - val_loss: 0.8431
Epoch 7/20
11s - loss: 0.6382 - val_loss: 0.8685
Epoch 8/20
11s - loss: 0.6371 - val_loss: 0.8240
Epoch 00007: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6699 - val_loss: 0.8884
Epoch 2/20
11s - loss: 0.6606 - val_loss: 0.8480
Epoch 3/20
11s - loss: 0.6592 - val_loss: 0.8463
Epoch 4/20
11s - loss: 0.6581 - val_loss: 0.8905
Epoch 5/20
12s - loss: 0.6572 - val_loss: 0.8259
Epoch 6/20
11s - loss: 0.6564 - val_loss: 0.8743
Epoch 7/20
11s - loss: 0.6554 - val_loss: 0.8620
Epoch 8/20
11s - loss: 0.6543 - val_loss: 0.7995
Epoch 9/20
11s - loss: 0.6534 - val_loss: 0.8277
Epoch 10/20
11s - loss: 0.6521 - val_loss: 0.8186
Epoch 11/20
11s - loss: 0.6508 - val_loss: 0.8384
Epoch 12/20
12s - loss: 0.6496 - val_loss: 0.8216
Epoch 00011: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6839 - val_loss: 0.8513
Epoch 2/20
12s - loss: 0.6782 - val_loss: 0.8785
Epoch 3/20
11s - loss: 0.6772 - val_loss: 0.8794
Epoch 4/20
11s - loss: 0.6767 - val_loss: 0.8411
Epoch 5/20
12s - loss: 0.6765 - val_loss: 0.8676
Epoch 6/20
11s - loss: 0.6759 - val_loss: 0.8548
Epoch 7/20
12s - loss: 0.6755 - val_loss: 0.8689
Epoch 8/20
11s - loss: 0.6749 - val_loss: 0.8542
Epoch 00007: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6854 - val_loss: 0.8842
Epoch 2/20
11s - loss: 0.6803 - val_loss: 0.8847
Epoch 3/20
12s - loss: 0.6794 - val_loss: 0.8817
Epoch 4/20
12s - loss: 0.6791 - val_loss: 0.8985
Epoch 5/20
12s - loss: 0.6788 - val_loss: 0.8873
Epoch 6/20
12s - loss: 0.6784 - val_loss: 0.8651
Epoch 7/20
12s - loss: 0.6780 - val_loss: 0.8607
Epoch 8/20
11s - loss: 0.6775 - val_loss: 0.8984
Epoch 9/20
12s - loss: 0.6771 - val_loss: 0.8761
Epoch 10/20
11s - loss: 0.6764 - val_loss: 0.8803
Epoch 11/20
11s - loss: 0.6752 - val_loss: 0.8774
Epoch 00010: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6656 - val_loss: 0.8752
Epoch 2/20
11s - loss: 0.6568 - val_loss: 0.8666
Epoch 3/20
12s - loss: 0.6536 - val_loss: 0.8917
Epoch 4/20
12s - loss: 0.6526 - val_loss: 0.8098
Epoch 5/20
12s - loss: 0.6514 - val_loss: 0.8135
Epoch 6/20
12s - loss: 0.6504 - val_loss: 0.8204
Epoch 7/20
12s - loss: 0.6496 - val_loss: 0.8207
Epoch 8/20
12s - loss: 0.6486 - val_loss: 0.8306
Epoch 00007: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6564 - val_loss: 0.8935
Epoch 2/20
12s - loss: 0.6490 - val_loss: 0.8121
Epoch 3/20
12s - loss: 0.6463 - val_loss: 0.7693
Epoch 4/20
12s - loss: 0.6444 - val_loss: 0.8079
Epoch 5/20
12s - loss: 0.6433 - val_loss: 0.8546
Epoch 6/20
12s - loss: 0.6418 - val_loss: 0.8627
Epoch 7/20
11s - loss: 0.6399 - val_loss: 0.8064
Epoch 00006: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6573 - val_loss: 0.8663
Epoch 2/20
12s - loss: 0.6497 - val_loss: 0.8745
Epoch 3/20
12s - loss: 0.6480 - val_loss: 0.8174
Epoch 4/20
12s - loss: 0.6466 - val_loss: 0.8024
Epoch 5/20
12s - loss: 0.6453 - val_loss: 0.8353
Epoch 6/20
12s - loss: 0.6441 - val_loss: 0.8824
Epoch 7/20
12s - loss: 0.6430 - val_loss: 0.8451
Epoch 8/20
12s - loss: 0.6418 - val_loss: 0.8679
Epoch 00007: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6580 - val_loss: 0.7943
Epoch 2/20
12s - loss: 0.6462 - val_loss: 0.7945
Epoch 3/20
12s - loss: 0.6426 - val_loss: 0.8675
Epoch 4/20
12s - loss: 0.6404 - val_loss: 0.8495
Epoch 5/20
12s - loss: 0.6384 - val_loss: 0.8817
Epoch 00004: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6709 - val_loss: 0.9247
Epoch 2/20
12s - loss: 0.6638 - val_loss: 0.8491
Epoch 3/20
12s - loss: 0.6612 - val_loss: 0.8938
Epoch 4/20
12s - loss: 0.6596 - val_loss: 0.8305
Epoch 5/20
12s - loss: 0.6583 - val_loss: 0.8935
Epoch 6/20
12s - loss: 0.6568 - val_loss: 0.8121
Epoch 7/20
12s - loss: 0.6556 - val_loss: 0.8426
Epoch 8/20
12s - loss: 0.6534 - val_loss: 0.8391
Epoch 9/20
12s - loss: 0.6519 - val_loss: 0.8692
Epoch 10/20
12s - loss: 0.6506 - val_loss: 0.8485
Epoch 00009: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6276 - val_loss: 0.7340
Epoch 2/20
12s - loss: 0.6159 - val_loss: 0.7503
Epoch 3/20
12s - loss: 0.6123 - val_loss: 0.7632
Epoch 4/20
12s - loss: 0.6109 - val_loss: 0.7777
Epoch 5/20
12s - loss: 0.6099 - val_loss: 0.8302
Epoch 00004: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6521 - val_loss: 0.8325
Epoch 2/20
12s - loss: 0.6388 - val_loss: 0.8659
Epoch 3/20
12s - loss: 0.6358 - val_loss: 0.8296
Epoch 4/20
12s - loss: 0.6342 - val_loss: 0.8531
Epoch 5/20
12s - loss: 0.6329 - val_loss: 0.8104
Epoch 6/20
12s - loss: 0.6318 - val_loss: 0.8103
Epoch 7/20
12s - loss: 0.6303 - val_loss: 0.8725
Epoch 8/20
12s - loss: 0.6293 - val_loss: 0.7393
Epoch 9/20
12s - loss: 0.6281 - val_loss: 0.8129
Epoch 10/20
12s - loss: 0.6265 - val_loss: 0.8420
Epoch 11/20
12s - loss: 0.6254 - val_loss: 0.8181
Epoch 12/20
12s - loss: 0.6238 - val_loss: 0.8181
Epoch 00011: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6742 - val_loss: 0.8674
Epoch 2/20
12s - loss: 0.6687 - val_loss: 0.8603
Epoch 3/20
12s - loss: 0.6673 - val_loss: 0.8607
Epoch 4/20
12s - loss: 0.6669 - val_loss: 0.8601
Epoch 5/20
12s - loss: 0.6659 - val_loss: 0.8527
Epoch 6/20
12s - loss: 0.6649 - val_loss: 0.8474
Epoch 7/20
12s - loss: 0.6643 - val_loss: 0.8568
Epoch 8/20
12s - loss: 0.6635 - val_loss: 0.8383
Epoch 9/20
12s - loss: 0.6626 - val_loss: 0.8638
Epoch 10/20
12s - loss: 0.6616 - val_loss: 0.8562
Epoch 11/20
12s - loss: 0.6603 - val_loss: 0.9065
Epoch 12/20
12s - loss: 0.6592 - val_loss: 0.8609
Epoch 00011: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6488 - val_loss: 0.8085
Epoch 2/20
12s - loss: 0.6349 - val_loss: 0.8090
Epoch 3/20
12s - loss: 0.6302 - val_loss: 0.7829
Epoch 4/20
12s - loss: 0.6276 - val_loss: 0.8487
Epoch 5/20
12s - loss: 0.6256 - val_loss: 0.8093
Epoch 6/20
12s - loss: 0.6236 - val_loss: 0.7922
Epoch 7/20
12s - loss: 0.6218 - val_loss: 0.8201
Epoch 00006: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6539 - val_loss: 0.7787
Epoch 2/20
12s - loss: 0.6450 - val_loss: 0.8075
Epoch 3/20
12s - loss: 0.6417 - val_loss: 0.8315
Epoch 4/20
12s - loss: 0.6399 - val_loss: 0.8664
Epoch 5/20
12s - loss: 0.6376 - val_loss: 0.8043
Epoch 00004: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6674 - val_loss: 0.8690
Epoch 2/20
12s - loss: 0.6607 - val_loss: 0.8640
Epoch 3/20
12s - loss: 0.6590 - val_loss: 0.8053
Epoch 4/20
12s - loss: 0.6580 - val_loss: 0.8198
Epoch 5/20
12s - loss: 0.6567 - val_loss: 0.8199
Epoch 6/20
12s - loss: 0.6557 - val_loss: 0.8476
Epoch 7/20
12s - loss: 0.6547 - val_loss: 0.8599
Epoch 00006: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6679 - val_loss: 0.9006
Epoch 2/20
12s - loss: 0.6607 - val_loss: 0.8422
Epoch 3/20
12s - loss: 0.6590 - val_loss: 0.8378
Epoch 4/20
12s - loss: 0.6583 - val_loss: 0.7970
Epoch 5/20
12s - loss: 0.6571 - val_loss: 0.9226
Epoch 6/20
12s - loss: 0.6560 - val_loss: 0.7918
Epoch 7/20
12s - loss: 0.6551 - val_loss: 0.8130
Epoch 8/20
12s - loss: 0.6535 - val_loss: 0.8606
Epoch 9/20
12s - loss: 0.6531 - val_loss: 0.8537
Epoch 10/20
12s - loss: 0.6518 - val_loss: 0.8524
Epoch 00009: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6519 - val_loss: 0.8131
Epoch 2/20
12s - loss: 0.6430 - val_loss: 0.8261
Epoch 3/20
12s - loss: 0.6398 - val_loss: 0.7897
Epoch 4/20
12s - loss: 0.6383 - val_loss: 0.8040
Epoch 5/20
12s - loss: 0.6370 - val_loss: 0.7572
Epoch 6/20
12s - loss: 0.6359 - val_loss: 0.8269
Epoch 7/20
12s - loss: 0.6348 - val_loss: 0.8738
Epoch 8/20
12s - loss: 0.6334 - val_loss: 0.8139
Epoch 9/20
12s - loss: 0.6319 - val_loss: 0.7983
Epoch 00008: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6853 - val_loss: 0.8796
Epoch 2/20
12s - loss: 0.6790 - val_loss: 0.8391
Epoch 3/20
12s - loss: 0.6779 - val_loss: 0.8709
Epoch 4/20
12s - loss: 0.6777 - val_loss: 0.8726
Epoch 5/20
12s - loss: 0.6772 - val_loss: 0.8818
Epoch 6/20
12s - loss: 0.6770 - val_loss: 0.8493
Epoch 00005: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6504 - val_loss: 0.8223
Epoch 2/20
12s - loss: 0.6368 - val_loss: 0.8129
Epoch 3/20
12s - loss: 0.6330 - val_loss: 0.7772
Epoch 4/20
12s - loss: 0.6305 - val_loss: 0.8001
Epoch 5/20
12s - loss: 0.6288 - val_loss: 0.8113
Epoch 6/20
12s - loss: 0.6263 - val_loss: 0.8648
Epoch 7/20
12s - loss: 0.6249 - val_loss: 0.8127
Epoch 00006: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6772 - val_loss: 0.8587
Epoch 2/20
12s - loss: 0.6716 - val_loss: 0.8374
Epoch 3/20
12s - loss: 0.6702 - val_loss: 0.8669
Epoch 4/20
12s - loss: 0.6694 - val_loss: 0.8766
Epoch 5/20
12s - loss: 0.6688 - val_loss: 0.8513
Epoch 6/20
12s - loss: 0.6678 - val_loss: 0.8710
Epoch 00005: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6341 - val_loss: 0.7943
Epoch 2/20
12s - loss: 0.6227 - val_loss: 0.8360
Epoch 3/20
12s - loss: 0.6196 - val_loss: 0.7631
Epoch 4/20
12s - loss: 0.6182 - val_loss: 0.8110
Epoch 5/20
12s - loss: 0.6167 - val_loss: 0.7421
Epoch 6/20
12s - loss: 0.6155 - val_loss: 0.8233
Epoch 7/20
12s - loss: 0.6147 - val_loss: 0.7743
Epoch 8/20
12s - loss: 0.6137 - val_loss: 0.8298
Epoch 9/20
12s - loss: 0.6125 - val_loss: 0.7512
Epoch 00008: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6672 - val_loss: 0.8275
Epoch 2/20
12s - loss: 0.6584 - val_loss: 0.8754
Epoch 3/20
12s - loss: 0.6554 - val_loss: 0.8675
Epoch 4/20
12s - loss: 0.6529 - val_loss: 0.8499
Epoch 5/20
12s - loss: 0.6514 - val_loss: 0.8692
Epoch 00004: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6472 - val_loss: 0.8232
Epoch 2/20
12s - loss: 0.6392 - val_loss: 0.7772
Epoch 3/20
12s - loss: 0.6359 - val_loss: 0.8459
Epoch 4/20
12s - loss: 0.6332 - val_loss: 0.8660
Epoch 5/20
12s - loss: 0.6310 - val_loss: 0.8226
Epoch 6/20
12s - loss: 0.6298 - val_loss: 0.8776
Epoch 00005: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6716 - val_loss: 0.8586
Epoch 2/20
12s - loss: 0.6654 - val_loss: 0.8780
Epoch 3/20
12s - loss: 0.6634 - val_loss: 0.8049
Epoch 4/20
12s - loss: 0.6622 - val_loss: 0.8659
Epoch 5/20
12s - loss: 0.6611 - val_loss: 0.8377
Epoch 6/20
12s - loss: 0.6594 - val_loss: 0.8519
Epoch 7/20
12s - loss: 0.6582 - val_loss: 0.9033
Epoch 00006: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6595 - val_loss: 0.8706
Epoch 2/20
12s - loss: 0.6523 - val_loss: 0.8741
Epoch 3/20
12s - loss: 0.6503 - val_loss: 0.8772
Epoch 4/20
12s - loss: 0.6490 - val_loss: 0.8237
Epoch 5/20
12s - loss: 0.6480 - val_loss: 0.8584
Epoch 6/20
12s - loss: 0.6467 - val_loss: 0.7789
Epoch 7/20
12s - loss: 0.6459 - val_loss: 0.8151
Epoch 8/20
12s - loss: 0.6448 - val_loss: 0.8350
Epoch 9/20
12s - loss: 0.6436 - val_loss: 0.8305
Epoch 10/20
12s - loss: 0.6423 - val_loss: 0.8183
Epoch 00009: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6373 - val_loss: 0.7709
Epoch 2/20
12s - loss: 0.6245 - val_loss: 0.8274
Epoch 3/20
12s - loss: 0.6214 - val_loss: 0.8359
Epoch 4/20
12s - loss: 0.6195 - val_loss: 0.7625
Epoch 5/20
12s - loss: 0.6185 - val_loss: 0.7224
Epoch 6/20
12s - loss: 0.6173 - val_loss: 0.7702
Epoch 7/20
12s - loss: 0.6163 - val_loss: 0.7734
Epoch 8/20
12s - loss: 0.6153 - val_loss: 0.7988
Epoch 9/20
12s - loss: 0.6140 - val_loss: 0.7654
Epoch 00008: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6607 - val_loss: 0.8752
Epoch 2/20
12s - loss: 0.6501 - val_loss: 0.8339
Epoch 3/20
12s - loss: 0.6470 - val_loss: 0.8430
Epoch 4/20
12s - loss: 0.6456 - val_loss: 0.8563
Epoch 5/20
12s - loss: 0.6443 - val_loss: 0.8493
Epoch 6/20
12s - loss: 0.6431 - val_loss: 0.8352
Epoch 00005: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6543 - val_loss: 0.8417
Epoch 2/20
12s - loss: 0.6458 - val_loss: 0.8119
Epoch 3/20
12s - loss: 0.6427 - val_loss: 0.7672
Epoch 4/20
12s - loss: 0.6400 - val_loss: 0.8342
Epoch 5/20
12s - loss: 0.6383 - val_loss: 0.8558
Epoch 6/20
12s - loss: 0.6366 - val_loss: 0.8238
Epoch 7/20
12s - loss: 0.6350 - val_loss: 0.8521
Epoch 00006: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6620 - val_loss: 0.8732
Epoch 2/20
12s - loss: 0.6543 - val_loss: 0.8775
Epoch 3/20
12s - loss: 0.6507 - val_loss: 0.8626
Epoch 4/20
12s - loss: 0.6489 - val_loss: 0.7989
Epoch 5/20
12s - loss: 0.6467 - val_loss: 0.8490
Epoch 6/20
12s - loss: 0.6453 - val_loss: 0.8704
Epoch 7/20
12s - loss: 0.6433 - val_loss: 0.8159
Epoch 8/20
12s - loss: 0.6419 - val_loss: 0.8105
Epoch 00007: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6519 - val_loss: 0.8568
Epoch 2/20
12s - loss: 0.6383 - val_loss: 0.8709
Epoch 3/20
12s - loss: 0.6350 - val_loss: 0.8404
Epoch 4/20
12s - loss: 0.6327 - val_loss: 0.8609
Epoch 5/20
12s - loss: 0.6304 - val_loss: 0.7610
Epoch 6/20
12s - loss: 0.6294 - val_loss: 0.7793
Epoch 7/20
12s - loss: 0.6277 - val_loss: 0.7706
Epoch 8/20
12s - loss: 0.6263 - val_loss: 0.8390
Epoch 9/20
12s - loss: 0.6247 - val_loss: 0.9060
Epoch 00008: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6856 - val_loss: 0.8563
Epoch 2/20
12s - loss: 0.6802 - val_loss: 0.8836
Epoch 3/20
12s - loss: 0.6792 - val_loss: 0.8713
Epoch 4/20
12s - loss: 0.6787 - val_loss: 0.8621
Epoch 5/20
12s - loss: 0.6784 - val_loss: 0.8763
Epoch 00004: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6474 - val_loss: 0.8260
Epoch 2/20
12s - loss: 0.6386 - val_loss: 0.8113
Epoch 3/20
12s - loss: 0.6359 - val_loss: 0.7946
Epoch 4/20
12s - loss: 0.6342 - val_loss: 0.8498
Epoch 5/20
12s - loss: 0.6321 - val_loss: 0.8128
Epoch 6/20
12s - loss: 0.6310 - val_loss: 0.8735
Epoch 7/20
12s - loss: 0.6295 - val_loss: 0.8232
Epoch 00006: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6686 - val_loss: 0.8274
Epoch 2/20
12s - loss: 0.6593 - val_loss: 0.8333
Epoch 3/20
12s - loss: 0.6575 - val_loss: 0.8596
Epoch 4/20
12s - loss: 0.6562 - val_loss: 0.8506
Epoch 5/20
12s - loss: 0.6551 - val_loss: 0.8709
Epoch 00004: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6631 - val_loss: 0.8561
Epoch 2/20
12s - loss: 0.6518 - val_loss: 0.8315
Epoch 3/20
12s - loss: 0.6486 - val_loss: 0.8485
Epoch 4/20
12s - loss: 0.6473 - val_loss: 0.9119
Epoch 5/20
12s - loss: 0.6459 - val_loss: 0.8432
Epoch 6/20
12s - loss: 0.6443 - val_loss: 0.8542
Epoch 00005: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6585 - val_loss: 0.8135
Epoch 2/20
12s - loss: 0.6509 - val_loss: 0.8750
Epoch 3/20
12s - loss: 0.6489 - val_loss: 0.8547
Epoch 4/20
12s - loss: 0.6478 - val_loss: 0.8867
Epoch 5/20
12s - loss: 0.6467 - val_loss: 0.8452
Epoch 00004: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6577 - val_loss: 0.8294
Epoch 2/20
12s - loss: 0.6450 - val_loss: 0.8120
Epoch 3/20
12s - loss: 0.6418 - val_loss: 0.8321
Epoch 4/20
12s - loss: 0.6390 - val_loss: 0.8798
Epoch 5/20
12s - loss: 0.6371 - val_loss: 0.7537
Epoch 6/20
12s - loss: 0.6353 - val_loss: 0.9053
Epoch 7/20
12s - loss: 0.6340 - val_loss: 0.8087
Epoch 8/20
12s - loss: 0.6323 - val_loss: 0.7539
Epoch 9/20
12s - loss: 0.6308 - val_loss: 0.9007
Epoch 00008: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6489 - val_loss: 0.8035
Epoch 2/20
12s - loss: 0.6396 - val_loss: 0.8166
Epoch 3/20
12s - loss: 0.6370 - val_loss: 0.8285
Epoch 4/20
12s - loss: 0.6349 - val_loss: 0.8330
Epoch 5/20
12s - loss: 0.6330 - val_loss: 0.8110
Epoch 00004: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6740 - val_loss: 0.8804
Epoch 2/20
12s - loss: 0.6687 - val_loss: 0.9164
Epoch 3/20
12s - loss: 0.6679 - val_loss: 0.8415
Epoch 4/20
12s - loss: 0.6671 - val_loss: 0.8661
Epoch 5/20
12s - loss: 0.6664 - val_loss: 0.8830
Epoch 6/20
12s - loss: 0.6653 - val_loss: 0.8471
Epoch 7/20
12s - loss: 0.6641 - val_loss: 0.9002
Epoch 00006: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6661 - val_loss: 0.8466
Epoch 2/20
12s - loss: 0.6612 - val_loss: 0.8726
Epoch 3/20
12s - loss: 0.6603 - val_loss: 0.8374
Epoch 4/20
12s - loss: 0.6599 - val_loss: 0.8812
Epoch 5/20
12s - loss: 0.6593 - val_loss: 0.8579
Epoch 6/20
12s - loss: 0.6580 - val_loss: 0.8731
Epoch 7/20
12s - loss: 0.6573 - val_loss: 0.8454
Epoch 00006: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6816 - val_loss: 0.8943
Epoch 2/20
12s - loss: 0.6762 - val_loss: 0.8274
Epoch 3/20
12s - loss: 0.6751 - val_loss: 0.8728
Epoch 4/20
12s - loss: 0.6746 - val_loss: 0.8706
Epoch 5/20
12s - loss: 0.6739 - val_loss: 0.8628
Epoch 6/20
12s - loss: 0.6730 - val_loss: 0.8795
Epoch 00005: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6609 - val_loss: 0.8882
Epoch 2/20
12s - loss: 0.6550 - val_loss: 0.8221
Epoch 3/20
12s - loss: 0.6531 - val_loss: 0.8275
Epoch 4/20
12s - loss: 0.6523 - val_loss: 0.8757
Epoch 5/20
12s - loss: 0.6516 - val_loss: 0.8091
Epoch 6/20
12s - loss: 0.6507 - val_loss: 0.8133
Epoch 7/20
12s - loss: 0.6497 - val_loss: 0.8174
Epoch 8/20
12s - loss: 0.6490 - val_loss: 0.8666
Epoch 9/20
12s - loss: 0.6478 - val_loss: 0.7979
Epoch 10/20
12s - loss: 0.6469 - val_loss: 0.8424
Epoch 11/20
12s - loss: 0.6459 - val_loss: 0.8337
Epoch 12/20
12s - loss: 0.6448 - val_loss: 0.8648
Epoch 13/20
12s - loss: 0.6435 - val_loss: 0.8473
Epoch 00012: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6747 - val_loss: 0.8510
Epoch 2/20
12s - loss: 0.6685 - val_loss: 0.8737
Epoch 3/20
12s - loss: 0.6667 - val_loss: 0.8938
Epoch 4/20
12s - loss: 0.6661 - val_loss: 0.9082
Epoch 5/20
12s - loss: 0.6649 - val_loss: 0.8542
Epoch 00004: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6687 - val_loss: 0.8615
Epoch 2/20
12s - loss: 0.6599 - val_loss: 0.8279
Epoch 3/20
12s - loss: 0.6576 - val_loss: 0.8604
Epoch 4/20
12s - loss: 0.6568 - val_loss: 0.8752
Epoch 5/20
12s - loss: 0.6560 - val_loss: 0.8634
Epoch 6/20
12s - loss: 0.6553 - val_loss: 0.8744
Epoch 00005: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6490 - val_loss: 0.8829
Epoch 2/20
12s - loss: 0.6374 - val_loss: 0.8308
Epoch 3/20
12s - loss: 0.6325 - val_loss: 0.8348
Epoch 4/20
12s - loss: 0.6296 - val_loss: 0.8060
Epoch 5/20
12s - loss: 0.6276 - val_loss: 0.8725
Epoch 6/20
12s - loss: 0.6262 - val_loss: 0.8278
Epoch 7/20
12s - loss: 0.6246 - val_loss: 0.7947
Epoch 8/20
12s - loss: 0.6233 - val_loss: 0.7957
Epoch 9/20
12s - loss: 0.6216 - val_loss: 0.7847
Epoch 10/20
12s - loss: 0.6198 - val_loss: 0.8589
Epoch 11/20
12s - loss: 0.6183 - val_loss: 0.8594
Epoch 12/20
12s - loss: 0.6165 - val_loss: 0.8886
Epoch 13/20
12s - loss: 0.6149 - val_loss: 0.8097
Epoch 00012: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6459 - val_loss: 0.8066
Epoch 2/20
12s - loss: 0.6346 - val_loss: 0.8154
Epoch 3/20
12s - loss: 0.6314 - val_loss: 0.8044
Epoch 4/20
12s - loss: 0.6287 - val_loss: 0.8076
Epoch 5/20
12s - loss: 0.6263 - val_loss: 0.8429
Epoch 6/20
12s - loss: 0.6248 - val_loss: 0.8075
Epoch 7/20
12s - loss: 0.6226 - val_loss: 0.7867
Epoch 8/20
12s - loss: 0.6215 - val_loss: 0.7956
Epoch 9/20
12s - loss: 0.6198 - val_loss: 0.8064
Epoch 10/20
12s - loss: 0.6178 - val_loss: 0.8398
Epoch 11/20
12s - loss: 0.6162 - val_loss: 0.8494
Epoch 00010: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6815 - val_loss: 0.8744
Epoch 2/20
12s - loss: 0.6748 - val_loss: 0.8573
Epoch 3/20
12s - loss: 0.6737 - val_loss: 0.8284
Epoch 4/20
12s - loss: 0.6729 - val_loss: 0.8696
Epoch 5/20
12s - loss: 0.6722 - val_loss: 0.9024
Epoch 6/20
12s - loss: 0.6714 - val_loss: 0.8823
Epoch 7/20
12s - loss: 0.6703 - val_loss: 0.8572
Epoch 00006: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6626 - val_loss: 0.8221
Epoch 2/20
12s - loss: 0.6542 - val_loss: 0.8275
Epoch 3/20
12s - loss: 0.6515 - val_loss: 0.8351
Epoch 4/20
12s - loss: 0.6490 - val_loss: 0.8210
Epoch 5/20
12s - loss: 0.6469 - val_loss: 0.8691
Epoch 6/20
12s - loss: 0.6456 - val_loss: 0.8406
Epoch 7/20
12s - loss: 0.6434 - val_loss: 0.7988
Epoch 8/20
12s - loss: 0.6418 - val_loss: 0.8846
Epoch 9/20
12s - loss: 0.6399 - val_loss: 0.8732
Epoch 10/20
12s - loss: 0.6383 - val_loss: 0.8319
Epoch 11/20
12s - loss: 0.6367 - val_loss: 0.8412
Epoch 00010: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6640 - val_loss: 0.8560
Epoch 2/20
12s - loss: 0.6532 - val_loss: 0.8319
Epoch 3/20
12s - loss: 0.6499 - val_loss: 0.8430
Epoch 4/20
12s - loss: 0.6465 - val_loss: 0.8827
Epoch 5/20
12s - loss: 0.6448 - val_loss: 0.8622
Epoch 6/20
12s - loss: 0.6425 - val_loss: 0.8180
Epoch 7/20
12s - loss: 0.6412 - val_loss: 0.9139
Epoch 8/20
12s - loss: 0.6392 - val_loss: 0.9175
Epoch 9/20
12s - loss: 0.6378 - val_loss: 0.7801
Epoch 10/20
12s - loss: 0.6359 - val_loss: 0.8650
Epoch 11/20
12s - loss: 0.6341 - val_loss: 0.8059
Epoch 12/20
12s - loss: 0.6320 - val_loss: 0.8129
Epoch 13/20
12s - loss: 0.6306 - val_loss: 0.7874
Epoch 00012: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6588 - val_loss: 0.8823
Epoch 2/20
12s - loss: 0.6505 - val_loss: 0.8223
Epoch 3/20
12s - loss: 0.6485 - val_loss: 0.8524
Epoch 4/20
12s - loss: 0.6471 - val_loss: 0.8600
Epoch 5/20
12s - loss: 0.6458 - val_loss: 0.8136
Epoch 6/20
12s - loss: 0.6442 - val_loss: 0.9050
Epoch 7/20
12s - loss: 0.6428 - val_loss: 0.8229
Epoch 8/20
12s - loss: 0.6417 - val_loss: 0.8728
Epoch 9/20
12s - loss: 0.6406 - val_loss: 0.7990
Epoch 10/20
12s - loss: 0.6389 - val_loss: 0.8552
Epoch 11/20
12s - loss: 0.6375 - val_loss: 0.8023
Epoch 12/20
12s - loss: 0.6358 - val_loss: 0.8270
Epoch 13/20
12s - loss: 0.6342 - val_loss: 0.7944
Epoch 14/20
12s - loss: 0.6325 - val_loss: 0.7909
Epoch 15/20
12s - loss: 0.6305 - val_loss: 0.8705
Epoch 16/20
12s - loss: 0.6288 - val_loss: 0.8982
Epoch 17/20
12s - loss: 0.6270 - val_loss: 0.8435
Epoch 18/20
12s - loss: 0.6254 - val_loss: 0.8166
Epoch 00017: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6592 - val_loss: 0.8475
Epoch 2/20
12s - loss: 0.6532 - val_loss: 0.8155
Epoch 3/20
12s - loss: 0.6515 - val_loss: 0.8475
Epoch 4/20
12s - loss: 0.6506 - val_loss: 0.8198
Epoch 5/20
12s - loss: 0.6495 - val_loss: 0.8627
Epoch 6/20
12s - loss: 0.6484 - val_loss: 0.8645
Epoch 00005: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6634 - val_loss: 0.8330
Epoch 2/20
12s - loss: 0.6547 - val_loss: 0.8408
Epoch 3/20
12s - loss: 0.6519 - val_loss: 0.8315
Epoch 4/20
12s - loss: 0.6499 - val_loss: 0.8073
Epoch 5/20
12s - loss: 0.6477 - val_loss: 0.8335
Epoch 6/20
12s - loss: 0.6456 - val_loss: 0.8219
Epoch 7/20
12s - loss: 0.6441 - val_loss: 0.8181
Epoch 8/20
12s - loss: 0.6426 - val_loss: 0.8441
Epoch 00007: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6559 - val_loss: 0.8412
Epoch 2/20
12s - loss: 0.6458 - val_loss: 0.8571
Epoch 3/20
12s - loss: 0.6416 - val_loss: 0.8188
Epoch 4/20
12s - loss: 0.6386 - val_loss: 0.8371
Epoch 5/20
12s - loss: 0.6368 - val_loss: 0.8363
Epoch 6/20
12s - loss: 0.6349 - val_loss: 0.8162
Epoch 7/20
12s - loss: 0.6338 - val_loss: 0.7828
Epoch 8/20
12s - loss: 0.6316 - val_loss: 0.7738
Epoch 9/20
12s - loss: 0.6298 - val_loss: 0.9114
Epoch 10/20
12s - loss: 0.6281 - val_loss: 0.8298
Epoch 11/20
12s - loss: 0.6264 - val_loss: 0.7695
Epoch 12/20
12s - loss: 0.6248 - val_loss: 0.8158
Epoch 13/20
12s - loss: 0.6226 - val_loss: 0.8089
Epoch 14/20
12s - loss: 0.6213 - val_loss: 0.7961
Epoch 15/20
12s - loss: 0.6192 - val_loss: 0.8008
Epoch 00014: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6623 - val_loss: 0.8811
Epoch 2/20
12s - loss: 0.6525 - val_loss: 0.8747
Epoch 3/20
12s - loss: 0.6498 - val_loss: 0.8518
Epoch 4/20
12s - loss: 0.6483 - val_loss: 0.9302
Epoch 5/20
12s - loss: 0.6464 - val_loss: 0.8796
Epoch 6/20
12s - loss: 0.6454 - val_loss: 0.8370
Epoch 7/20
12s - loss: 0.6440 - val_loss: 0.8249
Epoch 8/20
12s - loss: 0.6426 - val_loss: 0.8590
Epoch 9/20
12s - loss: 0.6415 - val_loss: 0.8256
Epoch 10/20
12s - loss: 0.6399 - val_loss: 0.8588
Epoch 11/20
12s - loss: 0.6388 - val_loss: 0.8303
Epoch 00010: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6800 - val_loss: 0.8731
Epoch 2/20
12s - loss: 0.6750 - val_loss: 0.8818
Epoch 3/20
12s - loss: 0.6741 - val_loss: 0.8678
Epoch 4/20
12s - loss: 0.6734 - val_loss: 0.8765
Epoch 5/20
12s - loss: 0.6728 - val_loss: 0.9165
Epoch 6/20
12s - loss: 0.6724 - val_loss: 0.8804
Epoch 7/20
12s - loss: 0.6713 - val_loss: 0.8803
Epoch 00006: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6773 - val_loss: 0.8828
Epoch 2/20
12s - loss: 0.6719 - val_loss: 0.8695
Epoch 3/20
12s - loss: 0.6708 - val_loss: 0.8643
Epoch 4/20
12s - loss: 0.6703 - val_loss: 0.8808
Epoch 5/20
12s - loss: 0.6701 - val_loss: 0.8745
Epoch 6/20
12s - loss: 0.6696 - val_loss: 0.8690
Epoch 7/20
12s - loss: 0.6694 - val_loss: 0.8309
Epoch 8/20
12s - loss: 0.6689 - val_loss: 0.8726
Epoch 9/20
12s - loss: 0.6680 - val_loss: 0.8733
Epoch 10/20
12s - loss: 0.6677 - val_loss: 0.8389
Epoch 11/20
12s - loss: 0.6670 - val_loss: 0.8375
Epoch 00010: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6821 - val_loss: 0.8730
Epoch 2/20
12s - loss: 0.6760 - val_loss: 0.8755
Epoch 3/20
12s - loss: 0.6748 - val_loss: 0.8810
Epoch 4/20
12s - loss: 0.6744 - val_loss: 0.8665
Epoch 5/20
12s - loss: 0.6739 - val_loss: 0.8701
Epoch 6/20
12s - loss: 0.6733 - val_loss: 0.8617
Epoch 7/20
12s - loss: 0.6728 - val_loss: 0.8624
Epoch 8/20
12s - loss: 0.6720 - val_loss: 0.8918
Epoch 9/20
12s - loss: 0.6715 - val_loss: 0.8663
Epoch 10/20
12s - loss: 0.6707 - val_loss: 0.8753
Epoch 00009: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6690 - val_loss: 0.8504
Epoch 2/20
12s - loss: 0.6621 - val_loss: 0.8439
Epoch 3/20
12s - loss: 0.6604 - val_loss: 0.8766
Epoch 4/20
12s - loss: 0.6594 - val_loss: 0.8631
Epoch 5/20
12s - loss: 0.6581 - val_loss: 0.8646
Epoch 6/20
12s - loss: 0.6562 - val_loss: 0.8482
Epoch 00005: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6513 - val_loss: 0.8782
Epoch 2/20
12s - loss: 0.6435 - val_loss: 0.8341
Epoch 3/20
12s - loss: 0.6413 - val_loss: 0.8396
Epoch 4/20
12s - loss: 0.6387 - val_loss: 0.8332
Epoch 5/20
12s - loss: 0.6374 - val_loss: 0.9095
Epoch 6/20
12s - loss: 0.6357 - val_loss: 0.8341
Epoch 7/20
12s - loss: 0.6340 - val_loss: 0.8504
Epoch 8/20
12s - loss: 0.6325 - val_loss: 0.8037
Epoch 9/20
12s - loss: 0.6310 - val_loss: 0.8155
Epoch 10/20
12s - loss: 0.6292 - val_loss: 0.8602
Epoch 11/20
12s - loss: 0.6278 - val_loss: 0.8688
Epoch 12/20
12s - loss: 0.6259 - val_loss: 0.8863
Epoch 00011: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6543 - val_loss: 0.8702
Epoch 2/20
12s - loss: 0.6470 - val_loss: 0.8549
Epoch 3/20
12s - loss: 0.6452 - val_loss: 0.8706
Epoch 4/20
12s - loss: 0.6429 - val_loss: 0.7785
Epoch 5/20
12s - loss: 0.6416 - val_loss: 0.8749
Epoch 6/20
12s - loss: 0.6401 - val_loss: 0.8837
Epoch 7/20
12s - loss: 0.6386 - val_loss: 0.8154
Epoch 8/20
12s - loss: 0.6371 - val_loss: 0.8194
Epoch 00007: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6378 - val_loss: 0.7912
Epoch 2/20
12s - loss: 0.6269 - val_loss: 0.7653
Epoch 3/20
12s - loss: 0.6230 - val_loss: 0.8428
Epoch 4/20
12s - loss: 0.6218 - val_loss: 0.8075
Epoch 5/20
12s - loss: 0.6204 - val_loss: 0.7665
Epoch 6/20
12s - loss: 0.6193 - val_loss: 0.7809
Epoch 00005: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6603 - val_loss: 0.8148
Epoch 2/20
12s - loss: 0.6492 - val_loss: 0.8409
Epoch 3/20
12s - loss: 0.6466 - val_loss: 0.8252
Epoch 4/20
12s - loss: 0.6451 - val_loss: 0.8063
Epoch 5/20
12s - loss: 0.6428 - val_loss: 0.8826
Epoch 6/20
12s - loss: 0.6412 - val_loss: 0.8535
Epoch 7/20
12s - loss: 0.6392 - val_loss: 0.8522
Epoch 8/20
12s - loss: 0.6374 - val_loss: 0.8283
Epoch 00007: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6530 - val_loss: 0.8383
Epoch 2/20
12s - loss: 0.6420 - val_loss: 0.8516
Epoch 3/20
12s - loss: 0.6383 - val_loss: 0.8056
Epoch 4/20
12s - loss: 0.6359 - val_loss: 0.8325
Epoch 5/20
12s - loss: 0.6331 - val_loss: 0.7988
Epoch 6/20
12s - loss: 0.6316 - val_loss: 0.8010
Epoch 7/20
12s - loss: 0.6295 - val_loss: 0.8677
Epoch 8/20
12s - loss: 0.6277 - val_loss: 0.8348
Epoch 9/20
12s - loss: 0.6263 - val_loss: 0.8132
Epoch 00008: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6842 - val_loss: 0.8816
Epoch 2/20
12s - loss: 0.6790 - val_loss: 0.8748
Epoch 3/20
12s - loss: 0.6781 - val_loss: 0.8824
Epoch 4/20
12s - loss: 0.6777 - val_loss: 0.8633
Epoch 5/20
12s - loss: 0.6773 - val_loss: 0.8878
Epoch 6/20
12s - loss: 0.6768 - val_loss: 0.8814
Epoch 7/20
12s - loss: 0.6764 - val_loss: 0.8722
Epoch 8/20
12s - loss: 0.6758 - val_loss: 0.8690
Epoch 00007: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6704 - val_loss: 0.8325
Epoch 2/20
12s - loss: 0.6645 - val_loss: 0.8712
Epoch 3/20
12s - loss: 0.6637 - val_loss: 0.8787
Epoch 4/20
12s - loss: 0.6632 - val_loss: 0.8802
Epoch 5/20
12s - loss: 0.6624 - val_loss: 0.8293
Epoch 6/20
12s - loss: 0.6615 - val_loss: 0.8290
Epoch 7/20
12s - loss: 0.6609 - val_loss: 0.8547
Epoch 8/20
12s - loss: 0.6598 - val_loss: 0.8566
Epoch 9/20
12s - loss: 0.6593 - val_loss: 0.8324
Epoch 10/20
12s - loss: 0.6579 - val_loss: 0.8602
Epoch 00009: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6418 - val_loss: 0.8260
Epoch 2/20
13s - loss: 0.6296 - val_loss: 0.8610
Epoch 3/20
12s - loss: 0.6257 - val_loss: 0.8723
Epoch 4/20
12s - loss: 0.6228 - val_loss: 0.7760
Epoch 5/20
12s - loss: 0.6205 - val_loss: 0.8154
Epoch 6/20
12s - loss: 0.6192 - val_loss: 0.8052
Epoch 7/20
12s - loss: 0.6178 - val_loss: 0.7996
Epoch 8/20
12s - loss: 0.6161 - val_loss: 0.7737
Epoch 9/20
12s - loss: 0.6143 - val_loss: 0.8166
Epoch 10/20
12s - loss: 0.6132 - val_loss: 0.8659
Epoch 11/20
12s - loss: 0.6116 - val_loss: 0.8115
Epoch 12/20
12s - loss: 0.6099 - val_loss: 0.7902
Epoch 00011: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6642 - val_loss: 0.8464
Epoch 2/20
12s - loss: 0.6566 - val_loss: 0.8399
Epoch 3/20
12s - loss: 0.6545 - val_loss: 0.8514
Epoch 4/20
12s - loss: 0.6537 - val_loss: 0.8134
Epoch 5/20
12s - loss: 0.6528 - val_loss: 0.8305
Epoch 6/20
12s - loss: 0.6517 - val_loss: 0.8502
Epoch 7/20
12s - loss: 0.6509 - val_loss: 0.8544
Epoch 8/20
12s - loss: 0.6494 - val_loss: 0.8386
Epoch 00007: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6781 - val_loss: 0.8791
Epoch 2/20
13s - loss: 0.6729 - val_loss: 0.8807
Epoch 3/20
13s - loss: 0.6720 - val_loss: 0.8763
Epoch 4/20
12s - loss: 0.6712 - val_loss: 0.8469
Epoch 5/20
12s - loss: 0.6703 - val_loss: 0.8409
Epoch 6/20
13s - loss: 0.6695 - val_loss: 0.8497
Epoch 7/20
13s - loss: 0.6683 - val_loss: 0.8952
Epoch 8/20
12s - loss: 0.6673 - val_loss: 0.8899
Epoch 9/20
13s - loss: 0.6663 - val_loss: 0.8559
Epoch 00008: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6605 - val_loss: 0.8486
Epoch 2/20
12s - loss: 0.6512 - val_loss: 0.8247
Epoch 3/20
13s - loss: 0.6492 - val_loss: 0.8561
Epoch 4/20
13s - loss: 0.6482 - val_loss: 0.8479
Epoch 5/20
13s - loss: 0.6471 - val_loss: 0.8645
Epoch 6/20
13s - loss: 0.6462 - val_loss: 0.8804
Epoch 00005: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6581 - val_loss: 0.8327
Epoch 2/20
13s - loss: 0.6484 - val_loss: 0.8069
Epoch 3/20
13s - loss: 0.6449 - val_loss: 0.8098
Epoch 4/20
13s - loss: 0.6425 - val_loss: 0.8407
Epoch 5/20
13s - loss: 0.6405 - val_loss: 0.7716
Epoch 6/20
13s - loss: 0.6388 - val_loss: 0.8541
Epoch 7/20
13s - loss: 0.6372 - val_loss: 0.8520
Epoch 8/20
13s - loss: 0.6356 - val_loss: 0.8372
Epoch 9/20
13s - loss: 0.6342 - val_loss: 0.8791
Epoch 00008: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6691 - val_loss: 0.8719
Epoch 2/20
13s - loss: 0.6620 - val_loss: 0.8481
Epoch 3/20
13s - loss: 0.6596 - val_loss: 0.8839
Epoch 4/20
13s - loss: 0.6581 - val_loss: 0.8184
Epoch 5/20
12s - loss: 0.6562 - val_loss: 0.8532
Epoch 6/20
13s - loss: 0.6549 - val_loss: 0.8480
Epoch 7/20
13s - loss: 0.6533 - val_loss: 0.8911
Epoch 8/20
13s - loss: 0.6518 - val_loss: 0.8619
Epoch 00007: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6726 - val_loss: 0.8647
Epoch 2/20
13s - loss: 0.6647 - val_loss: 0.8754
Epoch 3/20
13s - loss: 0.6631 - val_loss: 0.8728
Epoch 4/20
13s - loss: 0.6626 - val_loss: 0.8481
Epoch 5/20
13s - loss: 0.6615 - val_loss: 0.9064
Epoch 6/20
13s - loss: 0.6602 - val_loss: 0.8631
Epoch 7/20
13s - loss: 0.6591 - val_loss: 0.8575
Epoch 8/20
13s - loss: 0.6580 - val_loss: 0.8453
Epoch 9/20
13s - loss: 0.6565 - val_loss: 0.8848
Epoch 10/20
13s - loss: 0.6555 - val_loss: 0.8360
Epoch 11/20
13s - loss: 0.6539 - val_loss: 0.8939
Epoch 12/20
13s - loss: 0.6525 - val_loss: 0.8450
Epoch 13/20
13s - loss: 0.6507 - val_loss: 0.8816
Epoch 14/20
13s - loss: 0.6491 - val_loss: 0.8769
Epoch 00013: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6797 - val_loss: 0.8496
Epoch 2/20
13s - loss: 0.6736 - val_loss: 0.8576
Epoch 3/20
13s - loss: 0.6728 - val_loss: 0.8540
Epoch 4/20
13s - loss: 0.6722 - val_loss: 0.8440
Epoch 5/20
13s - loss: 0.6717 - val_loss: 0.8499
Epoch 6/20
13s - loss: 0.6712 - val_loss: 0.8840
Epoch 7/20
13s - loss: 0.6705 - val_loss: 0.8313
Epoch 8/20
13s - loss: 0.6699 - val_loss: 0.8823
Epoch 9/20
13s - loss: 0.6693 - val_loss: 0.8471
Epoch 10/20
13s - loss: 0.6683 - val_loss: 0.8691
Epoch 11/20
13s - loss: 0.6674 - val_loss: 0.8722
Epoch 00010: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6787 - val_loss: 0.8355
Epoch 2/20
13s - loss: 0.6728 - val_loss: 0.8654
Epoch 3/20
13s - loss: 0.6713 - val_loss: 0.8619
Epoch 4/20
13s - loss: 0.6704 - val_loss: 0.8940
Epoch 5/20
13s - loss: 0.6696 - val_loss: 0.8992
Epoch 00004: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6208 - val_loss: 0.8285
Epoch 2/20
13s - loss: 0.6089 - val_loss: 0.7562
Epoch 3/20
13s - loss: 0.6058 - val_loss: 0.8121
Epoch 4/20
13s - loss: 0.6043 - val_loss: 0.7479
Epoch 5/20
13s - loss: 0.6030 - val_loss: 0.8205
Epoch 6/20
13s - loss: 0.6017 - val_loss: 0.7963
Epoch 7/20
13s - loss: 0.6004 - val_loss: 0.7906
Epoch 8/20
13s - loss: 0.5993 - val_loss: 0.7520
Epoch 00007: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6573 - val_loss: 0.8354
Epoch 2/20
13s - loss: 0.6502 - val_loss: 0.8741
Epoch 3/20
13s - loss: 0.6483 - val_loss: 0.8265
Epoch 4/20
13s - loss: 0.6470 - val_loss: 0.9073
Epoch 5/20
13s - loss: 0.6457 - val_loss: 0.7871
Epoch 6/20
13s - loss: 0.6443 - val_loss: 0.8360
Epoch 7/20
13s - loss: 0.6431 - val_loss: 0.8044
Epoch 8/20
13s - loss: 0.6421 - val_loss: 0.8423
Epoch 9/20
13s - loss: 0.6405 - val_loss: 0.8783
Epoch 00008: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6745 - val_loss: 0.8950
Epoch 2/20
13s - loss: 0.6676 - val_loss: 0.9209
Epoch 3/20
13s - loss: 0.6663 - val_loss: 0.8412
Epoch 4/20
13s - loss: 0.6657 - val_loss: 0.8494
Epoch 5/20
13s - loss: 0.6651 - val_loss: 0.8522
Epoch 6/20
13s - loss: 0.6640 - val_loss: 0.8743
Epoch 7/20
13s - loss: 0.6632 - val_loss: 0.8353
Epoch 8/20
13s - loss: 0.6619 - val_loss: 0.8387
Epoch 9/20
13s - loss: 0.6610 - val_loss: 0.8416
Epoch 10/20
13s - loss: 0.6599 - val_loss: 0.8700
Epoch 11/20
13s - loss: 0.6588 - val_loss: 0.8474
Epoch 00010: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6563 - val_loss: 0.8449
Epoch 2/20
13s - loss: 0.6478 - val_loss: 0.8097
Epoch 3/20
13s - loss: 0.6452 - val_loss: 0.7843
Epoch 4/20
13s - loss: 0.6438 - val_loss: 0.7779
Epoch 5/20
13s - loss: 0.6429 - val_loss: 0.8287
Epoch 6/20
13s - loss: 0.6417 - val_loss: 0.8619
Epoch 7/20
13s - loss: 0.6406 - val_loss: 0.8395
Epoch 8/20
13s - loss: 0.6393 - val_loss: 0.8982
Epoch 00007: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6572 - val_loss: 0.7870
Epoch 2/20
13s - loss: 0.6446 - val_loss: 0.8174
Epoch 3/20
13s - loss: 0.6412 - val_loss: 0.8383
Epoch 4/20
13s - loss: 0.6396 - val_loss: 0.8179
Epoch 5/20
13s - loss: 0.6382 - val_loss: 0.8254
Epoch 00004: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6544 - val_loss: 0.8687
Epoch 2/20
13s - loss: 0.6467 - val_loss: 0.8440
Epoch 3/20
13s - loss: 0.6449 - val_loss: 0.8658
Epoch 4/20
13s - loss: 0.6434 - val_loss: 0.8099
Epoch 5/20
13s - loss: 0.6419 - val_loss: 0.7974
Epoch 6/20
13s - loss: 0.6401 - val_loss: 0.8849
Epoch 7/20
13s - loss: 0.6388 - val_loss: 0.8173
Epoch 8/20
13s - loss: 0.6372 - val_loss: 0.8127
Epoch 9/20
13s - loss: 0.6361 - val_loss: 0.8258
Epoch 00008: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6497 - val_loss: 0.7831
Epoch 2/20
13s - loss: 0.6379 - val_loss: 0.8253
Epoch 3/20
13s - loss: 0.6340 - val_loss: 0.8649
Epoch 4/20
13s - loss: 0.6308 - val_loss: 0.8428
Epoch 5/20
13s - loss: 0.6287 - val_loss: 0.7973
Epoch 00004: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6617 - val_loss: 0.8432
Epoch 2/20
13s - loss: 0.6527 - val_loss: 0.8387
Epoch 3/20
13s - loss: 0.6504 - val_loss: 0.8718
Epoch 4/20
13s - loss: 0.6492 - val_loss: 0.8258
Epoch 5/20
13s - loss: 0.6480 - val_loss: 0.8439
Epoch 6/20
13s - loss: 0.6468 - val_loss: 0.8392
Epoch 7/20
13s - loss: 0.6462 - val_loss: 0.8382
Epoch 8/20
13s - loss: 0.6448 - val_loss: 0.8716
Epoch 00007: early stopping
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6516 - val_loss: 0.8833
Epoch 2/20
13s - loss: 0.6435 - val_loss: 0.8068
Epoch 3/20
13s - loss: 0.6406 - val_loss: 0.8220
Epoch 4/20
13s - loss: 0.6391 - val_loss: 0.8428
Epoch 5/20
13s - loss: 0.6370 - val_loss: 0.8452
Epoch 6/20
13s - loss: 0.6358 - val_loss: 0.8932
Epoch 00005: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6700 - val_loss: 0.8354
Epoch 2/20
13s - loss: 0.6645 - val_loss: 0.8726
Epoch 3/20
13s - loss: 0.6635 - val_loss: 0.8502
Epoch 4/20
13s - loss: 0.6633 - val_loss: 0.8756
Epoch 5/20
13s - loss: 0.6624 - val_loss: 0.8707
Epoch 00004: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6761 - val_loss: 0.8900
Epoch 2/20
13s - loss: 0.6680 - val_loss: 0.8646
Epoch 3/20
13s - loss: 0.6664 - val_loss: 0.8766
Epoch 4/20
13s - loss: 0.6660 - val_loss: 0.8677
Epoch 5/20
13s - loss: 0.6649 - val_loss: 0.8875
Epoch 6/20
13s - loss: 0.6638 - val_loss: 0.8647
Epoch 00005: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6545 - val_loss: 0.8217
Epoch 2/20
13s - loss: 0.6407 - val_loss: 0.8054
Epoch 3/20
13s - loss: 0.6361 - val_loss: 0.8736
Epoch 4/20
13s - loss: 0.6335 - val_loss: 0.8154
Epoch 5/20
13s - loss: 0.6311 - val_loss: 0.8362
Epoch 6/20
13s - loss: 0.6293 - val_loss: 0.8186
Epoch 00005: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6767 - val_loss: 0.8764
Epoch 2/20
13s - loss: 0.6712 - val_loss: 0.8293
Epoch 3/20
13s - loss: 0.6701 - val_loss: 0.8635
Epoch 4/20
13s - loss: 0.6694 - val_loss: 0.8502
Epoch 5/20
13s - loss: 0.6688 - val_loss: 0.8553
Epoch 6/20
13s - loss: 0.6680 - val_loss: 0.8629
Epoch 00005: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6587 - val_loss: 0.8387
Epoch 2/20
13s - loss: 0.6491 - val_loss: 0.8447
Epoch 3/20
13s - loss: 0.6463 - val_loss: 0.8283
Epoch 4/20
13s - loss: 0.6441 - val_loss: 0.8488
Epoch 5/20
13s - loss: 0.6429 - val_loss: 0.8261
Epoch 6/20
13s - loss: 0.6412 - val_loss: 0.8925
Epoch 7/20
13s - loss: 0.6397 - val_loss: 0.8984
Epoch 8/20
13s - loss: 0.6381 - val_loss: 0.8243
Epoch 9/20
13s - loss: 0.6368 - val_loss: 0.8563
Epoch 10/20
13s - loss: 0.6350 - val_loss: 0.8045
Epoch 11/20
13s - loss: 0.6334 - val_loss: 0.8208
Epoch 12/20
13s - loss: 0.6313 - val_loss: 0.8254
Epoch 13/20
13s - loss: 0.6300 - val_loss: 0.8138
Epoch 14/20
13s - loss: 0.6282 - val_loss: 0.8882
Epoch 00013: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6787 - val_loss: 0.8407
Epoch 2/20
13s - loss: 0.6712 - val_loss: 0.8435
Epoch 3/20
13s - loss: 0.6694 - val_loss: 0.8702
Epoch 4/20
13s - loss: 0.6687 - val_loss: 0.8237
Epoch 5/20
13s - loss: 0.6683 - val_loss: 0.8441
Epoch 6/20
13s - loss: 0.6674 - val_loss: 0.8637
Epoch 7/20
13s - loss: 0.6669 - val_loss: 0.8860
Epoch 8/20
13s - loss: 0.6659 - val_loss: 0.8483
Epoch 00007: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6506 - val_loss: 0.8503
Epoch 2/20
13s - loss: 0.6392 - val_loss: 0.8375
Epoch 3/20
13s - loss: 0.6351 - val_loss: 0.8304
Epoch 4/20
13s - loss: 0.6331 - val_loss: 0.7557
Epoch 5/20
13s - loss: 0.6316 - val_loss: 0.8192
Epoch 6/20
13s - loss: 0.6303 - val_loss: 0.8707
Epoch 7/20
13s - loss: 0.6292 - val_loss: 0.8126
Epoch 8/20
13s - loss: 0.6285 - val_loss: 0.8327
Epoch 00007: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6588 - val_loss: 0.8590
Epoch 2/20
13s - loss: 0.6499 - val_loss: 0.7745
Epoch 3/20
13s - loss: 0.6476 - val_loss: 0.8230
Epoch 4/20
13s - loss: 0.6461 - val_loss: 0.8218
Epoch 5/20
13s - loss: 0.6449 - val_loss: 0.8419
Epoch 6/20
13s - loss: 0.6433 - val_loss: 0.8818
Epoch 00005: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6603 - val_loss: 0.8289
Epoch 2/20
13s - loss: 0.6518 - val_loss: 0.8279
Epoch 3/20
13s - loss: 0.6496 - val_loss: 0.8130
Epoch 4/20
13s - loss: 0.6486 - val_loss: 0.8131
Epoch 5/20
13s - loss: 0.6474 - val_loss: 0.8482
Epoch 6/20
13s - loss: 0.6468 - val_loss: 0.8184
Epoch 7/20
13s - loss: 0.6452 - val_loss: 0.8688
Epoch 00006: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.34217722e+08,  -0.00000000e+00]), 'nit': 2, 'funcalls': 33}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  5.03316540e+07,  -1.03432887e-16]), 'nit': 4, 'funcalls': 97}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-16777210.00035166,        -0.        ]), 'nit': 4, 'funcalls': 58}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  5.99313522e+000,  -6.62000977e-217]), 'nit': 0, 'funcalls': 21}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 809962.79505443,  -11679.14651207]), 'nit': 1, 'funcalls': 29}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-33554426.00038227,        -0.        ]), 'nit': 3, 'funcalls': 59}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 67108869.99965738,        -0.        ]), 'nit': 3, 'funcalls': 54}
  " state: %s" % convergence_dict)
Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   2

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-13 03:54:30.153991: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 03:54:30.156192: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 03:54:30.156201: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 03:54:30.156205: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 03:54:30.156209: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 03:54:30.448108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-13 03:54:30.448142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-13 03:54:30.448147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-13 03:54:30.448155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
13s - loss: 0.6703 - val_loss: 0.8773
Epoch 2/20
11s - loss: 0.6643 - val_loss: 0.8363
Epoch 3/20
11s - loss: 0.6634 - val_loss: 0.9171
Epoch 4/20
11s - loss: 0.6625 - val_loss: 0.8629
Epoch 5/20
11s - loss: 0.6612 - val_loss: 0.8582
Epoch 6/20
11s - loss: 0.6604 - val_loss: 0.8589
Epoch 00005: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
11s - loss: 0.6355 - val_loss: 0.7982
Epoch 2/20
11s - loss: 0.6222 - val_loss: 0.7810
Epoch 3/20
11s - loss: 0.6177 - val_loss: 0.7698
Epoch 4/20
11s - loss: 0.6152 - val_loss: 0.8011
Epoch 5/20
11s - loss: 0.6135 - val_loss: 0.8284
Epoch 6/20
11s - loss: 0.6119 - val_loss: 0.8056
Epoch 7/20
11s - loss: 0.6104 - val_loss: 0.7553
Epoch 8/20
11s - loss: 0.6091 - val_loss: 0.8630
Epoch 9/20
11s - loss: 0.6075 - val_loss: 0.8330
Epoch 10/20
11s - loss: 0.6062 - val_loss: 0.8122
Epoch 11/20
11s - loss: 0.6050 - val_loss: 0.8005
Epoch 00010: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6312 - val_loss: 0.7820
Epoch 2/20
11s - loss: 0.6123 - val_loss: 0.7768
Epoch 3/20
11s - loss: 0.6072 - val_loss: 0.7482
Epoch 4/20
11s - loss: 0.6045 - val_loss: 0.7440
Epoch 5/20
11s - loss: 0.6018 - val_loss: 0.7192
Epoch 6/20
11s - loss: 0.6000 - val_loss: 0.8246
Epoch 7/20
11s - loss: 0.5972 - val_loss: 0.8665
Epoch 8/20
11s - loss: 0.5951 - val_loss: 0.8060
Epoch 9/20
11s - loss: 0.5937 - val_loss: 0.7678
Epoch 00008: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6116 - val_loss: 0.7844
Epoch 2/20
11s - loss: 0.5976 - val_loss: 0.7670
Epoch 3/20
11s - loss: 0.5937 - val_loss: 0.7484
Epoch 4/20
11s - loss: 0.5922 - val_loss: 0.7058
Epoch 5/20
11s - loss: 0.5902 - val_loss: 0.8036
Epoch 6/20
11s - loss: 0.5893 - val_loss: 0.7464
Epoch 7/20
11s - loss: 0.5879 - val_loss: 0.8021
Epoch 8/20
11s - loss: 0.5865 - val_loss: 0.7103
Epoch 00007: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6676 - val_loss: 0.8141
Epoch 2/20
11s - loss: 0.6616 - val_loss: 0.8222
Epoch 3/20
11s - loss: 0.6606 - val_loss: 0.8760
Epoch 4/20
11s - loss: 0.6602 - val_loss: 0.8598
Epoch 5/20
11s - loss: 0.6595 - val_loss: 0.8455
Epoch 00004: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6578 - val_loss: 0.8366
Epoch 2/20
11s - loss: 0.6487 - val_loss: 0.8001
Epoch 3/20
11s - loss: 0.6461 - val_loss: 0.8174
Epoch 4/20
11s - loss: 0.6450 - val_loss: 0.7422
Epoch 5/20
11s - loss: 0.6433 - val_loss: 0.8365
Epoch 6/20
11s - loss: 0.6417 - val_loss: 0.7705
Epoch 7/20
11s - loss: 0.6403 - val_loss: 0.8159
Epoch 8/20
11s - loss: 0.6394 - val_loss: 0.8367
Epoch 00007: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6621 - val_loss: 0.8563
Epoch 2/20
11s - loss: 0.6527 - val_loss: 0.8379
Epoch 3/20
11s - loss: 0.6499 - val_loss: 0.8613
Epoch 4/20
11s - loss: 0.6489 - val_loss: 0.8244
Epoch 5/20
11s - loss: 0.6473 - val_loss: 0.8378
Epoch 6/20
11s - loss: 0.6460 - val_loss: 0.8544
Epoch 7/20
11s - loss: 0.6448 - val_loss: 0.8545
Epoch 8/20
11s - loss: 0.6435 - val_loss: 0.8839
Epoch 00007: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6430 - val_loss: 0.8386
Epoch 2/20
12s - loss: 0.6335 - val_loss: 0.8080
Epoch 3/20
11s - loss: 0.6300 - val_loss: 0.8077
Epoch 4/20
11s - loss: 0.6282 - val_loss: 0.7905
Epoch 5/20
11s - loss: 0.6273 - val_loss: 0.8340
Epoch 6/20
11s - loss: 0.6263 - val_loss: 0.8366
Epoch 7/20
11s - loss: 0.6249 - val_loss: 0.8301
Epoch 8/20
11s - loss: 0.6236 - val_loss: 0.7684
Epoch 9/20
11s - loss: 0.6221 - val_loss: 0.8017
Epoch 10/20
11s - loss: 0.6211 - val_loss: 0.7996
Epoch 11/20
11s - loss: 0.6196 - val_loss: 0.7754
Epoch 12/20
11s - loss: 0.6180 - val_loss: 0.8032
Epoch 00011: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6845 - val_loss: 0.8586
Epoch 2/20
11s - loss: 0.6798 - val_loss: 0.8657
Epoch 3/20
11s - loss: 0.6791 - val_loss: 0.8793
Epoch 4/20
11s - loss: 0.6788 - val_loss: 0.8685
Epoch 5/20
12s - loss: 0.6788 - val_loss: 0.8728
Epoch 00004: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6577 - val_loss: 0.8197
Epoch 2/20
12s - loss: 0.6464 - val_loss: 0.8112
Epoch 3/20
12s - loss: 0.6431 - val_loss: 0.8879
Epoch 4/20
12s - loss: 0.6417 - val_loss: 0.8437
Epoch 5/20
12s - loss: 0.6405 - val_loss: 0.7988
Epoch 6/20
11s - loss: 0.6391 - val_loss: 0.8808
Epoch 7/20
11s - loss: 0.6379 - val_loss: 0.8388
Epoch 8/20
11s - loss: 0.6372 - val_loss: 0.8240
Epoch 9/20
12s - loss: 0.6357 - val_loss: 0.8366
Epoch 00008: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6702 - val_loss: 0.8724
Epoch 2/20
12s - loss: 0.6609 - val_loss: 0.8520
Epoch 3/20
12s - loss: 0.6593 - val_loss: 0.8373
Epoch 4/20
12s - loss: 0.6579 - val_loss: 0.8699
Epoch 5/20
12s - loss: 0.6571 - val_loss: 0.7808
Epoch 6/20
12s - loss: 0.6560 - val_loss: 0.8968
Epoch 7/20
11s - loss: 0.6549 - val_loss: 0.8566
Epoch 8/20
11s - loss: 0.6538 - val_loss: 0.8697
Epoch 9/20
12s - loss: 0.6525 - val_loss: 0.8559
Epoch 00008: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6829 - val_loss: 0.8384
Epoch 2/20
12s - loss: 0.6782 - val_loss: 0.8457
Epoch 3/20
12s - loss: 0.6773 - val_loss: 0.8504
Epoch 4/20
12s - loss: 0.6767 - val_loss: 0.8737
Epoch 5/20
12s - loss: 0.6766 - val_loss: 0.8544
Epoch 00004: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6856 - val_loss: 0.8931
Epoch 2/20
12s - loss: 0.6803 - val_loss: 0.8639
Epoch 3/20
12s - loss: 0.6793 - val_loss: 0.8829
Epoch 4/20
12s - loss: 0.6795 - val_loss: 0.8892
Epoch 5/20
12s - loss: 0.6789 - val_loss: 0.8836
Epoch 6/20
12s - loss: 0.6789 - val_loss: 0.8893
Epoch 00005: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6650 - val_loss: 0.8369
Epoch 2/20
12s - loss: 0.6556 - val_loss: 0.7934
Epoch 3/20
12s - loss: 0.6533 - val_loss: 0.8734
Epoch 4/20
12s - loss: 0.6523 - val_loss: 0.8539
Epoch 5/20
12s - loss: 0.6515 - val_loss: 0.8121
Epoch 6/20
12s - loss: 0.6508 - val_loss: 0.8417
Epoch 00005: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6567 - val_loss: 0.8772
Epoch 2/20
12s - loss: 0.6487 - val_loss: 0.8340
Epoch 3/20
12s - loss: 0.6463 - val_loss: 0.7867
Epoch 4/20
12s - loss: 0.6450 - val_loss: 0.7847
Epoch 5/20
12s - loss: 0.6432 - val_loss: 0.8326
Epoch 6/20
12s - loss: 0.6423 - val_loss: 0.8471
Epoch 7/20
12s - loss: 0.6406 - val_loss: 0.7992
Epoch 8/20
12s - loss: 0.6391 - val_loss: 0.8271
Epoch 00007: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6585 - val_loss: 0.8268
Epoch 2/20
12s - loss: 0.6504 - val_loss: 0.8740
Epoch 3/20
12s - loss: 0.6485 - val_loss: 0.8757
Epoch 4/20
12s - loss: 0.6468 - val_loss: 0.8337
Epoch 5/20
12s - loss: 0.6454 - val_loss: 0.8373
Epoch 00004: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6594 - val_loss: 0.8587
Epoch 2/20
12s - loss: 0.6455 - val_loss: 0.8066
Epoch 3/20
12s - loss: 0.6423 - val_loss: 0.8647
Epoch 4/20
12s - loss: 0.6403 - val_loss: 0.7870
Epoch 5/20
12s - loss: 0.6392 - val_loss: 0.7598
Epoch 6/20
12s - loss: 0.6379 - val_loss: 0.8354
Epoch 7/20
12s - loss: 0.6361 - val_loss: 0.8405
Epoch 8/20
12s - loss: 0.6350 - val_loss: 0.8653
Epoch 9/20
12s - loss: 0.6335 - val_loss: 0.8693
Epoch 00008: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6711 - val_loss: 0.8200
Epoch 2/20
12s - loss: 0.6641 - val_loss: 0.8293
Epoch 3/20
12s - loss: 0.6616 - val_loss: 0.8545
Epoch 4/20
12s - loss: 0.6597 - val_loss: 0.8664
Epoch 5/20
12s - loss: 0.6583 - val_loss: 0.8669
Epoch 00004: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6284 - val_loss: 0.7857
Epoch 2/20
12s - loss: 0.6171 - val_loss: 0.8134
Epoch 3/20
12s - loss: 0.6128 - val_loss: 0.7532
Epoch 4/20
12s - loss: 0.6111 - val_loss: 0.7661
Epoch 5/20
12s - loss: 0.6097 - val_loss: 0.7950
Epoch 6/20
12s - loss: 0.6086 - val_loss: 0.7329
Epoch 7/20
12s - loss: 0.6072 - val_loss: 0.8099
Epoch 8/20
12s - loss: 0.6058 - val_loss: 0.8704
Epoch 9/20
12s - loss: 0.6045 - val_loss: 0.8028
Epoch 10/20
12s - loss: 0.6035 - val_loss: 0.8095
Epoch 00009: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6519 - val_loss: 0.8116
Epoch 2/20
12s - loss: 0.6395 - val_loss: 0.8095
Epoch 3/20
12s - loss: 0.6362 - val_loss: 0.7965
Epoch 4/20
12s - loss: 0.6347 - val_loss: 0.7724
Epoch 5/20
12s - loss: 0.6331 - val_loss: 0.8796
Epoch 6/20
12s - loss: 0.6320 - val_loss: 0.8528
Epoch 7/20
12s - loss: 0.6308 - val_loss: 0.7971
Epoch 8/20
12s - loss: 0.6295 - val_loss: 0.8305
Epoch 00007: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6745 - val_loss: 0.8408
Epoch 2/20
12s - loss: 0.6688 - val_loss: 0.8336
Epoch 3/20
12s - loss: 0.6675 - val_loss: 0.8800
Epoch 4/20
12s - loss: 0.6666 - val_loss: 0.8434
Epoch 5/20
12s - loss: 0.6660 - val_loss: 0.8368
Epoch 6/20
12s - loss: 0.6650 - val_loss: 0.8919
Epoch 00005: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6491 - val_loss: 0.8123
Epoch 2/20
12s - loss: 0.6344 - val_loss: 0.8745
Epoch 3/20
12s - loss: 0.6300 - val_loss: 0.7616
Epoch 4/20
12s - loss: 0.6272 - val_loss: 0.8252
Epoch 5/20
12s - loss: 0.6252 - val_loss: 0.7907
Epoch 6/20
12s - loss: 0.6228 - val_loss: 0.7923
Epoch 7/20
12s - loss: 0.6211 - val_loss: 0.8046
Epoch 00006: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6542 - val_loss: 0.8115
Epoch 2/20
12s - loss: 0.6449 - val_loss: 0.7863
Epoch 3/20
12s - loss: 0.6417 - val_loss: 0.8323
Epoch 4/20
12s - loss: 0.6396 - val_loss: 0.8100
Epoch 5/20
12s - loss: 0.6377 - val_loss: 0.8263
Epoch 6/20
12s - loss: 0.6359 - val_loss: 0.8307
Epoch 00005: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6657 - val_loss: 0.8436
Epoch 2/20
12s - loss: 0.6601 - val_loss: 0.8418
Epoch 3/20
12s - loss: 0.6589 - val_loss: 0.8424
Epoch 4/20
12s - loss: 0.6578 - val_loss: 0.8370
Epoch 5/20
12s - loss: 0.6569 - val_loss: 0.8295
Epoch 6/20
12s - loss: 0.6561 - val_loss: 0.8227
Epoch 7/20
12s - loss: 0.6550 - val_loss: 0.8556
Epoch 8/20
12s - loss: 0.6540 - val_loss: 0.8320
Epoch 9/20
12s - loss: 0.6528 - val_loss: 0.8361
Epoch 10/20
12s - loss: 0.6517 - val_loss: 0.8308
Epoch 00009: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6672 - val_loss: 0.8488
Epoch 2/20
12s - loss: 0.6602 - val_loss: 0.8572
Epoch 3/20
12s - loss: 0.6585 - val_loss: 0.8687
Epoch 4/20
12s - loss: 0.6579 - val_loss: 0.8351
Epoch 5/20
12s - loss: 0.6564 - val_loss: 0.8437
Epoch 6/20
12s - loss: 0.6555 - val_loss: 0.8431
Epoch 7/20
12s - loss: 0.6544 - val_loss: 0.8156
Epoch 8/20
12s - loss: 0.6534 - val_loss: 0.8831
Epoch 9/20
12s - loss: 0.6525 - val_loss: 0.8682
Epoch 10/20
12s - loss: 0.6511 - val_loss: 0.8702
Epoch 11/20
12s - loss: 0.6496 - val_loss: 0.8600
Epoch 00010: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6516 - val_loss: 0.8138
Epoch 2/20
12s - loss: 0.6418 - val_loss: 0.8436
Epoch 3/20
12s - loss: 0.6394 - val_loss: 0.8075
Epoch 4/20
12s - loss: 0.6379 - val_loss: 0.8135
Epoch 5/20
12s - loss: 0.6370 - val_loss: 0.8020
Epoch 6/20
12s - loss: 0.6358 - val_loss: 0.8162
Epoch 7/20
12s - loss: 0.6345 - val_loss: 0.8432
Epoch 8/20
12s - loss: 0.6333 - val_loss: 0.7734
Epoch 9/20
12s - loss: 0.6319 - val_loss: 0.8117
Epoch 10/20
12s - loss: 0.6305 - val_loss: 0.7794
Epoch 11/20
12s - loss: 0.6294 - val_loss: 0.7955
Epoch 12/20
12s - loss: 0.6280 - val_loss: 0.8450
Epoch 00011: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6846 - val_loss: 0.8702
Epoch 2/20
12s - loss: 0.6791 - val_loss: 0.9007
Epoch 3/20
12s - loss: 0.6780 - val_loss: 0.8641
Epoch 4/20
12s - loss: 0.6775 - val_loss: 0.8749
Epoch 5/20
12s - loss: 0.6772 - val_loss: 0.8769
Epoch 6/20
12s - loss: 0.6766 - val_loss: 0.8765
Epoch 7/20
12s - loss: 0.6763 - val_loss: 0.8762
Epoch 00006: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6513 - val_loss: 0.8421
Epoch 2/20
12s - loss: 0.6371 - val_loss: 0.8138
Epoch 3/20
12s - loss: 0.6330 - val_loss: 0.8186
Epoch 4/20
12s - loss: 0.6304 - val_loss: 0.8898
Epoch 5/20
12s - loss: 0.6287 - val_loss: 0.8248
Epoch 6/20
12s - loss: 0.6271 - val_loss: 0.8025
Epoch 7/20
12s - loss: 0.6252 - val_loss: 0.8063
Epoch 8/20
12s - loss: 0.6237 - val_loss: 0.8572
Epoch 9/20
12s - loss: 0.6219 - val_loss: 0.8211
Epoch 10/20
12s - loss: 0.6208 - val_loss: 0.7469
Epoch 11/20
12s - loss: 0.6188 - val_loss: 0.7925
Epoch 12/20
12s - loss: 0.6175 - val_loss: 0.7783
Epoch 13/20
12s - loss: 0.6155 - val_loss: 0.7756
Epoch 14/20
12s - loss: 0.6135 - val_loss: 0.8308
Epoch 00013: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6781 - val_loss: 0.8487
Epoch 2/20
12s - loss: 0.6719 - val_loss: 0.8574
Epoch 3/20
12s - loss: 0.6703 - val_loss: 0.8943
Epoch 4/20
12s - loss: 0.6696 - val_loss: 0.8441
Epoch 5/20
12s - loss: 0.6690 - val_loss: 0.8416
Epoch 6/20
12s - loss: 0.6679 - val_loss: 0.9012
Epoch 7/20
12s - loss: 0.6674 - val_loss: 0.8706
Epoch 8/20
12s - loss: 0.6662 - val_loss: 0.8485
Epoch 9/20
12s - loss: 0.6654 - val_loss: 0.8590
Epoch 00008: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6342 - val_loss: 0.7970
Epoch 2/20
12s - loss: 0.6230 - val_loss: 0.8042
Epoch 3/20
12s - loss: 0.6201 - val_loss: 0.7846
Epoch 4/20
12s - loss: 0.6180 - val_loss: 0.7787
Epoch 5/20
12s - loss: 0.6170 - val_loss: 0.7702
Epoch 6/20
12s - loss: 0.6156 - val_loss: 0.7644
Epoch 7/20
12s - loss: 0.6148 - val_loss: 0.8179
Epoch 8/20
12s - loss: 0.6134 - val_loss: 0.8016
Epoch 9/20
12s - loss: 0.6121 - val_loss: 0.7686
Epoch 10/20
12s - loss: 0.6108 - val_loss: 0.7828
Epoch 00009: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6681 - val_loss: 0.8398
Epoch 2/20
12s - loss: 0.6586 - val_loss: 0.8437
Epoch 3/20
12s - loss: 0.6549 - val_loss: 0.8445
Epoch 4/20
12s - loss: 0.6530 - val_loss: 0.8409
Epoch 5/20
12s - loss: 0.6509 - val_loss: 0.9062
Epoch 00004: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6505 - val_loss: 0.8199
Epoch 2/20
12s - loss: 0.6391 - val_loss: 0.8339
Epoch 3/20
12s - loss: 0.6351 - val_loss: 0.8342
Epoch 4/20
12s - loss: 0.6324 - val_loss: 0.8184
Epoch 5/20
12s - loss: 0.6301 - val_loss: 0.8165
Epoch 6/20
12s - loss: 0.6287 - val_loss: 0.7922
Epoch 7/20
12s - loss: 0.6273 - val_loss: 0.8696
Epoch 8/20
12s - loss: 0.6253 - val_loss: 0.8074
Epoch 9/20
12s - loss: 0.6241 - val_loss: 0.8478
Epoch 10/20
12s - loss: 0.6225 - val_loss: 0.8104
Epoch 00009: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6732 - val_loss: 0.8584
Epoch 2/20
12s - loss: 0.6658 - val_loss: 0.8618
Epoch 3/20
12s - loss: 0.6642 - val_loss: 0.8520
Epoch 4/20
12s - loss: 0.6627 - val_loss: 0.8872
Epoch 5/20
12s - loss: 0.6615 - val_loss: 0.8611
Epoch 6/20
12s - loss: 0.6596 - val_loss: 0.9226
Epoch 7/20
12s - loss: 0.6585 - val_loss: 0.8332
Epoch 8/20
12s - loss: 0.6566 - val_loss: 0.8785
Epoch 9/20
12s - loss: 0.6548 - val_loss: 0.8956
Epoch 10/20
12s - loss: 0.6533 - val_loss: 0.8597
Epoch 11/20
12s - loss: 0.6516 - val_loss: 0.8873
Epoch 00010: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6606 - val_loss: 0.8319
Epoch 2/20
12s - loss: 0.6523 - val_loss: 0.8141
Epoch 3/20
12s - loss: 0.6504 - val_loss: 0.8173
Epoch 4/20
12s - loss: 0.6491 - val_loss: 0.8444
Epoch 5/20
12s - loss: 0.6482 - val_loss: 0.8693
Epoch 6/20
12s - loss: 0.6473 - val_loss: 0.8256
Epoch 00005: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6379 - val_loss: 0.7724
Epoch 2/20
12s - loss: 0.6249 - val_loss: 0.7825
Epoch 3/20
12s - loss: 0.6212 - val_loss: 0.8168
Epoch 4/20
12s - loss: 0.6191 - val_loss: 0.7152
Epoch 5/20
12s - loss: 0.6180 - val_loss: 0.8023
Epoch 6/20
12s - loss: 0.6165 - val_loss: 0.7518
Epoch 7/20
12s - loss: 0.6156 - val_loss: 0.8101
Epoch 8/20
12s - loss: 0.6142 - val_loss: 0.7237
Epoch 00007: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6604 - val_loss: 0.8297
Epoch 2/20
12s - loss: 0.6492 - val_loss: 0.7912
Epoch 3/20
12s - loss: 0.6458 - val_loss: 0.8343
Epoch 4/20
12s - loss: 0.6448 - val_loss: 0.8274
Epoch 5/20
12s - loss: 0.6435 - val_loss: 0.7990
Epoch 6/20
12s - loss: 0.6423 - val_loss: 0.8552
Epoch 00005: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6545 - val_loss: 0.8479
Epoch 2/20
12s - loss: 0.6464 - val_loss: 0.7792
Epoch 3/20
12s - loss: 0.6433 - val_loss: 0.7635
Epoch 4/20
12s - loss: 0.6406 - val_loss: 0.8017
Epoch 5/20
12s - loss: 0.6384 - val_loss: 0.8127
Epoch 6/20
12s - loss: 0.6369 - val_loss: 0.8312
Epoch 7/20
12s - loss: 0.6346 - val_loss: 0.8464
Epoch 00006: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6617 - val_loss: 0.8683
Epoch 2/20
12s - loss: 0.6539 - val_loss: 0.8653
Epoch 3/20
12s - loss: 0.6511 - val_loss: 0.8669
Epoch 4/20
12s - loss: 0.6489 - val_loss: 0.8233
Epoch 5/20
12s - loss: 0.6470 - val_loss: 0.8365
Epoch 6/20
12s - loss: 0.6450 - val_loss: 0.8402
Epoch 7/20
12s - loss: 0.6433 - val_loss: 0.8414
Epoch 8/20
12s - loss: 0.6418 - val_loss: 0.8213
Epoch 9/20
12s - loss: 0.6399 - val_loss: 0.8422
Epoch 10/20
12s - loss: 0.6383 - val_loss: 0.8714
Epoch 11/20
12s - loss: 0.6369 - val_loss: 0.8205
Epoch 12/20
12s - loss: 0.6350 - val_loss: 0.8311
Epoch 13/20
12s - loss: 0.6333 - val_loss: 0.8441
Epoch 14/20
12s - loss: 0.6315 - val_loss: 0.8364
Epoch 15/20
12s - loss: 0.6297 - val_loss: 0.8563
Epoch 00014: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6515 - val_loss: 0.8236
Epoch 2/20
12s - loss: 0.6379 - val_loss: 0.7933
Epoch 3/20
12s - loss: 0.6349 - val_loss: 0.7904
Epoch 4/20
12s - loss: 0.6328 - val_loss: 0.7881
Epoch 5/20
12s - loss: 0.6312 - val_loss: 0.8084
Epoch 6/20
12s - loss: 0.6294 - val_loss: 0.8369
Epoch 7/20
12s - loss: 0.6278 - val_loss: 0.8224
Epoch 8/20
12s - loss: 0.6263 - val_loss: 0.7991
Epoch 00007: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6847 - val_loss: 0.8810
Epoch 2/20
12s - loss: 0.6799 - val_loss: 0.8949
Epoch 3/20
12s - loss: 0.6789 - val_loss: 0.8581
Epoch 4/20
12s - loss: 0.6785 - val_loss: 0.8728
Epoch 5/20
12s - loss: 0.6784 - val_loss: 0.8599
Epoch 6/20
12s - loss: 0.6779 - val_loss: 0.8883
Epoch 7/20
12s - loss: 0.6776 - val_loss: 0.9222
Epoch 00006: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
12s - loss: 0.6472 - val_loss: 0.8007
Epoch 2/20
12s - loss: 0.6386 - val_loss: 0.8142
Epoch 3/20
12s - loss: 0.6358 - val_loss: 0.8648
Epoch 4/20
12s - loss: 0.6332 - val_loss: 0.8739
Epoch 5/20
12s - loss: 0.6320 - val_loss: 0.8309
Epoch 00004: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6693 - val_loss: 0.8550
Epoch 2/20
12s - loss: 0.6601 - val_loss: 0.8673
Epoch 3/20
12s - loss: 0.6580 - val_loss: 0.8391
Epoch 4/20
12s - loss: 0.6565 - val_loss: 0.8615
Epoch 5/20
12s - loss: 0.6556 - val_loss: 0.8296
Epoch 6/20
12s - loss: 0.6544 - val_loss: 0.9129
Epoch 7/20
12s - loss: 0.6533 - val_loss: 0.8234
Epoch 8/20
12s - loss: 0.6520 - val_loss: 0.8370
Epoch 9/20
12s - loss: 0.6513 - val_loss: 0.8479
Epoch 10/20
12s - loss: 0.6505 - val_loss: 0.7979
Epoch 11/20
12s - loss: 0.6490 - val_loss: 0.9038
Epoch 12/20
12s - loss: 0.6473 - val_loss: 0.8318
Epoch 13/20
12s - loss: 0.6461 - val_loss: 0.8774
Epoch 14/20
12s - loss: 0.6447 - val_loss: 0.8217
Epoch 00013: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6611 - val_loss: 0.8912
Epoch 2/20
12s - loss: 0.6507 - val_loss: 0.8591
Epoch 3/20
12s - loss: 0.6484 - val_loss: 0.7774
Epoch 4/20
12s - loss: 0.6466 - val_loss: 0.8160
Epoch 5/20
12s - loss: 0.6450 - val_loss: 0.8798
Epoch 6/20
12s - loss: 0.6437 - val_loss: 0.8356
Epoch 7/20
12s - loss: 0.6423 - val_loss: 0.7679
Epoch 8/20
12s - loss: 0.6409 - val_loss: 0.7559
Epoch 9/20
12s - loss: 0.6395 - val_loss: 0.7938
Epoch 10/20
12s - loss: 0.6378 - val_loss: 0.8709
Epoch 11/20
12s - loss: 0.6365 - val_loss: 0.8686
Epoch 12/20
12s - loss: 0.6348 - val_loss: 0.8198
Epoch 00011: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6585 - val_loss: 0.8237
Epoch 2/20
12s - loss: 0.6507 - val_loss: 0.8492
Epoch 3/20
12s - loss: 0.6487 - val_loss: 0.8596
Epoch 4/20
12s - loss: 0.6482 - val_loss: 0.7857
Epoch 5/20
12s - loss: 0.6470 - val_loss: 0.7795
Epoch 6/20
12s - loss: 0.6458 - val_loss: 0.8157
Epoch 7/20
12s - loss: 0.6450 - val_loss: 0.8539
Epoch 8/20
12s - loss: 0.6440 - val_loss: 0.8032
Epoch 9/20
12s - loss: 0.6427 - val_loss: 0.8182
Epoch 00008: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6581 - val_loss: 0.8361
Epoch 2/20
12s - loss: 0.6448 - val_loss: 0.8241
Epoch 3/20
12s - loss: 0.6412 - val_loss: 0.8003
Epoch 4/20
12s - loss: 0.6390 - val_loss: 0.8588
Epoch 5/20
12s - loss: 0.6372 - val_loss: 0.8207
Epoch 6/20
12s - loss: 0.6353 - val_loss: 0.7753
Epoch 7/20
12s - loss: 0.6339 - val_loss: 0.8044
Epoch 8/20
12s - loss: 0.6323 - val_loss: 0.8613
Epoch 9/20
12s - loss: 0.6308 - val_loss: 0.8197
Epoch 10/20
12s - loss: 0.6293 - val_loss: 0.8326
Epoch 00009: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6499 - val_loss: 0.8763
Epoch 2/20
12s - loss: 0.6404 - val_loss: 0.8252
Epoch 3/20
12s - loss: 0.6368 - val_loss: 0.8430
Epoch 4/20
12s - loss: 0.6349 - val_loss: 0.8171
Epoch 5/20
12s - loss: 0.6331 - val_loss: 0.8210
Epoch 6/20
12s - loss: 0.6311 - val_loss: 0.7614
Epoch 7/20
12s - loss: 0.6300 - val_loss: 0.8018
Epoch 8/20
12s - loss: 0.6287 - val_loss: 0.8016
Epoch 9/20
12s - loss: 0.6271 - val_loss: 0.8058
Epoch 10/20
12s - loss: 0.6255 - val_loss: 0.7976
Epoch 00009: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6740 - val_loss: 0.9079
Epoch 2/20
12s - loss: 0.6685 - val_loss: 0.8418
Epoch 3/20
12s - loss: 0.6677 - val_loss: 0.8437
Epoch 4/20
12s - loss: 0.6670 - val_loss: 0.8534
Epoch 5/20
12s - loss: 0.6659 - val_loss: 0.8519
Epoch 6/20
12s - loss: 0.6650 - val_loss: 0.8675
Epoch 00005: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6667 - val_loss: 0.8276
Epoch 2/20
12s - loss: 0.6614 - val_loss: 0.8555
Epoch 3/20
12s - loss: 0.6604 - val_loss: 0.8830
Epoch 4/20
12s - loss: 0.6597 - val_loss: 0.8362
Epoch 5/20
12s - loss: 0.6590 - val_loss: 0.8759
Epoch 00004: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6820 - val_loss: 0.8692
Epoch 2/20
12s - loss: 0.6763 - val_loss: 0.8688
Epoch 3/20
12s - loss: 0.6751 - val_loss: 0.8601
Epoch 4/20
12s - loss: 0.6742 - val_loss: 0.8480
Epoch 5/20
12s - loss: 0.6739 - val_loss: 0.8651
Epoch 6/20
12s - loss: 0.6730 - val_loss: 0.8563
Epoch 7/20
12s - loss: 0.6725 - val_loss: 0.8801
Epoch 8/20
12s - loss: 0.6715 - val_loss: 0.8533
Epoch 00007: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6616 - val_loss: 0.8460
Epoch 2/20
12s - loss: 0.6553 - val_loss: 0.8667
Epoch 3/20
12s - loss: 0.6535 - val_loss: 0.8718
Epoch 4/20
12s - loss: 0.6526 - val_loss: 0.8580
Epoch 5/20
12s - loss: 0.6518 - val_loss: 0.8260
Epoch 6/20
12s - loss: 0.6509 - val_loss: 0.8501
Epoch 7/20
12s - loss: 0.6496 - val_loss: 0.8287
Epoch 8/20
12s - loss: 0.6490 - val_loss: 0.8478
Epoch 9/20
12s - loss: 0.6479 - val_loss: 0.8283
Epoch 00008: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6757 - val_loss: 0.8745
Epoch 2/20
12s - loss: 0.6685 - val_loss: 0.8428
Epoch 3/20
12s - loss: 0.6671 - val_loss: 0.8711
Epoch 4/20
12s - loss: 0.6664 - val_loss: 0.8426
Epoch 5/20
12s - loss: 0.6654 - val_loss: 0.8845
Epoch 6/20
12s - loss: 0.6647 - val_loss: 0.9295
Epoch 7/20
12s - loss: 0.6641 - val_loss: 0.8990
Epoch 8/20
12s - loss: 0.6630 - val_loss: 0.8820
Epoch 00007: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6678 - val_loss: 0.8394
Epoch 2/20
12s - loss: 0.6601 - val_loss: 0.8557
Epoch 3/20
12s - loss: 0.6578 - val_loss: 0.8502
Epoch 4/20
12s - loss: 0.6565 - val_loss: 0.8505
Epoch 5/20
12s - loss: 0.6558 - val_loss: 0.8584
Epoch 00004: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6487 - val_loss: 0.7984
Epoch 2/20
12s - loss: 0.6375 - val_loss: 0.8444
Epoch 3/20
12s - loss: 0.6330 - val_loss: 0.8183
Epoch 4/20
12s - loss: 0.6300 - val_loss: 0.8159
Epoch 5/20
12s - loss: 0.6277 - val_loss: 0.7812
Epoch 6/20
12s - loss: 0.6259 - val_loss: 0.8269
Epoch 7/20
12s - loss: 0.6248 - val_loss: 0.8218
Epoch 8/20
12s - loss: 0.6231 - val_loss: 0.8204
Epoch 9/20
12s - loss: 0.6214 - val_loss: 0.8554
Epoch 00008: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6455 - val_loss: 0.8471
Epoch 2/20
12s - loss: 0.6350 - val_loss: 0.8202
Epoch 3/20
12s - loss: 0.6309 - val_loss: 0.7767
Epoch 4/20
12s - loss: 0.6283 - val_loss: 0.7977
Epoch 5/20
12s - loss: 0.6266 - val_loss: 0.8178
Epoch 6/20
12s - loss: 0.6246 - val_loss: 0.7805
Epoch 7/20
12s - loss: 0.6229 - val_loss: 0.8766
Epoch 00006: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6808 - val_loss: 0.8621
Epoch 2/20
12s - loss: 0.6750 - val_loss: 0.8714
Epoch 3/20
12s - loss: 0.6735 - val_loss: 0.8829
Epoch 4/20
12s - loss: 0.6728 - val_loss: 0.8831
Epoch 5/20
12s - loss: 0.6722 - val_loss: 0.8654
Epoch 00004: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6633 - val_loss: 0.7800
Epoch 2/20
12s - loss: 0.6550 - val_loss: 0.8419
Epoch 3/20
12s - loss: 0.6526 - val_loss: 0.8426
Epoch 4/20
12s - loss: 0.6496 - val_loss: 0.8228
Epoch 5/20
12s - loss: 0.6477 - val_loss: 0.8507
Epoch 00004: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6635 - val_loss: 0.7987
Epoch 2/20
12s - loss: 0.6525 - val_loss: 0.8943
Epoch 3/20
12s - loss: 0.6482 - val_loss: 0.8329
Epoch 4/20
12s - loss: 0.6458 - val_loss: 0.8314
Epoch 5/20
12s - loss: 0.6436 - val_loss: 0.8341
Epoch 00004: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6588 - val_loss: 0.8312
Epoch 2/20
12s - loss: 0.6507 - val_loss: 0.8389
Epoch 3/20
12s - loss: 0.6482 - val_loss: 0.7826
Epoch 4/20
12s - loss: 0.6467 - val_loss: 0.8193
Epoch 5/20
12s - loss: 0.6455 - val_loss: 0.8489
Epoch 6/20
12s - loss: 0.6443 - val_loss: 0.8321
Epoch 7/20
12s - loss: 0.6431 - val_loss: 0.8068
Epoch 00006: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6593 - val_loss: 0.8066
Epoch 2/20
12s - loss: 0.6531 - val_loss: 0.8708
Epoch 3/20
12s - loss: 0.6513 - val_loss: 0.8770
Epoch 4/20
12s - loss: 0.6503 - val_loss: 0.8261
Epoch 5/20
12s - loss: 0.6496 - val_loss: 0.8651
Epoch 00004: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6620 - val_loss: 0.8665
Epoch 2/20
12s - loss: 0.6542 - val_loss: 0.8668
Epoch 3/20
12s - loss: 0.6512 - val_loss: 0.8209
Epoch 4/20
12s - loss: 0.6489 - val_loss: 0.8267
Epoch 5/20
12s - loss: 0.6466 - val_loss: 0.8311
Epoch 6/20
12s - loss: 0.6445 - val_loss: 0.8579
Epoch 7/20
12s - loss: 0.6432 - val_loss: 0.8629
Epoch 00006: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6555 - val_loss: 0.8216
Epoch 2/20
12s - loss: 0.6456 - val_loss: 0.8940
Epoch 3/20
12s - loss: 0.6413 - val_loss: 0.8240
Epoch 4/20
12s - loss: 0.6386 - val_loss: 0.8434
Epoch 5/20
12s - loss: 0.6368 - val_loss: 0.8433
Epoch 00004: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6614 - val_loss: 0.8440
Epoch 2/20
12s - loss: 0.6530 - val_loss: 0.8661
Epoch 3/20
12s - loss: 0.6502 - val_loss: 0.8540
Epoch 4/20
12s - loss: 0.6485 - val_loss: 0.8231
Epoch 5/20
12s - loss: 0.6471 - val_loss: 0.8084
Epoch 6/20
12s - loss: 0.6455 - val_loss: 0.8205
Epoch 7/20
12s - loss: 0.6442 - val_loss: 0.8776
Epoch 8/20
12s - loss: 0.6432 - val_loss: 0.8318
Epoch 9/20
12s - loss: 0.6418 - val_loss: 0.8321
Epoch 00008: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6798 - val_loss: 0.8803
Epoch 2/20
12s - loss: 0.6750 - val_loss: 0.8637
Epoch 3/20
12s - loss: 0.6737 - val_loss: 0.9096
Epoch 4/20
12s - loss: 0.6734 - val_loss: 0.8774
Epoch 5/20
12s - loss: 0.6729 - val_loss: 0.8535
Epoch 6/20
12s - loss: 0.6721 - val_loss: 0.8823
Epoch 7/20
12s - loss: 0.6719 - val_loss: 0.8877
Epoch 8/20
12s - loss: 0.6709 - val_loss: 0.8762
Epoch 9/20
12s - loss: 0.6700 - val_loss: 0.8512
Epoch 10/20
12s - loss: 0.6689 - val_loss: 0.8777
Epoch 11/20
12s - loss: 0.6682 - val_loss: 0.8738
Epoch 12/20
12s - loss: 0.6669 - val_loss: 0.8761
Epoch 13/20
12s - loss: 0.6656 - val_loss: 0.9227
Epoch 00012: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6779 - val_loss: 0.8551
Epoch 2/20
12s - loss: 0.6724 - val_loss: 0.8509
Epoch 3/20
12s - loss: 0.6711 - val_loss: 0.8636
Epoch 4/20
12s - loss: 0.6707 - val_loss: 0.8510
Epoch 5/20
12s - loss: 0.6701 - val_loss: 0.8805
Epoch 6/20
12s - loss: 0.6698 - val_loss: 0.8831
Epoch 00005: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6814 - val_loss: 0.8425
Epoch 2/20
12s - loss: 0.6758 - val_loss: 0.8686
Epoch 3/20
12s - loss: 0.6747 - val_loss: 0.8637
Epoch 4/20
12s - loss: 0.6740 - val_loss: 0.9089
Epoch 5/20
12s - loss: 0.6738 - val_loss: 0.8598
Epoch 00004: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6681 - val_loss: 0.8340
Epoch 2/20
12s - loss: 0.6620 - val_loss: 0.8138
Epoch 3/20
12s - loss: 0.6600 - val_loss: 0.8616
Epoch 4/20
12s - loss: 0.6586 - val_loss: 0.8039
Epoch 5/20
12s - loss: 0.6573 - val_loss: 0.8548
Epoch 6/20
12s - loss: 0.6563 - val_loss: 0.8039
Epoch 7/20
12s - loss: 0.6547 - val_loss: 0.8144
Epoch 8/20
12s - loss: 0.6536 - val_loss: 0.9207
Epoch 9/20
12s - loss: 0.6518 - val_loss: 0.9178
Epoch 10/20
12s - loss: 0.6508 - val_loss: 0.9016
Epoch 00009: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6527 - val_loss: 0.7980
Epoch 2/20
12s - loss: 0.6437 - val_loss: 0.7877
Epoch 3/20
12s - loss: 0.6408 - val_loss: 0.8555
Epoch 4/20
12s - loss: 0.6393 - val_loss: 0.8330
Epoch 5/20
12s - loss: 0.6376 - val_loss: 0.7763
Epoch 6/20
12s - loss: 0.6359 - val_loss: 0.8516
Epoch 7/20
12s - loss: 0.6347 - val_loss: 0.8227
Epoch 8/20
12s - loss: 0.6330 - val_loss: 0.8858
Epoch 9/20
12s - loss: 0.6316 - val_loss: 0.7968
Epoch 00008: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6546 - val_loss: 0.7917
Epoch 2/20
12s - loss: 0.6473 - val_loss: 0.8872
Epoch 3/20
12s - loss: 0.6448 - val_loss: 0.8779
Epoch 4/20
12s - loss: 0.6430 - val_loss: 0.8469
Epoch 5/20
12s - loss: 0.6412 - val_loss: 0.8495
Epoch 00004: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6383 - val_loss: 0.8471
Epoch 2/20
12s - loss: 0.6267 - val_loss: 0.8306
Epoch 3/20
12s - loss: 0.6235 - val_loss: 0.8102
Epoch 4/20
12s - loss: 0.6215 - val_loss: 0.7871
Epoch 5/20
12s - loss: 0.6208 - val_loss: 0.8606
Epoch 6/20
12s - loss: 0.6195 - val_loss: 0.7807
Epoch 7/20
12s - loss: 0.6180 - val_loss: 0.7536
Epoch 8/20
12s - loss: 0.6170 - val_loss: 0.7450
Epoch 9/20
12s - loss: 0.6162 - val_loss: 0.7811
Epoch 10/20
12s - loss: 0.6144 - val_loss: 0.7767
Epoch 11/20
12s - loss: 0.6134 - val_loss: 0.8512
Epoch 12/20
12s - loss: 0.6120 - val_loss: 0.8675
Epoch 00011: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6592 - val_loss: 0.8630
Epoch 2/20
12s - loss: 0.6496 - val_loss: 0.8086
Epoch 3/20
12s - loss: 0.6465 - val_loss: 0.8873
Epoch 4/20
12s - loss: 0.6442 - val_loss: 0.8275
Epoch 5/20
12s - loss: 0.6430 - val_loss: 0.8775
Epoch 6/20
12s - loss: 0.6415 - val_loss: 0.8637
Epoch 00005: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6520 - val_loss: 0.8071
Epoch 2/20
12s - loss: 0.6420 - val_loss: 0.8028
Epoch 3/20
12s - loss: 0.6382 - val_loss: 0.8551
Epoch 4/20
12s - loss: 0.6348 - val_loss: 0.8285
Epoch 5/20
12s - loss: 0.6327 - val_loss: 0.7484
Epoch 6/20
12s - loss: 0.6308 - val_loss: 0.8969
Epoch 7/20
12s - loss: 0.6291 - val_loss: 0.7437
Epoch 8/20
12s - loss: 0.6275 - val_loss: 0.8185
Epoch 9/20
12s - loss: 0.6259 - val_loss: 0.8006
Epoch 10/20
12s - loss: 0.6238 - val_loss: 0.8647
Epoch 11/20
12s - loss: 0.6220 - val_loss: 0.8710
Epoch 00010: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6854 - val_loss: 0.8697
Epoch 2/20
12s - loss: 0.6789 - val_loss: 0.8487
Epoch 3/20
12s - loss: 0.6781 - val_loss: 0.8821
Epoch 4/20
12s - loss: 0.6775 - val_loss: 0.8651
Epoch 5/20
12s - loss: 0.6774 - val_loss: 0.8620
Epoch 6/20
12s - loss: 0.6770 - val_loss: 0.8798
Epoch 00005: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6695 - val_loss: 0.8364
Epoch 2/20
13s - loss: 0.6644 - val_loss: 0.8566
Epoch 3/20
12s - loss: 0.6637 - val_loss: 0.8596
Epoch 4/20
13s - loss: 0.6629 - val_loss: 0.8909
Epoch 5/20
12s - loss: 0.6622 - val_loss: 0.8700
Epoch 00004: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6424 - val_loss: 0.8233
Epoch 2/20
13s - loss: 0.6300 - val_loss: 0.8389
Epoch 3/20
13s - loss: 0.6250 - val_loss: 0.7512
Epoch 4/20
13s - loss: 0.6226 - val_loss: 0.7783
Epoch 5/20
13s - loss: 0.6209 - val_loss: 0.7713
Epoch 6/20
13s - loss: 0.6192 - val_loss: 0.7763
Epoch 7/20
12s - loss: 0.6177 - val_loss: 0.8216
Epoch 00006: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6644 - val_loss: 0.8181
Epoch 2/20
13s - loss: 0.6567 - val_loss: 0.8341
Epoch 3/20
13s - loss: 0.6548 - val_loss: 0.8949
Epoch 4/20
13s - loss: 0.6537 - val_loss: 0.8457
Epoch 5/20
13s - loss: 0.6527 - val_loss: 0.8823
Epoch 00004: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6785 - val_loss: 0.9120
Epoch 2/20
13s - loss: 0.6730 - val_loss: 0.8675
Epoch 3/20
13s - loss: 0.6719 - val_loss: 0.8761
Epoch 4/20
13s - loss: 0.6715 - val_loss: 0.8581
Epoch 5/20
13s - loss: 0.6707 - val_loss: 0.8417
Epoch 6/20
13s - loss: 0.6700 - val_loss: 0.8807
Epoch 7/20
13s - loss: 0.6691 - val_loss: 0.8906
Epoch 8/20
13s - loss: 0.6682 - val_loss: 0.8911
Epoch 9/20
13s - loss: 0.6672 - val_loss: 0.8676
Epoch 00008: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6609 - val_loss: 0.8736
Epoch 2/20
13s - loss: 0.6515 - val_loss: 0.8208
Epoch 3/20
13s - loss: 0.6495 - val_loss: 0.8188
Epoch 4/20
13s - loss: 0.6483 - val_loss: 0.8001
Epoch 5/20
13s - loss: 0.6470 - val_loss: 0.8033
Epoch 6/20
13s - loss: 0.6457 - val_loss: 0.8022
Epoch 7/20
13s - loss: 0.6445 - val_loss: 0.8279
Epoch 8/20
13s - loss: 0.6434 - val_loss: 0.8681
Epoch 00007: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6595 - val_loss: 0.7550
Epoch 2/20
13s - loss: 0.6487 - val_loss: 0.7958
Epoch 3/20
13s - loss: 0.6455 - val_loss: 0.8142
Epoch 4/20
13s - loss: 0.6429 - val_loss: 0.8241
Epoch 5/20
13s - loss: 0.6408 - val_loss: 0.8441
Epoch 00004: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6684 - val_loss: 0.8737
Epoch 2/20
13s - loss: 0.6617 - val_loss: 0.8563
Epoch 3/20
13s - loss: 0.6597 - val_loss: 0.8599
Epoch 4/20
13s - loss: 0.6581 - val_loss: 0.8467
Epoch 5/20
13s - loss: 0.6563 - val_loss: 0.8814
Epoch 6/20
13s - loss: 0.6550 - val_loss: 0.8870
Epoch 7/20
13s - loss: 0.6532 - val_loss: 0.9407
Epoch 8/20
13s - loss: 0.6517 - val_loss: 0.8715
Epoch 00007: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6731 - val_loss: 0.8962
Epoch 2/20
13s - loss: 0.6650 - val_loss: 0.8612
Epoch 3/20
13s - loss: 0.6631 - val_loss: 0.8439
Epoch 4/20
13s - loss: 0.6621 - val_loss: 0.8768
Epoch 5/20
13s - loss: 0.6612 - val_loss: 0.8692
Epoch 6/20
13s - loss: 0.6605 - val_loss: 0.9090
Epoch 7/20
13s - loss: 0.6594 - val_loss: 0.8558
Epoch 00006: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6781 - val_loss: 0.8845
Epoch 2/20
13s - loss: 0.6735 - val_loss: 0.8702
Epoch 3/20
13s - loss: 0.6726 - val_loss: 0.8549
Epoch 4/20
13s - loss: 0.6722 - val_loss: 0.8606
Epoch 5/20
13s - loss: 0.6715 - val_loss: 0.8753
Epoch 6/20
13s - loss: 0.6713 - val_loss: 0.8618
Epoch 7/20
13s - loss: 0.6709 - val_loss: 0.8797
Epoch 00006: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6782 - val_loss: 0.8694
Epoch 2/20
13s - loss: 0.6723 - val_loss: 0.8458
Epoch 3/20
13s - loss: 0.6711 - val_loss: 0.9469
Epoch 4/20
13s - loss: 0.6700 - val_loss: 0.8736
Epoch 5/20
13s - loss: 0.6693 - val_loss: 0.8875
Epoch 6/20
13s - loss: 0.6685 - val_loss: 0.8550
Epoch 00005: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6218 - val_loss: 0.7687
Epoch 2/20
13s - loss: 0.6095 - val_loss: 0.7270
Epoch 3/20
13s - loss: 0.6060 - val_loss: 0.7860
Epoch 4/20
13s - loss: 0.6043 - val_loss: 0.7398
Epoch 5/20
13s - loss: 0.6035 - val_loss: 0.7615
Epoch 6/20
13s - loss: 0.6020 - val_loss: 0.7829
Epoch 00005: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6577 - val_loss: 0.8270
Epoch 2/20
13s - loss: 0.6498 - val_loss: 0.8272
Epoch 3/20
13s - loss: 0.6480 - val_loss: 0.8596
Epoch 4/20
13s - loss: 0.6466 - val_loss: 0.8083
Epoch 5/20
13s - loss: 0.6451 - val_loss: 0.8425
Epoch 6/20
13s - loss: 0.6441 - val_loss: 0.8755
Epoch 7/20
13s - loss: 0.6431 - val_loss: 0.8365
Epoch 8/20
13s - loss: 0.6420 - val_loss: 0.8446
Epoch 00007: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6757 - val_loss: 0.8517
Epoch 2/20
13s - loss: 0.6682 - val_loss: 0.8567
Epoch 3/20
13s - loss: 0.6663 - val_loss: 0.8306
Epoch 4/20
13s - loss: 0.6654 - val_loss: 0.8528
Epoch 5/20
13s - loss: 0.6649 - val_loss: 0.8515
Epoch 6/20
13s - loss: 0.6638 - val_loss: 0.8778
Epoch 7/20
13s - loss: 0.6629 - val_loss: 0.8563
Epoch 00006: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6577 - val_loss: 0.8614
Epoch 2/20
13s - loss: 0.6481 - val_loss: 0.8342
Epoch 3/20
13s - loss: 0.6461 - val_loss: 0.8400
Epoch 4/20
13s - loss: 0.6444 - val_loss: 0.8697
Epoch 5/20
13s - loss: 0.6430 - val_loss: 0.8727
Epoch 6/20
13s - loss: 0.6415 - val_loss: 0.7862
Epoch 7/20
13s - loss: 0.6406 - val_loss: 0.8190
Epoch 8/20
13s - loss: 0.6395 - val_loss: 0.9010
Epoch 9/20
13s - loss: 0.6378 - val_loss: 0.8042
Epoch 10/20
13s - loss: 0.6368 - val_loss: 0.8465
Epoch 00009: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6564 - val_loss: 0.8618
Epoch 2/20
13s - loss: 0.6438 - val_loss: 0.8374
Epoch 3/20
13s - loss: 0.6407 - val_loss: 0.8282
Epoch 4/20
13s - loss: 0.6388 - val_loss: 0.8587
Epoch 5/20
13s - loss: 0.6375 - val_loss: 0.8042
Epoch 6/20
13s - loss: 0.6361 - val_loss: 0.7964
Epoch 7/20
13s - loss: 0.6347 - val_loss: 0.7688
Epoch 8/20
13s - loss: 0.6335 - val_loss: 0.7935
Epoch 9/20
13s - loss: 0.6318 - val_loss: 0.8170
Epoch 10/20
13s - loss: 0.6305 - val_loss: 0.8510
Epoch 11/20
13s - loss: 0.6290 - val_loss: 0.8191
Epoch 00010: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6549 - val_loss: 0.8621
Epoch 2/20
13s - loss: 0.6475 - val_loss: 0.8262
Epoch 3/20
13s - loss: 0.6449 - val_loss: 0.8577
Epoch 4/20
13s - loss: 0.6434 - val_loss: 0.8714
Epoch 5/20
13s - loss: 0.6418 - val_loss: 0.8155
Epoch 6/20
13s - loss: 0.6400 - val_loss: 0.7959
Epoch 7/20
13s - loss: 0.6392 - val_loss: 0.7872
Epoch 8/20
13s - loss: 0.6376 - val_loss: 0.8321
Epoch 9/20
13s - loss: 0.6361 - val_loss: 0.8380
Epoch 10/20
13s - loss: 0.6349 - val_loss: 0.8266
Epoch 11/20
13s - loss: 0.6331 - val_loss: 0.8304
Epoch 00010: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6494 - val_loss: 0.8600
Epoch 2/20
13s - loss: 0.6377 - val_loss: 0.8046
Epoch 3/20
13s - loss: 0.6329 - val_loss: 0.8402
Epoch 4/20
13s - loss: 0.6300 - val_loss: 0.7882
Epoch 5/20
13s - loss: 0.6280 - val_loss: 0.7982
Epoch 6/20
13s - loss: 0.6266 - val_loss: 0.8117
Epoch 7/20
13s - loss: 0.6250 - val_loss: 0.8518
Epoch 8/20
13s - loss: 0.6234 - val_loss: 0.7818
Epoch 9/20
13s - loss: 0.6223 - val_loss: 0.8131
Epoch 10/20
13s - loss: 0.6205 - val_loss: 0.8034
Epoch 11/20
13s - loss: 0.6184 - val_loss: 0.8180
Epoch 12/20
13s - loss: 0.6170 - val_loss: 0.8417
Epoch 00011: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6628 - val_loss: 0.8184
Epoch 2/20
13s - loss: 0.6533 - val_loss: 0.8717
Epoch 3/20
13s - loss: 0.6509 - val_loss: 0.8719
Epoch 4/20
13s - loss: 0.6492 - val_loss: 0.7924
Epoch 5/20
13s - loss: 0.6480 - val_loss: 0.8476
Epoch 6/20
13s - loss: 0.6467 - val_loss: 0.8252
Epoch 7/20
13s - loss: 0.6452 - val_loss: 0.8044
Epoch 8/20
13s - loss: 0.6443 - val_loss: 0.8812
Epoch 00007: early stopping
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6526 - val_loss: 0.8694
Epoch 2/20
13s - loss: 0.6438 - val_loss: 0.8394
Epoch 3/20
13s - loss: 0.6409 - val_loss: 0.8309
Epoch 4/20
13s - loss: 0.6394 - val_loss: 0.7879
Epoch 5/20
13s - loss: 0.6375 - val_loss: 0.8413
Epoch 6/20
13s - loss: 0.6360 - val_loss: 0.8462
Epoch 7/20
13s - loss: 0.6346 - val_loss: 0.8406
Epoch 8/20
13s - loss: 0.6329 - val_loss: 0.8236
Epoch 00007: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6706 - val_loss: 0.8581
Epoch 2/20
13s - loss: 0.6653 - val_loss: 0.8724
Epoch 3/20
13s - loss: 0.6640 - val_loss: 0.8425
Epoch 4/20
13s - loss: 0.6631 - val_loss: 0.8333
Epoch 5/20
13s - loss: 0.6621 - val_loss: 0.8924
Epoch 6/20
13s - loss: 0.6613 - val_loss: 0.8860
Epoch 7/20
13s - loss: 0.6604 - val_loss: 0.8543
Epoch 8/20
13s - loss: 0.6595 - val_loss: 0.8836
Epoch 00007: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6757 - val_loss: 0.8713
Epoch 2/20
13s - loss: 0.6686 - val_loss: 0.8529
Epoch 3/20
13s - loss: 0.6664 - val_loss: 0.8496
Epoch 4/20
13s - loss: 0.6656 - val_loss: 0.8320
Epoch 5/20
13s - loss: 0.6645 - val_loss: 0.8521
Epoch 6/20
13s - loss: 0.6638 - val_loss: 0.8883
Epoch 7/20
13s - loss: 0.6624 - val_loss: 0.8284
Epoch 8/20
13s - loss: 0.6615 - val_loss: 0.8485
Epoch 9/20
13s - loss: 0.6604 - val_loss: 0.8529
Epoch 10/20
13s - loss: 0.6594 - val_loss: 0.8647
Epoch 11/20
13s - loss: 0.6579 - val_loss: 0.8687
Epoch 00010: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6542 - val_loss: 0.8329
Epoch 2/20
13s - loss: 0.6416 - val_loss: 0.8277
Epoch 3/20
13s - loss: 0.6365 - val_loss: 0.7986
Epoch 4/20
13s - loss: 0.6338 - val_loss: 0.8114
Epoch 5/20
13s - loss: 0.6317 - val_loss: 0.8571
Epoch 6/20
13s - loss: 0.6294 - val_loss: 0.8441
Epoch 7/20
13s - loss: 0.6277 - val_loss: 0.8054
Epoch 00006: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6762 - val_loss: 0.8592
Epoch 2/20
13s - loss: 0.6708 - val_loss: 0.8893
Epoch 3/20
13s - loss: 0.6700 - val_loss: 0.8566
Epoch 4/20
13s - loss: 0.6693 - val_loss: 0.8789
Epoch 5/20
13s - loss: 0.6687 - val_loss: 0.8883
Epoch 6/20
13s - loss: 0.6680 - val_loss: 0.8878
Epoch 7/20
13s - loss: 0.6672 - val_loss: 0.8560
Epoch 8/20
13s - loss: 0.6669 - val_loss: 0.8802
Epoch 9/20
13s - loss: 0.6659 - val_loss: 0.8765
Epoch 10/20
13s - loss: 0.6651 - val_loss: 0.8892
Epoch 11/20
13s - loss: 0.6640 - val_loss: 0.9036
Epoch 00010: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6589 - val_loss: 0.8037
Epoch 2/20
13s - loss: 0.6497 - val_loss: 0.8725
Epoch 3/20
13s - loss: 0.6465 - val_loss: 0.8665
Epoch 4/20
13s - loss: 0.6441 - val_loss: 0.8196
Epoch 5/20
13s - loss: 0.6425 - val_loss: 0.7808
Epoch 6/20
13s - loss: 0.6408 - val_loss: 0.8519
Epoch 7/20
13s - loss: 0.6395 - val_loss: 0.7993
Epoch 8/20
13s - loss: 0.6381 - val_loss: 0.8734
Epoch 9/20
13s - loss: 0.6361 - val_loss: 0.8157
Epoch 00008: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6770 - val_loss: 0.8787
Epoch 2/20
13s - loss: 0.6706 - val_loss: 0.8509
Epoch 3/20
13s - loss: 0.6695 - val_loss: 0.8683
Epoch 4/20
13s - loss: 0.6691 - val_loss: 0.9060
Epoch 5/20
13s - loss: 0.6683 - val_loss: 0.8819
Epoch 6/20
13s - loss: 0.6678 - val_loss: 0.8601
Epoch 00005: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6506 - val_loss: 0.8187
Epoch 2/20
13s - loss: 0.6371 - val_loss: 0.7839
Epoch 3/20
13s - loss: 0.6337 - val_loss: 0.7989
Epoch 4/20
13s - loss: 0.6320 - val_loss: 0.7709
Epoch 5/20
13s - loss: 0.6313 - val_loss: 0.8128
Epoch 6/20
13s - loss: 0.6301 - val_loss: 0.7781
Epoch 7/20
13s - loss: 0.6293 - val_loss: 0.7805
Epoch 8/20
13s - loss: 0.6279 - val_loss: 0.8024
Epoch 00007: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6574 - val_loss: 0.8461
Epoch 2/20
13s - loss: 0.6496 - val_loss: 0.7550
Epoch 3/20
13s - loss: 0.6469 - val_loss: 0.8214
Epoch 4/20
13s - loss: 0.6459 - val_loss: 0.8393
Epoch 5/20
13s - loss: 0.6445 - val_loss: 0.8460
Epoch 6/20
13s - loss: 0.6435 - val_loss: 0.8299
Epoch 00005: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6611 - val_loss: 0.8093
Epoch 2/20
13s - loss: 0.6517 - val_loss: 0.8679
Epoch 3/20
13s - loss: 0.6492 - val_loss: 0.8787
Epoch 4/20
13s - loss: 0.6481 - val_loss: 0.8118
Epoch 5/20
13s - loss: 0.6472 - val_loss: 0.8083
Epoch 6/20
13s - loss: 0.6462 - val_loss: 0.8628
Epoch 7/20
13s - loss: 0.6450 - val_loss: 0.8047
Epoch 8/20
13s - loss: 0.6440 - val_loss: 0.8315
Epoch 9/20
13s - loss: 0.6427 - val_loss: 0.8474
Epoch 10/20
13s - loss: 0.6413 - val_loss: 0.8273
Epoch 11/20
13s - loss: 0.6405 - val_loss: 0.8469
Epoch 00010: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 5.99973931, -0.        ]), 'nit': 3, 'funcalls': 46}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.48055183e+07,  -1.15491342e+02]), 'nit': 3, 'funcalls': 95}
  " state: %s" % convergence_dict)
Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   3

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-13 06:50:01.509534: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 06:50:01.512464: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 06:50:01.512473: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 06:50:01.512478: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 06:50:01.512482: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 06:50:01.814383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-13 06:50:01.814418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-13 06:50:01.814423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-13 06:50:01.814432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
14s - loss: 0.6699 - val_loss: 0.8574
Epoch 2/20
13s - loss: 0.6653 - val_loss: 0.8339
Epoch 3/20
13s - loss: 0.6646 - val_loss: 0.8711
Epoch 4/20
13s - loss: 0.6640 - val_loss: 0.9151
Epoch 5/20
13s - loss: 0.6628 - val_loss: 0.8223
Epoch 6/20
13s - loss: 0.6618 - val_loss: 0.8614
Epoch 7/20
13s - loss: 0.6609 - val_loss: 0.8446
Epoch 8/20
13s - loss: 0.6600 - val_loss: 0.9075
Epoch 9/20
13s - loss: 0.6589 - val_loss: 0.8345
Epoch 00008: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6377 - val_loss: 0.8050
Epoch 2/20
13s - loss: 0.6226 - val_loss: 0.7787
Epoch 3/20
13s - loss: 0.6187 - val_loss: 0.8021
Epoch 4/20
13s - loss: 0.6166 - val_loss: 0.7926
Epoch 5/20
13s - loss: 0.6143 - val_loss: 0.7683
Epoch 6/20
13s - loss: 0.6121 - val_loss: 0.7284
Epoch 7/20
13s - loss: 0.6104 - val_loss: 0.7947
Epoch 8/20
13s - loss: 0.6087 - val_loss: 0.8396
Epoch 9/20
13s - loss: 0.6062 - val_loss: 0.7700
Epoch 10/20
13s - loss: 0.6047 - val_loss: 0.7790
Epoch 00009: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6272 - val_loss: 0.8142
Epoch 2/20
13s - loss: 0.6115 - val_loss: 0.7695
Epoch 3/20
13s - loss: 0.6073 - val_loss: 0.8019
Epoch 4/20
13s - loss: 0.6043 - val_loss: 0.7243
Epoch 5/20
13s - loss: 0.6017 - val_loss: 0.7851
Epoch 6/20
13s - loss: 0.5989 - val_loss: 0.8373
Epoch 7/20
13s - loss: 0.5967 - val_loss: 0.7551
Epoch 8/20
13s - loss: 0.5947 - val_loss: 0.7743
Epoch 00007: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6079 - val_loss: 0.7211
Epoch 2/20
13s - loss: 0.5970 - val_loss: 0.6741
Epoch 3/20
13s - loss: 0.5944 - val_loss: 0.7464
Epoch 4/20
13s - loss: 0.5928 - val_loss: 0.8137
Epoch 5/20
13s - loss: 0.5909 - val_loss: 0.8011
Epoch 6/20
13s - loss: 0.5894 - val_loss: 0.7724
Epoch 00005: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6675 - val_loss: 0.8586
Epoch 2/20
13s - loss: 0.6625 - val_loss: 0.8345
Epoch 3/20
13s - loss: 0.6617 - val_loss: 0.8304
Epoch 4/20
13s - loss: 0.6608 - val_loss: 0.8285
Epoch 5/20
13s - loss: 0.6605 - val_loss: 0.8634
Epoch 6/20
13s - loss: 0.6600 - val_loss: 0.8150
Epoch 7/20
13s - loss: 0.6595 - val_loss: 0.8690
Epoch 8/20
13s - loss: 0.6590 - val_loss: 0.8854
Epoch 9/20
13s - loss: 0.6582 - val_loss: 0.8465
Epoch 10/20
13s - loss: 0.6573 - val_loss: 0.8421
Epoch 00009: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6555 - val_loss: 0.8643
Epoch 2/20
13s - loss: 0.6481 - val_loss: 0.8203
Epoch 3/20
13s - loss: 0.6457 - val_loss: 0.8927
Epoch 4/20
13s - loss: 0.6445 - val_loss: 0.8220
Epoch 5/20
13s - loss: 0.6436 - val_loss: 0.8042
Epoch 6/20
13s - loss: 0.6424 - val_loss: 0.7894
Epoch 7/20
13s - loss: 0.6410 - val_loss: 0.8834
Epoch 8/20
13s - loss: 0.6400 - val_loss: 0.7494
Epoch 9/20
13s - loss: 0.6388 - val_loss: 0.8295
Epoch 10/20
13s - loss: 0.6376 - val_loss: 0.8163
Epoch 11/20
13s - loss: 0.6361 - val_loss: 0.8261
Epoch 12/20
13s - loss: 0.6347 - val_loss: 0.8918
Epoch 00011: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6617 - val_loss: 0.8476
Epoch 2/20
13s - loss: 0.6529 - val_loss: 0.7795
Epoch 3/20
13s - loss: 0.6500 - val_loss: 0.8677
Epoch 4/20
13s - loss: 0.6487 - val_loss: 0.8984
Epoch 5/20
13s - loss: 0.6472 - val_loss: 0.8107
Epoch 6/20
13s - loss: 0.6460 - val_loss: 0.8493
Epoch 00005: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6417 - val_loss: 0.8166
Epoch 2/20
13s - loss: 0.6322 - val_loss: 0.7372
Epoch 3/20
13s - loss: 0.6306 - val_loss: 0.8628
Epoch 4/20
13s - loss: 0.6292 - val_loss: 0.7404
Epoch 5/20
13s - loss: 0.6279 - val_loss: 0.8076
Epoch 6/20
13s - loss: 0.6270 - val_loss: 0.8240
Epoch 00005: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6852 - val_loss: 0.8522
Epoch 2/20
13s - loss: 0.6805 - val_loss: 0.8443
Epoch 3/20
13s - loss: 0.6796 - val_loss: 0.8335
Epoch 4/20
13s - loss: 0.6794 - val_loss: 0.8642
Epoch 5/20
13s - loss: 0.6793 - val_loss: 0.8693
Epoch 6/20
13s - loss: 0.6793 - val_loss: 0.8927
Epoch 7/20
13s - loss: 0.6793 - val_loss: 0.8680
Epoch 00006: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6551 - val_loss: 0.8291
Epoch 2/20
13s - loss: 0.6460 - val_loss: 0.8336
Epoch 3/20
13s - loss: 0.6439 - val_loss: 0.7597
Epoch 4/20
13s - loss: 0.6427 - val_loss: 0.7592
Epoch 5/20
13s - loss: 0.6413 - val_loss: 0.8119
Epoch 6/20
13s - loss: 0.6400 - val_loss: 0.7749
Epoch 7/20
13s - loss: 0.6390 - val_loss: 0.8218
Epoch 8/20
13s - loss: 0.6373 - val_loss: 0.7924
Epoch 00007: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6695 - val_loss: 0.8556
Epoch 2/20
13s - loss: 0.6613 - val_loss: 0.8564
Epoch 3/20
13s - loss: 0.6591 - val_loss: 0.8760
Epoch 4/20
13s - loss: 0.6587 - val_loss: 0.8374
Epoch 5/20
13s - loss: 0.6577 - val_loss: 0.8779
Epoch 6/20
13s - loss: 0.6567 - val_loss: 0.8274
Epoch 7/20
13s - loss: 0.6559 - val_loss: 0.8863
Epoch 8/20
13s - loss: 0.6548 - val_loss: 0.8561
Epoch 9/20
13s - loss: 0.6534 - val_loss: 0.8439
Epoch 10/20
13s - loss: 0.6521 - val_loss: 0.8261
Epoch 11/20
13s - loss: 0.6503 - val_loss: 0.8800
Epoch 12/20
13s - loss: 0.6487 - val_loss: 0.8713
Epoch 13/20
13s - loss: 0.6469 - val_loss: 0.8496
Epoch 14/20
13s - loss: 0.6443 - val_loss: 0.8372
Epoch 00013: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6820 - val_loss: 0.8568
Epoch 2/20
13s - loss: 0.6786 - val_loss: 0.8511
Epoch 3/20
13s - loss: 0.6778 - val_loss: 0.8783
Epoch 4/20
13s - loss: 0.6775 - val_loss: 0.8681
Epoch 5/20
13s - loss: 0.6774 - val_loss: 0.8658
Epoch 6/20
13s - loss: 0.6774 - val_loss: 0.8841
Epoch 00005: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6846 - val_loss: 0.8789
Epoch 2/20
13s - loss: 0.6810 - val_loss: 0.8720
Epoch 3/20
13s - loss: 0.6799 - val_loss: 0.8478
Epoch 4/20
13s - loss: 0.6795 - val_loss: 0.8775
Epoch 5/20
13s - loss: 0.6796 - val_loss: 0.8898
Epoch 6/20
13s - loss: 0.6795 - val_loss: 0.8840
Epoch 7/20
13s - loss: 0.6794 - val_loss: 0.8994
Epoch 00006: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6640 - val_loss: 0.8236
Epoch 2/20
13s - loss: 0.6563 - val_loss: 0.7930
Epoch 3/20
13s - loss: 0.6553 - val_loss: 0.8123
Epoch 4/20
13s - loss: 0.6537 - val_loss: 0.8414
Epoch 5/20
13s - loss: 0.6530 - val_loss: 0.8209
Epoch 6/20
13s - loss: 0.6516 - val_loss: 0.8338
Epoch 00005: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6565 - val_loss: 0.8309
Epoch 2/20
13s - loss: 0.6486 - val_loss: 0.8554
Epoch 3/20
13s - loss: 0.6468 - val_loss: 0.8531
Epoch 4/20
13s - loss: 0.6455 - val_loss: 0.7895
Epoch 5/20
13s - loss: 0.6442 - val_loss: 0.8235
Epoch 6/20
13s - loss: 0.6429 - val_loss: 0.8848
Epoch 7/20
13s - loss: 0.6412 - val_loss: 0.8103
Epoch 8/20
13s - loss: 0.6401 - val_loss: 0.8000
Epoch 00007: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6574 - val_loss: 0.8482
Epoch 2/20
13s - loss: 0.6505 - val_loss: 0.7659
Epoch 3/20
13s - loss: 0.6482 - val_loss: 0.8669
Epoch 4/20
13s - loss: 0.6471 - val_loss: 0.8117
Epoch 5/20
13s - loss: 0.6463 - val_loss: 0.8269
Epoch 6/20
13s - loss: 0.6448 - val_loss: 0.8170
Epoch 00005: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6552 - val_loss: 0.7914
Epoch 2/20
13s - loss: 0.6446 - val_loss: 0.8228
Epoch 3/20
13s - loss: 0.6422 - val_loss: 0.8508
Epoch 4/20
13s - loss: 0.6406 - val_loss: 0.8181
Epoch 5/20
13s - loss: 0.6390 - val_loss: 0.8854
Epoch 00004: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6713 - val_loss: 0.8659
Epoch 2/20
13s - loss: 0.6640 - val_loss: 0.8571
Epoch 3/20
13s - loss: 0.6617 - val_loss: 0.8709
Epoch 4/20
13s - loss: 0.6597 - val_loss: 0.9123
Epoch 5/20
13s - loss: 0.6580 - val_loss: 0.8352
Epoch 6/20
13s - loss: 0.6568 - val_loss: 0.8163
Epoch 7/20
13s - loss: 0.6556 - val_loss: 0.8009
Epoch 8/20
13s - loss: 0.6541 - val_loss: 0.9020
Epoch 9/20
13s - loss: 0.6524 - val_loss: 0.8998
Epoch 10/20
13s - loss: 0.6504 - val_loss: 0.8906
Epoch 11/20
13s - loss: 0.6484 - val_loss: 0.8498
Epoch 00010: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6266 - val_loss: 0.8516
Epoch 2/20
13s - loss: 0.6152 - val_loss: 0.8768
Epoch 3/20
13s - loss: 0.6132 - val_loss: 0.7019
Epoch 4/20
13s - loss: 0.6118 - val_loss: 0.7787
Epoch 5/20
13s - loss: 0.6104 - val_loss: 0.7491
Epoch 6/20
13s - loss: 0.6090 - val_loss: 0.7398
Epoch 7/20
13s - loss: 0.6073 - val_loss: 0.7674
Epoch 00006: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6512 - val_loss: 0.9203
Epoch 2/20
13s - loss: 0.6393 - val_loss: 0.8228
Epoch 3/20
13s - loss: 0.6368 - val_loss: 0.8351
Epoch 4/20
13s - loss: 0.6358 - val_loss: 0.7848
Epoch 5/20
13s - loss: 0.6341 - val_loss: 0.8343
Epoch 6/20
13s - loss: 0.6326 - val_loss: 0.8144
Epoch 7/20
13s - loss: 0.6314 - val_loss: 0.8437
Epoch 8/20
13s - loss: 0.6300 - val_loss: 0.8007
Epoch 00007: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6743 - val_loss: 0.8890
Epoch 2/20
13s - loss: 0.6691 - val_loss: 0.8302
Epoch 3/20
13s - loss: 0.6682 - val_loss: 0.8661
Epoch 4/20
13s - loss: 0.6677 - val_loss: 0.8654
Epoch 5/20
13s - loss: 0.6669 - val_loss: 0.8690
Epoch 6/20
13s - loss: 0.6659 - val_loss: 0.8998
Epoch 00005: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6485 - val_loss: 0.8740
Epoch 2/20
13s - loss: 0.6337 - val_loss: 0.8441
Epoch 3/20
13s - loss: 0.6299 - val_loss: 0.8002
Epoch 4/20
13s - loss: 0.6274 - val_loss: 0.7680
Epoch 5/20
13s - loss: 0.6259 - val_loss: 0.7734
Epoch 6/20
13s - loss: 0.6236 - val_loss: 0.8216
Epoch 7/20
13s - loss: 0.6220 - val_loss: 0.7705
Epoch 8/20
13s - loss: 0.6196 - val_loss: 0.8788
Epoch 00007: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6535 - val_loss: 0.8396
Epoch 2/20
13s - loss: 0.6448 - val_loss: 0.8059
Epoch 3/20
13s - loss: 0.6417 - val_loss: 0.7921
Epoch 4/20
13s - loss: 0.6391 - val_loss: 0.7826
Epoch 5/20
13s - loss: 0.6374 - val_loss: 0.8130
Epoch 6/20
13s - loss: 0.6360 - val_loss: 0.7634
Epoch 7/20
13s - loss: 0.6339 - val_loss: 0.8311
Epoch 8/20
13s - loss: 0.6326 - val_loss: 0.8393
Epoch 9/20
13s - loss: 0.6306 - val_loss: 0.8247
Epoch 10/20
13s - loss: 0.6288 - val_loss: 0.7128
Epoch 11/20
13s - loss: 0.6269 - val_loss: 0.7983
Epoch 12/20
13s - loss: 0.6250 - val_loss: 0.7982
Epoch 13/20
13s - loss: 0.6227 - val_loss: 0.7634
Epoch 14/20
13s - loss: 0.6202 - val_loss: 0.8528
Epoch 00013: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6670 - val_loss: 0.8563
Epoch 2/20
13s - loss: 0.6610 - val_loss: 0.8622
Epoch 3/20
13s - loss: 0.6596 - val_loss: 0.8306
Epoch 4/20
13s - loss: 0.6588 - val_loss: 0.8051
Epoch 5/20
13s - loss: 0.6581 - val_loss: 0.8068
Epoch 6/20
13s - loss: 0.6567 - val_loss: 0.8424
Epoch 7/20
13s - loss: 0.6557 - val_loss: 0.8665
Epoch 8/20
13s - loss: 0.6545 - val_loss: 0.8519
Epoch 00007: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6670 - val_loss: 0.8437
Epoch 2/20
13s - loss: 0.6611 - val_loss: 0.8207
Epoch 3/20
13s - loss: 0.6596 - val_loss: 0.8702
Epoch 4/20
13s - loss: 0.6579 - val_loss: 0.8761
Epoch 5/20
13s - loss: 0.6571 - val_loss: 0.8795
Epoch 6/20
13s - loss: 0.6561 - val_loss: 0.9162
Epoch 00005: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6508 - val_loss: 0.7891
Epoch 2/20
13s - loss: 0.6426 - val_loss: 0.8269
Epoch 3/20
13s - loss: 0.6402 - val_loss: 0.8418
Epoch 4/20
13s - loss: 0.6392 - val_loss: 0.8136
Epoch 5/20
13s - loss: 0.6379 - val_loss: 0.8057
Epoch 00004: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6842 - val_loss: 0.8784
Epoch 2/20
13s - loss: 0.6795 - val_loss: 0.8437
Epoch 3/20
13s - loss: 0.6786 - val_loss: 0.8786
Epoch 4/20
13s - loss: 0.6780 - val_loss: 0.8350
Epoch 5/20
13s - loss: 0.6782 - val_loss: 0.8526
Epoch 6/20
13s - loss: 0.6777 - val_loss: 0.8800
Epoch 7/20
13s - loss: 0.6775 - val_loss: 0.8377
Epoch 8/20
13s - loss: 0.6773 - val_loss: 0.8810
Epoch 00007: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6479 - val_loss: 0.8169
Epoch 2/20
13s - loss: 0.6356 - val_loss: 0.7813
Epoch 3/20
13s - loss: 0.6327 - val_loss: 0.8428
Epoch 4/20
13s - loss: 0.6310 - val_loss: 0.7859
Epoch 5/20
13s - loss: 0.6291 - val_loss: 0.8465
Epoch 6/20
13s - loss: 0.6277 - val_loss: 0.7770
Epoch 7/20
13s - loss: 0.6257 - val_loss: 0.8622
Epoch 8/20
13s - loss: 0.6240 - val_loss: 0.8482
Epoch 9/20
13s - loss: 0.6224 - val_loss: 0.8537
Epoch 10/20
13s - loss: 0.6199 - val_loss: 0.8576
Epoch 00009: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6779 - val_loss: 0.8625
Epoch 2/20
13s - loss: 0.6723 - val_loss: 0.8086
Epoch 3/20
13s - loss: 0.6712 - val_loss: 0.8652
Epoch 4/20
13s - loss: 0.6708 - val_loss: 0.8871
Epoch 5/20
13s - loss: 0.6703 - val_loss: 0.8635
Epoch 6/20
13s - loss: 0.6697 - val_loss: 0.8613
Epoch 00005: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6341 - val_loss: 0.7668
Epoch 2/20
13s - loss: 0.6234 - val_loss: 0.7708
Epoch 3/20
13s - loss: 0.6211 - val_loss: 0.7755
Epoch 4/20
13s - loss: 0.6191 - val_loss: 0.7933
Epoch 5/20
13s - loss: 0.6183 - val_loss: 0.7892
Epoch 00004: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6666 - val_loss: 0.8532
Epoch 2/20
13s - loss: 0.6580 - val_loss: 0.8478
Epoch 3/20
13s - loss: 0.6550 - val_loss: 0.8529
Epoch 4/20
13s - loss: 0.6528 - val_loss: 0.8196
Epoch 5/20
13s - loss: 0.6516 - val_loss: 0.9122
Epoch 6/20
13s - loss: 0.6496 - val_loss: 0.8358
Epoch 7/20
13s - loss: 0.6483 - val_loss: 0.8803
Epoch 8/20
13s - loss: 0.6463 - val_loss: 0.8330
Epoch 00007: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6495 - val_loss: 0.8665
Epoch 2/20
13s - loss: 0.6389 - val_loss: 0.8239
Epoch 3/20
13s - loss: 0.6359 - val_loss: 0.8547
Epoch 4/20
13s - loss: 0.6337 - val_loss: 0.8110
Epoch 5/20
13s - loss: 0.6316 - val_loss: 0.7950
Epoch 6/20
13s - loss: 0.6303 - val_loss: 0.9150
Epoch 7/20
13s - loss: 0.6286 - val_loss: 0.9000
Epoch 8/20
13s - loss: 0.6270 - val_loss: 0.8413
Epoch 9/20
13s - loss: 0.6252 - val_loss: 0.8064
Epoch 00008: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6730 - val_loss: 0.9099
Epoch 2/20
13s - loss: 0.6661 - val_loss: 0.8412
Epoch 3/20
13s - loss: 0.6642 - val_loss: 0.8332
Epoch 4/20
13s - loss: 0.6632 - val_loss: 0.8443
Epoch 5/20
13s - loss: 0.6614 - val_loss: 0.8629
Epoch 6/20
13s - loss: 0.6603 - val_loss: 0.9070
Epoch 7/20
13s - loss: 0.6591 - val_loss: 0.8463
Epoch 00006: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6602 - val_loss: 0.8218
Epoch 2/20
13s - loss: 0.6532 - val_loss: 0.8367
Epoch 3/20
13s - loss: 0.6514 - val_loss: 0.7894
Epoch 4/20
13s - loss: 0.6503 - val_loss: 0.8074
Epoch 5/20
13s - loss: 0.6498 - val_loss: 0.8472
Epoch 6/20
14s - loss: 0.6483 - val_loss: 0.8390
Epoch 7/20
13s - loss: 0.6470 - val_loss: 0.8045
Epoch 00006: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6367 - val_loss: 0.7839
Epoch 2/20
14s - loss: 0.6240 - val_loss: 0.8230
Epoch 3/20
14s - loss: 0.6219 - val_loss: 0.8045
Epoch 4/20
14s - loss: 0.6203 - val_loss: 0.7243
Epoch 5/20
13s - loss: 0.6181 - val_loss: 0.8377
Epoch 6/20
13s - loss: 0.6169 - val_loss: 0.8232
Epoch 7/20
14s - loss: 0.6152 - val_loss: 0.8049
Epoch 8/20
13s - loss: 0.6142 - val_loss: 0.7977
Epoch 00007: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6577 - val_loss: 0.8555
Epoch 2/20
14s - loss: 0.6490 - val_loss: 0.8174
Epoch 3/20
14s - loss: 0.6470 - val_loss: 0.9610
Epoch 4/20
14s - loss: 0.6456 - val_loss: 0.8791
Epoch 5/20
14s - loss: 0.6445 - val_loss: 0.8626
Epoch 6/20
14s - loss: 0.6432 - val_loss: 0.9664
Epoch 00005: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6545 - val_loss: 0.8826
Epoch 2/20
14s - loss: 0.6466 - val_loss: 0.8230
Epoch 3/20
14s - loss: 0.6431 - val_loss: 0.8873
Epoch 4/20
14s - loss: 0.6409 - val_loss: 0.8496
Epoch 5/20
14s - loss: 0.6395 - val_loss: 0.8114
Epoch 6/20
14s - loss: 0.6375 - val_loss: 0.8378
Epoch 7/20
14s - loss: 0.6359 - val_loss: 0.8389
Epoch 8/20
14s - loss: 0.6341 - val_loss: 0.8717
Epoch 9/20
14s - loss: 0.6324 - val_loss: 0.7919
Epoch 10/20
14s - loss: 0.6304 - val_loss: 0.8196
Epoch 11/20
14s - loss: 0.6284 - val_loss: 0.7802
Epoch 12/20
14s - loss: 0.6257 - val_loss: 0.8629
Epoch 13/20
14s - loss: 0.6237 - val_loss: 0.7627
Epoch 14/20
14s - loss: 0.6216 - val_loss: 0.8226
Epoch 15/20
14s - loss: 0.6182 - val_loss: 0.8343
Epoch 16/20
14s - loss: 0.6153 - val_loss: 0.8543
Epoch 17/20
14s - loss: 0.6122 - val_loss: 0.8639
Epoch 00016: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6615 - val_loss: 0.8267
Epoch 2/20
14s - loss: 0.6534 - val_loss: 0.7948
Epoch 3/20
14s - loss: 0.6504 - val_loss: 0.8260
Epoch 4/20
14s - loss: 0.6485 - val_loss: 0.8340
Epoch 5/20
14s - loss: 0.6473 - val_loss: 0.8853
Epoch 6/20
14s - loss: 0.6458 - val_loss: 0.8049
Epoch 00005: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6505 - val_loss: 0.7885
Epoch 2/20
14s - loss: 0.6372 - val_loss: 0.8095
Epoch 3/20
14s - loss: 0.6348 - val_loss: 0.7844
Epoch 4/20
14s - loss: 0.6324 - val_loss: 0.8950
Epoch 5/20
14s - loss: 0.6309 - val_loss: 0.8259
Epoch 6/20
14s - loss: 0.6296 - val_loss: 0.7973
Epoch 7/20
14s - loss: 0.6281 - val_loss: 0.7892
Epoch 00006: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6841 - val_loss: 0.8607
Epoch 2/20
14s - loss: 0.6806 - val_loss: 0.8779
Epoch 3/20
14s - loss: 0.6795 - val_loss: 0.8641
Epoch 4/20
14s - loss: 0.6790 - val_loss: 0.8804
Epoch 5/20
14s - loss: 0.6791 - val_loss: 0.8963
Epoch 00004: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6482 - val_loss: 0.8648
Epoch 2/20
14s - loss: 0.6391 - val_loss: 0.8271
Epoch 3/20
14s - loss: 0.6366 - val_loss: 0.8340
Epoch 4/20
14s - loss: 0.6346 - val_loss: 0.8537
Epoch 5/20
14s - loss: 0.6330 - val_loss: 0.8630
Epoch 6/20
14s - loss: 0.6318 - val_loss: 0.7760
Epoch 7/20
14s - loss: 0.6301 - val_loss: 0.8144
Epoch 8/20
14s - loss: 0.6282 - val_loss: 0.8398
Epoch 9/20
14s - loss: 0.6270 - val_loss: 0.7936
Epoch 10/20
14s - loss: 0.6256 - val_loss: 0.8756
Epoch 00009: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6678 - val_loss: 0.8204
Epoch 2/20
14s - loss: 0.6600 - val_loss: 0.8611
Epoch 3/20
14s - loss: 0.6583 - val_loss: 0.8808
Epoch 4/20
14s - loss: 0.6573 - val_loss: 0.9215
Epoch 5/20
14s - loss: 0.6563 - val_loss: 0.8767
Epoch 00004: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6605 - val_loss: 0.7660
Epoch 2/20
14s - loss: 0.6503 - val_loss: 0.8317
Epoch 3/20
14s - loss: 0.6486 - val_loss: 0.7972
Epoch 4/20
14s - loss: 0.6468 - val_loss: 0.8435
Epoch 5/20
14s - loss: 0.6458 - val_loss: 0.8935
Epoch 00004: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6589 - val_loss: 0.8395
Epoch 2/20
14s - loss: 0.6519 - val_loss: 0.8417
Epoch 3/20
14s - loss: 0.6505 - val_loss: 0.8233
Epoch 4/20
14s - loss: 0.6495 - val_loss: 0.8062
Epoch 5/20
14s - loss: 0.6484 - val_loss: 0.8367
Epoch 6/20
14s - loss: 0.6474 - val_loss: 0.8231
Epoch 7/20
14s - loss: 0.6464 - val_loss: 0.7931
Epoch 8/20
14s - loss: 0.6449 - val_loss: 0.8263
Epoch 9/20
14s - loss: 0.6432 - val_loss: 0.8386
Epoch 10/20
14s - loss: 0.6412 - val_loss: 0.8237
Epoch 11/20
14s - loss: 0.6398 - val_loss: 0.7948
Epoch 00010: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6557 - val_loss: 0.8660
Epoch 2/20
14s - loss: 0.6429 - val_loss: 0.8920
Epoch 3/20
14s - loss: 0.6404 - val_loss: 0.8258
Epoch 4/20
14s - loss: 0.6383 - val_loss: 0.8600
Epoch 5/20
14s - loss: 0.6364 - val_loss: 0.8472
Epoch 6/20
14s - loss: 0.6351 - val_loss: 0.8163
Epoch 7/20
14s - loss: 0.6338 - val_loss: 0.8832
Epoch 8/20
14s - loss: 0.6321 - val_loss: 0.8263
Epoch 9/20
14s - loss: 0.6304 - val_loss: 0.8223
Epoch 10/20
14s - loss: 0.6289 - val_loss: 0.8267
Epoch 00009: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6486 - val_loss: 0.8270
Epoch 2/20
14s - loss: 0.6391 - val_loss: 0.7844
Epoch 3/20
14s - loss: 0.6369 - val_loss: 0.7956
Epoch 4/20
14s - loss: 0.6351 - val_loss: 0.7647
Epoch 5/20
14s - loss: 0.6338 - val_loss: 0.8752
Epoch 6/20
14s - loss: 0.6324 - val_loss: 0.8201
Epoch 7/20
14s - loss: 0.6306 - val_loss: 0.8225
Epoch 8/20
14s - loss: 0.6292 - val_loss: 0.8022
Epoch 00007: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6733 - val_loss: 0.8764
Epoch 2/20
14s - loss: 0.6697 - val_loss: 0.8157
Epoch 3/20
14s - loss: 0.6689 - val_loss: 0.8852
Epoch 4/20
14s - loss: 0.6684 - val_loss: 0.8678
Epoch 5/20
14s - loss: 0.6676 - val_loss: 0.8672
Epoch 6/20
14s - loss: 0.6669 - val_loss: 0.8722
Epoch 00005: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6667 - val_loss: 0.8635
Epoch 2/20
14s - loss: 0.6623 - val_loss: 0.8593
Epoch 3/20
14s - loss: 0.6616 - val_loss: 0.8216
Epoch 4/20
14s - loss: 0.6610 - val_loss: 0.8631
Epoch 5/20
14s - loss: 0.6602 - val_loss: 0.8581
Epoch 6/20
14s - loss: 0.6595 - val_loss: 0.8586
Epoch 7/20
14s - loss: 0.6588 - val_loss: 0.8382
Epoch 00006: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6813 - val_loss: 0.8993
Epoch 2/20
14s - loss: 0.6766 - val_loss: 0.8370
Epoch 3/20
14s - loss: 0.6757 - val_loss: 0.8565
Epoch 4/20
14s - loss: 0.6753 - val_loss: 0.8553
Epoch 5/20
14s - loss: 0.6748 - val_loss: 0.8848
Epoch 6/20
14s - loss: 0.6745 - val_loss: 0.9036
Epoch 00005: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6623 - val_loss: 0.8762
Epoch 2/20
14s - loss: 0.6560 - val_loss: 0.8049
Epoch 3/20
14s - loss: 0.6545 - val_loss: 0.7946
Epoch 4/20
14s - loss: 0.6539 - val_loss: 0.8165
Epoch 5/20
14s - loss: 0.6526 - val_loss: 0.8097
Epoch 6/20
14s - loss: 0.6517 - val_loss: 0.8640
Epoch 7/20
14s - loss: 0.6509 - val_loss: 0.8200
Epoch 00006: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6752 - val_loss: 0.8757
Epoch 2/20
14s - loss: 0.6695 - val_loss: 0.8609
Epoch 3/20
14s - loss: 0.6684 - val_loss: 0.9171
Epoch 4/20
14s - loss: 0.6673 - val_loss: 0.8490
Epoch 5/20
14s - loss: 0.6668 - val_loss: 0.9088
Epoch 6/20
14s - loss: 0.6658 - val_loss: 0.8819
Epoch 7/20
14s - loss: 0.6648 - val_loss: 0.8605
Epoch 8/20
14s - loss: 0.6639 - val_loss: 0.8969
Epoch 00007: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6681 - val_loss: 0.8617
Epoch 2/20
14s - loss: 0.6606 - val_loss: 0.8401
Epoch 3/20
14s - loss: 0.6588 - val_loss: 0.8545
Epoch 4/20
14s - loss: 0.6582 - val_loss: 0.7722
Epoch 5/20
14s - loss: 0.6568 - val_loss: 0.8098
Epoch 6/20
14s - loss: 0.6564 - val_loss: 0.8601
Epoch 7/20
14s - loss: 0.6550 - val_loss: 0.8118
Epoch 8/20
14s - loss: 0.6539 - val_loss: 0.8257
Epoch 00007: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6479 - val_loss: 0.9020
Epoch 2/20
14s - loss: 0.6366 - val_loss: 0.8160
Epoch 3/20
14s - loss: 0.6326 - val_loss: 0.7605
Epoch 4/20
14s - loss: 0.6306 - val_loss: 0.8139
Epoch 5/20
14s - loss: 0.6287 - val_loss: 0.8629
Epoch 6/20
14s - loss: 0.6266 - val_loss: 0.7969
Epoch 7/20
14s - loss: 0.6254 - val_loss: 0.7844
Epoch 00006: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6456 - val_loss: 0.8340
Epoch 2/20
14s - loss: 0.6348 - val_loss: 0.7670
Epoch 3/20
14s - loss: 0.6312 - val_loss: 0.8930
Epoch 4/20
14s - loss: 0.6288 - val_loss: 0.7878
Epoch 5/20
14s - loss: 0.6271 - val_loss: 0.8564
Epoch 6/20
14s - loss: 0.6256 - val_loss: 0.7795
Epoch 00005: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6805 - val_loss: 0.8663
Epoch 2/20
14s - loss: 0.6756 - val_loss: 0.8592
Epoch 3/20
14s - loss: 0.6746 - val_loss: 0.8709
Epoch 4/20
14s - loss: 0.6739 - val_loss: 0.9235
Epoch 5/20
14s - loss: 0.6735 - val_loss: 0.8481
Epoch 6/20
14s - loss: 0.6730 - val_loss: 0.8819
Epoch 7/20
14s - loss: 0.6722 - val_loss: 0.8760
Epoch 8/20
14s - loss: 0.6715 - val_loss: 0.9061
Epoch 9/20
14s - loss: 0.6705 - val_loss: 0.8933
Epoch 00008: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6615 - val_loss: 0.8773
Epoch 2/20
14s - loss: 0.6539 - val_loss: 0.8205
Epoch 3/20
14s - loss: 0.6511 - val_loss: 0.7901
Epoch 4/20
14s - loss: 0.6491 - val_loss: 0.8365
Epoch 5/20
14s - loss: 0.6475 - val_loss: 0.8797
Epoch 6/20
14s - loss: 0.6456 - val_loss: 0.8377
Epoch 7/20
14s - loss: 0.6445 - val_loss: 0.8689
Epoch 00006: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6631 - val_loss: 0.8212
Epoch 2/20
14s - loss: 0.6515 - val_loss: 0.7534
Epoch 3/20
14s - loss: 0.6485 - val_loss: 0.7549
Epoch 4/20
14s - loss: 0.6458 - val_loss: 0.7933
Epoch 5/20
14s - loss: 0.6439 - val_loss: 0.8805
Epoch 6/20
14s - loss: 0.6424 - val_loss: 0.8153
Epoch 00005: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6574 - val_loss: 0.8997
Epoch 2/20
14s - loss: 0.6509 - val_loss: 0.7479
Epoch 3/20
14s - loss: 0.6484 - val_loss: 0.8198
Epoch 4/20
14s - loss: 0.6476 - val_loss: 0.8307
Epoch 5/20
14s - loss: 0.6463 - val_loss: 0.8583
Epoch 6/20
14s - loss: 0.6453 - val_loss: 0.8071
Epoch 00005: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6599 - val_loss: 0.8681
Epoch 2/20
14s - loss: 0.6542 - val_loss: 0.9020
Epoch 3/20
14s - loss: 0.6530 - val_loss: 0.8233
Epoch 4/20
14s - loss: 0.6508 - val_loss: 0.8444
Epoch 5/20
14s - loss: 0.6502 - val_loss: 0.7937
Epoch 6/20
14s - loss: 0.6495 - val_loss: 0.7777
Epoch 7/20
14s - loss: 0.6483 - val_loss: 0.8183
Epoch 8/20
14s - loss: 0.6473 - val_loss: 0.8288
Epoch 9/20
14s - loss: 0.6459 - val_loss: 0.8431
Epoch 10/20
14s - loss: 0.6441 - val_loss: 0.8764
Epoch 00009: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6624 - val_loss: 0.7908
Epoch 2/20
14s - loss: 0.6535 - val_loss: 0.7971
Epoch 3/20
14s - loss: 0.6509 - val_loss: 0.8249
Epoch 4/20
14s - loss: 0.6488 - val_loss: 0.8349
Epoch 5/20
14s - loss: 0.6473 - val_loss: 0.8826
Epoch 00004: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6553 - val_loss: 0.8152
Epoch 2/20
14s - loss: 0.6440 - val_loss: 0.8239
Epoch 3/20
14s - loss: 0.6408 - val_loss: 0.8083
Epoch 4/20
14s - loss: 0.6384 - val_loss: 0.8855
Epoch 5/20
14s - loss: 0.6366 - val_loss: 0.8533
Epoch 6/20
14s - loss: 0.6354 - val_loss: 0.8280
Epoch 7/20
14s - loss: 0.6330 - val_loss: 0.8230
Epoch 00006: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6602 - val_loss: 0.8800
Epoch 2/20
14s - loss: 0.6527 - val_loss: 0.8263
Epoch 3/20
14s - loss: 0.6504 - val_loss: 0.7897
Epoch 4/20
14s - loss: 0.6488 - val_loss: 0.8802
Epoch 5/20
14s - loss: 0.6472 - val_loss: 0.7829
Epoch 6/20
14s - loss: 0.6461 - val_loss: 0.8867
Epoch 7/20
14s - loss: 0.6445 - val_loss: 0.8235
Epoch 8/20
14s - loss: 0.6434 - val_loss: 0.8943
Epoch 9/20
14s - loss: 0.6419 - val_loss: 0.8307
Epoch 00008: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6804 - val_loss: 0.9022
Epoch 2/20
14s - loss: 0.6759 - val_loss: 0.8536
Epoch 3/20
14s - loss: 0.6747 - val_loss: 0.8840
Epoch 4/20
14s - loss: 0.6745 - val_loss: 0.8864
Epoch 5/20
14s - loss: 0.6740 - val_loss: 0.9020
Epoch 6/20
14s - loss: 0.6737 - val_loss: 0.8373
Epoch 7/20
14s - loss: 0.6734 - val_loss: 0.8400
Epoch 8/20
14s - loss: 0.6728 - val_loss: 0.8936
Epoch 9/20
14s - loss: 0.6721 - val_loss: 0.8501
Epoch 10/20
14s - loss: 0.6712 - val_loss: 0.8949
Epoch 00009: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6778 - val_loss: 0.8537
Epoch 2/20
14s - loss: 0.6729 - val_loss: 0.8555
Epoch 3/20
14s - loss: 0.6718 - val_loss: 0.8436
Epoch 4/20
14s - loss: 0.6716 - val_loss: 0.8593
Epoch 5/20
14s - loss: 0.6716 - val_loss: 0.8721
Epoch 6/20
14s - loss: 0.6711 - val_loss: 0.8333
Epoch 7/20
14s - loss: 0.6709 - val_loss: 0.8832
Epoch 8/20
14s - loss: 0.6702 - val_loss: 0.8419
Epoch 9/20
14s - loss: 0.6698 - val_loss: 0.8571
Epoch 10/20
14s - loss: 0.6689 - val_loss: 0.9036
Epoch 00009: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6791 - val_loss: 0.8590
Epoch 2/20
14s - loss: 0.6761 - val_loss: 0.8697
Epoch 3/20
14s - loss: 0.6753 - val_loss: 0.8714
Epoch 4/20
14s - loss: 0.6748 - val_loss: 0.8517
Epoch 5/20
14s - loss: 0.6746 - val_loss: 0.8670
Epoch 6/20
14s - loss: 0.6742 - val_loss: 0.8595
Epoch 7/20
14s - loss: 0.6738 - val_loss: 0.8457
Epoch 8/20
14s - loss: 0.6737 - val_loss: 0.8681
Epoch 9/20
14s - loss: 0.6730 - val_loss: 0.8583
Epoch 10/20
14s - loss: 0.6726 - val_loss: 0.8256
Epoch 11/20
14s - loss: 0.6719 - val_loss: 0.8902
Epoch 12/20
14s - loss: 0.6709 - val_loss: 0.8768
Epoch 13/20
14s - loss: 0.6697 - val_loss: 0.8429
Epoch 14/20
14s - loss: 0.6680 - val_loss: 0.8859
Epoch 00013: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6680 - val_loss: 0.8477
Epoch 2/20
14s - loss: 0.6621 - val_loss: 0.8649
Epoch 3/20
14s - loss: 0.6601 - val_loss: 0.9038
Epoch 4/20
14s - loss: 0.6590 - val_loss: 0.7969
Epoch 5/20
14s - loss: 0.6579 - val_loss: 0.8615
Epoch 6/20
14s - loss: 0.6566 - val_loss: 0.9042
Epoch 7/20
14s - loss: 0.6553 - val_loss: 0.8671
Epoch 8/20
14s - loss: 0.6540 - val_loss: 0.8897
Epoch 00007: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6522 - val_loss: 0.8517
Epoch 2/20
14s - loss: 0.6434 - val_loss: 0.9057
Epoch 3/20
14s - loss: 0.6417 - val_loss: 0.8300
Epoch 4/20
14s - loss: 0.6398 - val_loss: 0.8334
Epoch 5/20
14s - loss: 0.6382 - val_loss: 0.7927
Epoch 6/20
14s - loss: 0.6369 - val_loss: 0.8866
Epoch 7/20
14s - loss: 0.6355 - val_loss: 0.8938
Epoch 8/20
14s - loss: 0.6337 - val_loss: 0.7674
Epoch 9/20
14s - loss: 0.6322 - val_loss: 0.8548
Epoch 10/20
14s - loss: 0.6301 - val_loss: 0.8507
Epoch 11/20
14s - loss: 0.6286 - val_loss: 0.8695
Epoch 12/20
14s - loss: 0.6265 - val_loss: 0.7858
Epoch 00011: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6555 - val_loss: 0.8444
Epoch 2/20
14s - loss: 0.6472 - val_loss: 0.7474
Epoch 3/20
14s - loss: 0.6450 - val_loss: 0.7781
Epoch 4/20
14s - loss: 0.6433 - val_loss: 0.8209
Epoch 5/20
14s - loss: 0.6424 - val_loss: 0.8121
Epoch 6/20
14s - loss: 0.6410 - val_loss: 0.8090
Epoch 00005: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6361 - val_loss: 0.7848
Epoch 2/20
14s - loss: 0.6257 - val_loss: 0.8016
Epoch 3/20
14s - loss: 0.6243 - val_loss: 0.7407
Epoch 4/20
14s - loss: 0.6225 - val_loss: 0.7764
Epoch 5/20
14s - loss: 0.6214 - val_loss: 0.8182
Epoch 6/20
14s - loss: 0.6202 - val_loss: 0.8127
Epoch 7/20
14s - loss: 0.6189 - val_loss: 0.8461
Epoch 00006: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6590 - val_loss: 0.8248
Epoch 2/20
14s - loss: 0.6502 - val_loss: 0.8038
Epoch 3/20
14s - loss: 0.6468 - val_loss: 0.8087
Epoch 4/20
14s - loss: 0.6450 - val_loss: 0.8441
Epoch 5/20
14s - loss: 0.6434 - val_loss: 0.7577
Epoch 6/20
14s - loss: 0.6419 - val_loss: 0.8741
Epoch 7/20
14s - loss: 0.6404 - val_loss: 0.8094
Epoch 8/20
14s - loss: 0.6389 - val_loss: 0.8339
Epoch 9/20
14s - loss: 0.6372 - val_loss: 0.8312
Epoch 00008: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6531 - val_loss: 0.8158
Epoch 2/20
14s - loss: 0.6409 - val_loss: 0.8493
Epoch 3/20
14s - loss: 0.6374 - val_loss: 0.7552
Epoch 4/20
14s - loss: 0.6355 - val_loss: 0.8178
Epoch 5/20
14s - loss: 0.6334 - val_loss: 0.7246
Epoch 6/20
14s - loss: 0.6319 - val_loss: 0.8095
Epoch 7/20
14s - loss: 0.6301 - val_loss: 0.8224
Epoch 8/20
14s - loss: 0.6283 - val_loss: 0.8288
Epoch 9/20
14s - loss: 0.6267 - val_loss: 0.7589
Epoch 00008: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6830 - val_loss: 0.8697
Epoch 2/20
14s - loss: 0.6796 - val_loss: 0.8374
Epoch 3/20
14s - loss: 0.6787 - val_loss: 0.8667
Epoch 4/20
14s - loss: 0.6782 - val_loss: 0.8593
Epoch 5/20
14s - loss: 0.6783 - val_loss: 0.8648
Epoch 6/20
14s - loss: 0.6782 - val_loss: 0.8754
Epoch 00005: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6694 - val_loss: 0.8412
Epoch 2/20
14s - loss: 0.6651 - val_loss: 0.8586
Epoch 3/20
14s - loss: 0.6646 - val_loss: 0.8589
Epoch 4/20
14s - loss: 0.6639 - val_loss: 0.8432
Epoch 5/20
14s - loss: 0.6630 - val_loss: 0.8477
Epoch 00004: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6410 - val_loss: 0.8263
Epoch 2/20
14s - loss: 0.6283 - val_loss: 0.7929
Epoch 3/20
14s - loss: 0.6244 - val_loss: 0.8115
Epoch 4/20
14s - loss: 0.6228 - val_loss: 0.8106
Epoch 5/20
14s - loss: 0.6208 - val_loss: 0.7522
Epoch 6/20
14s - loss: 0.6193 - val_loss: 0.8558
Epoch 7/20
14s - loss: 0.6177 - val_loss: 0.7659
Epoch 8/20
14s - loss: 0.6161 - val_loss: 0.7915
Epoch 9/20
14s - loss: 0.6145 - val_loss: 0.8084
Epoch 00008: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6638 - val_loss: 0.7927
Epoch 2/20
14s - loss: 0.6571 - val_loss: 0.8270
Epoch 3/20
14s - loss: 0.6559 - val_loss: 0.8079
Epoch 4/20
14s - loss: 0.6554 - val_loss: 0.8006
Epoch 5/20
14s - loss: 0.6539 - val_loss: 0.8669
Epoch 00004: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6778 - val_loss: 0.8485
Epoch 2/20
14s - loss: 0.6736 - val_loss: 0.8458
Epoch 3/20
14s - loss: 0.6730 - val_loss: 0.8593
Epoch 4/20
14s - loss: 0.6724 - val_loss: 0.8486
Epoch 5/20
14s - loss: 0.6719 - val_loss: 0.8747
Epoch 6/20
14s - loss: 0.6714 - val_loss: 0.8657
Epoch 00005: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6604 - val_loss: 0.8397
Epoch 2/20
14s - loss: 0.6519 - val_loss: 0.8986
Epoch 3/20
14s - loss: 0.6503 - val_loss: 0.8585
Epoch 4/20
14s - loss: 0.6491 - val_loss: 0.8847
Epoch 5/20
14s - loss: 0.6477 - val_loss: 0.8091
Epoch 6/20
14s - loss: 0.6463 - val_loss: 0.8422
Epoch 7/20
14s - loss: 0.6453 - val_loss: 0.8746
Epoch 8/20
15s - loss: 0.6438 - val_loss: 0.8341
Epoch 9/20
14s - loss: 0.6422 - val_loss: 0.8136
Epoch 00008: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6593 - val_loss: 0.8575
Epoch 2/20
14s - loss: 0.6492 - val_loss: 0.8394
Epoch 3/20
14s - loss: 0.6454 - val_loss: 0.7841
Epoch 4/20
14s - loss: 0.6435 - val_loss: 0.7910
Epoch 5/20
14s - loss: 0.6417 - val_loss: 0.7791
Epoch 6/20
14s - loss: 0.6403 - val_loss: 0.8445
Epoch 7/20
14s - loss: 0.6377 - val_loss: 0.8199
Epoch 8/20
14s - loss: 0.6365 - val_loss: 0.9379
Epoch 9/20
14s - loss: 0.6346 - val_loss: 0.8860
Epoch 00008: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6692 - val_loss: 0.9274
Epoch 2/20
14s - loss: 0.6623 - val_loss: 0.8994
Epoch 3/20
14s - loss: 0.6597 - val_loss: 0.9309
Epoch 4/20
14s - loss: 0.6584 - val_loss: 0.8434
Epoch 5/20
14s - loss: 0.6572 - val_loss: 0.8424
Epoch 6/20
14s - loss: 0.6557 - val_loss: 0.8353
Epoch 7/20
14s - loss: 0.6543 - val_loss: 0.8946
Epoch 8/20
14s - loss: 0.6532 - val_loss: 0.8916
Epoch 9/20
14s - loss: 0.6515 - val_loss: 0.8206
Epoch 10/20
14s - loss: 0.6498 - val_loss: 0.8604
Epoch 11/20
14s - loss: 0.6476 - val_loss: 0.9062
Epoch 12/20
14s - loss: 0.6455 - val_loss: 0.8383
Epoch 13/20
14s - loss: 0.6433 - val_loss: 0.8423
Epoch 00012: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6724 - val_loss: 0.8729
Epoch 2/20
14s - loss: 0.6657 - val_loss: 0.8890
Epoch 3/20
14s - loss: 0.6645 - val_loss: 0.8760
Epoch 4/20
14s - loss: 0.6634 - val_loss: 0.8616
Epoch 5/20
14s - loss: 0.6626 - val_loss: 0.8598
Epoch 6/20
14s - loss: 0.6617 - val_loss: 0.8926
Epoch 7/20
14s - loss: 0.6603 - val_loss: 0.8060
Epoch 8/20
14s - loss: 0.6592 - val_loss: 0.9042
Epoch 9/20
14s - loss: 0.6577 - val_loss: 0.8679
Epoch 10/20
14s - loss: 0.6564 - val_loss: 0.8494
Epoch 11/20
14s - loss: 0.6546 - val_loss: 0.8260
Epoch 00010: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6787 - val_loss: 0.8517
Epoch 2/20
14s - loss: 0.6740 - val_loss: 0.8524
Epoch 3/20
14s - loss: 0.6731 - val_loss: 0.8860
Epoch 4/20
14s - loss: 0.6729 - val_loss: 0.8370
Epoch 5/20
14s - loss: 0.6728 - val_loss: 0.8773
Epoch 6/20
14s - loss: 0.6722 - val_loss: 0.8687
Epoch 7/20
14s - loss: 0.6719 - val_loss: 0.8279
Epoch 8/20
14s - loss: 0.6714 - val_loss: 0.8470
Epoch 9/20
14s - loss: 0.6709 - val_loss: 0.8749
Epoch 10/20
14s - loss: 0.6704 - val_loss: 0.8647
Epoch 11/20
14s - loss: 0.6694 - val_loss: 0.8853
Epoch 00010: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6783 - val_loss: 0.8421
Epoch 2/20
14s - loss: 0.6734 - val_loss: 0.8444
Epoch 3/20
14s - loss: 0.6721 - val_loss: 0.8528
Epoch 4/20
14s - loss: 0.6712 - val_loss: 0.8238
Epoch 5/20
14s - loss: 0.6706 - val_loss: 0.8699
Epoch 6/20
14s - loss: 0.6698 - val_loss: 0.8706
Epoch 7/20
14s - loss: 0.6692 - val_loss: 0.9134
Epoch 8/20
14s - loss: 0.6680 - val_loss: 0.8529
Epoch 00007: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6210 - val_loss: 0.7489
Epoch 2/20
14s - loss: 0.6088 - val_loss: 0.7659
Epoch 3/20
14s - loss: 0.6065 - val_loss: 0.7325
Epoch 4/20
14s - loss: 0.6050 - val_loss: 0.8575
Epoch 5/20
14s - loss: 0.6040 - val_loss: 0.6940
Epoch 6/20
14s - loss: 0.6022 - val_loss: 0.7622
Epoch 7/20
14s - loss: 0.6007 - val_loss: 0.7730
Epoch 8/20
14s - loss: 0.5991 - val_loss: 0.7711
Epoch 9/20
14s - loss: 0.5970 - val_loss: 0.8745
Epoch 00008: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6580 - val_loss: 0.7980
Epoch 2/20
14s - loss: 0.6509 - val_loss: 0.8711
Epoch 3/20
14s - loss: 0.6487 - val_loss: 0.8130
Epoch 4/20
14s - loss: 0.6469 - val_loss: 0.8770
Epoch 5/20
14s - loss: 0.6462 - val_loss: 0.8482
Epoch 00004: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6747 - val_loss: 0.8303
Epoch 2/20
14s - loss: 0.6685 - val_loss: 0.8333
Epoch 3/20
14s - loss: 0.6671 - val_loss: 0.8647
Epoch 4/20
15s - loss: 0.6668 - val_loss: 0.8789
Epoch 5/20
14s - loss: 0.6657 - val_loss: 0.8725
Epoch 00004: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6548 - val_loss: 0.8186
Epoch 2/20
14s - loss: 0.6478 - val_loss: 0.9578
Epoch 3/20
15s - loss: 0.6456 - val_loss: 0.9115
Epoch 4/20
14s - loss: 0.6442 - val_loss: 0.7918
Epoch 5/20
14s - loss: 0.6437 - val_loss: 0.8696
Epoch 6/20
14s - loss: 0.6423 - val_loss: 0.8364
Epoch 7/20
15s - loss: 0.6410 - val_loss: 0.8124
Epoch 8/20
14s - loss: 0.6401 - val_loss: 0.8975
Epoch 00007: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6541 - val_loss: 0.7800
Epoch 2/20
15s - loss: 0.6436 - val_loss: 0.8218
Epoch 3/20
15s - loss: 0.6414 - val_loss: 0.8604
Epoch 4/20
14s - loss: 0.6393 - val_loss: 0.8045
Epoch 5/20
15s - loss: 0.6386 - val_loss: 0.8539
Epoch 00004: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6556 - val_loss: 0.7980
Epoch 2/20
15s - loss: 0.6475 - val_loss: 0.8644
Epoch 3/20
15s - loss: 0.6449 - val_loss: 0.8989
Epoch 4/20
14s - loss: 0.6432 - val_loss: 0.8397
Epoch 5/20
15s - loss: 0.6427 - val_loss: 0.7758
Epoch 6/20
15s - loss: 0.6413 - val_loss: 0.8506
Epoch 7/20
15s - loss: 0.6400 - val_loss: 0.8067
Epoch 8/20
15s - loss: 0.6383 - val_loss: 0.8088
Epoch 9/20
15s - loss: 0.6368 - val_loss: 0.8851
Epoch 00008: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6500 - val_loss: 0.8364
Epoch 2/20
15s - loss: 0.6375 - val_loss: 0.8649
Epoch 3/20
15s - loss: 0.6332 - val_loss: 0.8487
Epoch 4/20
15s - loss: 0.6315 - val_loss: 0.8101
Epoch 5/20
15s - loss: 0.6295 - val_loss: 0.7636
Epoch 6/20
15s - loss: 0.6273 - val_loss: 0.7933
Epoch 7/20
15s - loss: 0.6261 - val_loss: 0.8361
Epoch 8/20
15s - loss: 0.6246 - val_loss: 0.8032
Epoch 9/20
15s - loss: 0.6230 - val_loss: 0.8615
Epoch 00008: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6608 - val_loss: 0.8476
Epoch 2/20
15s - loss: 0.6531 - val_loss: 0.8472
Epoch 3/20
15s - loss: 0.6513 - val_loss: 0.7901
Epoch 4/20
15s - loss: 0.6497 - val_loss: 0.9174
Epoch 5/20
15s - loss: 0.6487 - val_loss: 0.8178
Epoch 6/20
15s - loss: 0.6471 - val_loss: 0.8869
Epoch 7/20
15s - loss: 0.6458 - val_loss: 0.8539
Epoch 00006: early stopping
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6522 - val_loss: 0.8675
Epoch 2/20
15s - loss: 0.6434 - val_loss: 0.8161
Epoch 3/20
15s - loss: 0.6404 - val_loss: 0.8532
Epoch 4/20
15s - loss: 0.6387 - val_loss: 0.8256
Epoch 5/20
15s - loss: 0.6369 - val_loss: 0.7807
Epoch 6/20
15s - loss: 0.6357 - val_loss: 0.7951
Epoch 7/20
15s - loss: 0.6344 - val_loss: 0.8266
Epoch 8/20
15s - loss: 0.6333 - val_loss: 0.8459
Epoch 9/20
15s - loss: 0.6316 - val_loss: 0.7463
Epoch 10/20
15s - loss: 0.6302 - val_loss: 0.8048
Epoch 11/20
15s - loss: 0.6282 - val_loss: 0.8968
Epoch 12/20
15s - loss: 0.6268 - val_loss: 0.8789
Epoch 13/20
15s - loss: 0.6250 - val_loss: 0.8379
Epoch 00012: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6712 - val_loss: 0.8631
Epoch 2/20
15s - loss: 0.6657 - val_loss: 0.8768
Epoch 3/20
15s - loss: 0.6651 - val_loss: 0.8619
Epoch 4/20
15s - loss: 0.6645 - val_loss: 0.8450
Epoch 5/20
15s - loss: 0.6638 - val_loss: 0.8063
Epoch 6/20
15s - loss: 0.6632 - val_loss: 0.8781
Epoch 7/20
15s - loss: 0.6624 - val_loss: 0.8928
Epoch 8/20
15s - loss: 0.6614 - val_loss: 0.8625
Epoch 9/20
15s - loss: 0.6603 - val_loss: 0.8637
Epoch 00008: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6746 - val_loss: 0.8467
Epoch 2/20
15s - loss: 0.6688 - val_loss: 0.8026
Epoch 3/20
15s - loss: 0.6678 - val_loss: 0.8684
Epoch 4/20
15s - loss: 0.6669 - val_loss: 0.8307
Epoch 5/20
15s - loss: 0.6659 - val_loss: 0.8734
Epoch 6/20
15s - loss: 0.6651 - val_loss: 0.8947
Epoch 00005: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6541 - val_loss: 0.8921
Epoch 2/20
15s - loss: 0.6414 - val_loss: 0.8290
Epoch 3/20
15s - loss: 0.6368 - val_loss: 0.8433
Epoch 4/20
15s - loss: 0.6345 - val_loss: 0.8310
Epoch 5/20
15s - loss: 0.6323 - val_loss: 0.8033
Epoch 6/20
15s - loss: 0.6301 - val_loss: 0.8028
Epoch 7/20
15s - loss: 0.6279 - val_loss: 0.8021
Epoch 8/20
15s - loss: 0.6262 - val_loss: 0.8095
Epoch 9/20
15s - loss: 0.6241 - val_loss: 0.7360
Epoch 10/20
15s - loss: 0.6218 - val_loss: 0.8168
Epoch 11/20
15s - loss: 0.6192 - val_loss: 0.7639
Epoch 12/20
15s - loss: 0.6167 - val_loss: 0.8180
Epoch 13/20
15s - loss: 0.6145 - val_loss: 0.8456
Epoch 00012: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6773 - val_loss: 0.8514
Epoch 2/20
15s - loss: 0.6715 - val_loss: 0.8839
Epoch 3/20
15s - loss: 0.6707 - val_loss: 0.8717
Epoch 4/20
15s - loss: 0.6705 - val_loss: 0.8654
Epoch 5/20
15s - loss: 0.6699 - val_loss: 0.8432
Epoch 6/20
15s - loss: 0.6694 - val_loss: 0.8775
Epoch 7/20
15s - loss: 0.6689 - val_loss: 0.8487
Epoch 8/20
15s - loss: 0.6681 - val_loss: 0.9151
Epoch 9/20
15s - loss: 0.6674 - val_loss: 0.8703
Epoch 00008: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6581 - val_loss: 0.8360
Epoch 2/20
15s - loss: 0.6482 - val_loss: 0.8085
Epoch 3/20
15s - loss: 0.6452 - val_loss: 0.9149
Epoch 4/20
15s - loss: 0.6434 - val_loss: 0.9023
Epoch 5/20
15s - loss: 0.6418 - val_loss: 0.8864
Epoch 6/20
15s - loss: 0.6406 - val_loss: 0.8877
Epoch 00005: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6774 - val_loss: 0.8905
Epoch 2/20
15s - loss: 0.6720 - val_loss: 0.8604
Epoch 3/20
15s - loss: 0.6704 - val_loss: 0.8947
Epoch 4/20
15s - loss: 0.6700 - val_loss: 0.9167
Epoch 5/20
15s - loss: 0.6695 - val_loss: 0.8364
Epoch 6/20
15s - loss: 0.6687 - val_loss: 0.8727
Epoch 7/20
15s - loss: 0.6679 - val_loss: 0.8632
Epoch 8/20
15s - loss: 0.6672 - val_loss: 0.8556
Epoch 9/20
15s - loss: 0.6662 - val_loss: 0.8210
Epoch 10/20
15s - loss: 0.6649 - val_loss: 0.9002
Epoch 11/20
15s - loss: 0.6634 - val_loss: 0.8979
Epoch 12/20
15s - loss: 0.6615 - val_loss: 0.8568
Epoch 13/20
15s - loss: 0.6597 - val_loss: 0.8959
Epoch 00012: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6468 - val_loss: 0.8378
Epoch 2/20
15s - loss: 0.6367 - val_loss: 0.8087
Epoch 3/20
15s - loss: 0.6344 - val_loss: 0.8583
Epoch 4/20
15s - loss: 0.6332 - val_loss: 0.7843
Epoch 5/20
15s - loss: 0.6318 - val_loss: 0.7359
Epoch 6/20
15s - loss: 0.6303 - val_loss: 0.7998
Epoch 7/20
15s - loss: 0.6287 - val_loss: 0.8115
Epoch 8/20
15s - loss: 0.6273 - val_loss: 0.8325
Epoch 9/20
15s - loss: 0.6262 - val_loss: 0.7609
Epoch 00008: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6573 - val_loss: 0.7619
Epoch 2/20
15s - loss: 0.6498 - val_loss: 0.8549
Epoch 3/20
15s - loss: 0.6469 - val_loss: 0.8023
Epoch 4/20
15s - loss: 0.6457 - val_loss: 0.8045
Epoch 5/20
15s - loss: 0.6449 - val_loss: 0.7450
Epoch 6/20
15s - loss: 0.6437 - val_loss: 0.8311
Epoch 7/20
15s - loss: 0.6429 - val_loss: 0.7949
Epoch 8/20
15s - loss: 0.6411 - val_loss: 0.8093
Epoch 9/20
15s - loss: 0.6400 - val_loss: 0.7806
Epoch 00008: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6598 - val_loss: 0.8467
Epoch 2/20
15s - loss: 0.6523 - val_loss: 0.7868
Epoch 3/20
15s - loss: 0.6502 - val_loss: 0.8699
Epoch 4/20
15s - loss: 0.6494 - val_loss: 0.8174
Epoch 5/20
15s - loss: 0.6482 - val_loss: 0.7894
Epoch 6/20
15s - loss: 0.6470 - val_loss: 0.9031
Epoch 00005: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  1.04858094e+06,  -9.35513665e-57]), 'nit': 1, 'funcalls': 28}
  " state: %s" % convergence_dict)
Using TensorFlow backend.

Main settings:
  Algorithm:                 carl

Options:
  Number of epochs:          20
  Number of hidden layers:   3

Theta 0 [ 0.  0.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
2018-01-13 10:10:20.677273: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 10:10:20.680647: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 10:10:20.680657: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 10:10:20.680662: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 10:10:20.680666: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-13 10:10:20.978033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:09:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-01-13 10:10:20.978068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-01-13 10:10:20.978074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-01-13 10:10:20.978082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:09:00.0)
14s - loss: 0.6697 - val_loss: 0.8502
Epoch 2/20
12s - loss: 0.6656 - val_loss: 0.8482
Epoch 3/20
12s - loss: 0.6646 - val_loss: 0.8056
Epoch 4/20
12s - loss: 0.6638 - val_loss: 0.8319
Epoch 5/20
12s - loss: 0.6624 - val_loss: 0.8777
Epoch 6/20
12s - loss: 0.6613 - val_loss: 0.8170
Epoch 7/20
12s - loss: 0.6607 - val_loss: 0.8769
Epoch 00006: early stopping
Theta 13 [-1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6375 - val_loss: 0.7643
Epoch 2/20
12s - loss: 0.6234 - val_loss: 0.7982
Epoch 3/20
12s - loss: 0.6199 - val_loss: 0.7205
Epoch 4/20
12s - loss: 0.6167 - val_loss: 0.8338
Epoch 5/20
12s - loss: 0.6150 - val_loss: 0.7562
Epoch 6/20
12s - loss: 0.6130 - val_loss: 0.8002
Epoch 7/20
12s - loss: 0.6112 - val_loss: 0.7734
Epoch 00006: early stopping
Theta 14 [-1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6274 - val_loss: 0.8099
Epoch 2/20
12s - loss: 0.6112 - val_loss: 0.7831
Epoch 3/20
13s - loss: 0.6078 - val_loss: 0.7886
Epoch 4/20
13s - loss: 0.6050 - val_loss: 0.7813
Epoch 5/20
12s - loss: 0.6028 - val_loss: 0.7763
Epoch 6/20
12s - loss: 0.6005 - val_loss: 0.7701
Epoch 7/20
12s - loss: 0.5982 - val_loss: 0.7859
Epoch 8/20
13s - loss: 0.5955 - val_loss: 0.7812
Epoch 9/20
12s - loss: 0.5937 - val_loss: 0.7334
Epoch 10/20
12s - loss: 0.5913 - val_loss: 0.7569
Epoch 11/20
12s - loss: 0.5893 - val_loss: 0.7932
Epoch 12/20
12s - loss: 0.5866 - val_loss: 0.8184
Epoch 13/20
13s - loss: 0.5838 - val_loss: 0.7351
Epoch 00012: early stopping
Theta 15 [ 1. -1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6096 - val_loss: 0.7966
Epoch 2/20
12s - loss: 0.5973 - val_loss: 0.7327
Epoch 3/20
12s - loss: 0.5944 - val_loss: 0.6903
Epoch 4/20
13s - loss: 0.5932 - val_loss: 0.8070
Epoch 5/20
12s - loss: 0.5914 - val_loss: 0.7632
Epoch 6/20
12s - loss: 0.5898 - val_loss: 0.7793
Epoch 7/20
12s - loss: 0.5882 - val_loss: 0.8141
Epoch 00006: early stopping
Theta 16 [ 1.  1.]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6674 - val_loss: 0.8767
Epoch 2/20
13s - loss: 0.6623 - val_loss: 0.8033
Epoch 3/20
13s - loss: 0.6614 - val_loss: 0.8559
Epoch 4/20
13s - loss: 0.6609 - val_loss: 0.8514
Epoch 5/20
13s - loss: 0.6605 - val_loss: 0.8296
Epoch 6/20
13s - loss: 0.6601 - val_loss: 0.8324
Epoch 00005: early stopping
Theta 9 [-0.5 -0.5]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6573 - val_loss: 0.9167
Epoch 2/20
13s - loss: 0.6491 - val_loss: 0.8505
Epoch 3/20
13s - loss: 0.6461 - val_loss: 0.7771
Epoch 4/20
13s - loss: 0.6449 - val_loss: 0.8777
Epoch 5/20
13s - loss: 0.6434 - val_loss: 0.8252
Epoch 6/20
13s - loss: 0.6422 - val_loss: 0.8259
Epoch 7/20
13s - loss: 0.6414 - val_loss: 0.8036
Epoch 00006: early stopping
Theta 422 [-0.19238158 -0.59962178]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6611 - val_loss: 0.7789
Epoch 2/20
13s - loss: 0.6536 - val_loss: 0.8404
Epoch 3/20
13s - loss: 0.6512 - val_loss: 0.7541
Epoch 4/20
13s - loss: 0.6496 - val_loss: 0.8536
Epoch 5/20
13s - loss: 0.6482 - val_loss: 0.8477
Epoch 6/20
13s - loss: 0.6470 - val_loss: 0.8559
Epoch 7/20
13s - loss: 0.6456 - val_loss: 0.7715
Epoch 00006: early stopping
Theta 956 [ 0.89009995 -0.46538046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6430 - val_loss: 0.8726
Epoch 2/20
13s - loss: 0.6334 - val_loss: 0.8178
Epoch 3/20
13s - loss: 0.6314 - val_loss: 0.7724
Epoch 4/20
13s - loss: 0.6298 - val_loss: 0.7984
Epoch 5/20
13s - loss: 0.6281 - val_loss: 0.7765
Epoch 6/20
13s - loss: 0.6267 - val_loss: 0.7738
Epoch 7/20
13s - loss: 0.6252 - val_loss: 0.7631
Epoch 8/20
13s - loss: 0.6237 - val_loss: 0.8132
Epoch 9/20
13s - loss: 0.6217 - val_loss: 0.7929
Epoch 10/20
13s - loss: 0.6199 - val_loss: 0.7364
Epoch 11/20
13s - loss: 0.6177 - val_loss: 0.8131
Epoch 12/20
13s - loss: 0.6153 - val_loss: 0.7997
Epoch 13/20
13s - loss: 0.6127 - val_loss: 0.8532
Epoch 14/20
13s - loss: 0.6098 - val_loss: 0.7801
Epoch 00013: early stopping
Theta 666 [ 0.30761222  0.31321016]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6850 - val_loss: 0.9076
Epoch 2/20
13s - loss: 0.6807 - val_loss: 0.8569
Epoch 3/20
13s - loss: 0.6794 - val_loss: 0.9046
Epoch 4/20
13s - loss: 0.6792 - val_loss: 0.8658
Epoch 5/20
13s - loss: 0.6792 - val_loss: 0.8959
Epoch 6/20
13s - loss: 0.6793 - val_loss: 0.8865
Epoch 00005: early stopping
Theta 802 [ 0.57114539 -0.53482071]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6543 - val_loss: 0.8656
Epoch 2/20
13s - loss: 0.6455 - val_loss: 0.8077
Epoch 3/20
13s - loss: 0.6437 - val_loss: 0.8087
Epoch 4/20
13s - loss: 0.6423 - val_loss: 0.7954
Epoch 5/20
13s - loss: 0.6412 - val_loss: 0.8178
Epoch 6/20
13s - loss: 0.6401 - val_loss: 0.7996
Epoch 7/20
13s - loss: 0.6389 - val_loss: 0.8327
Epoch 8/20
13s - loss: 0.6370 - val_loss: 0.8163
Epoch 00007: early stopping
Theta 675 [ 0.32337198 -0.34480615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6690 - val_loss: 0.8074
Epoch 2/20
13s - loss: 0.6612 - val_loss: 0.8486
Epoch 3/20
13s - loss: 0.6602 - val_loss: 0.9460
Epoch 4/20
13s - loss: 0.6587 - val_loss: 0.8531
Epoch 5/20
13s - loss: 0.6581 - val_loss: 0.8981
Epoch 00004: early stopping
Theta 839 [ 0.64589677  0.55027312]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6827 - val_loss: 0.8627
Epoch 2/20
13s - loss: 0.6787 - val_loss: 0.8966
Epoch 3/20
13s - loss: 0.6777 - val_loss: 0.8645
Epoch 4/20
13s - loss: 0.6777 - val_loss: 0.8626
Epoch 5/20
13s - loss: 0.6773 - val_loss: 0.8783
Epoch 6/20
13s - loss: 0.6775 - val_loss: 0.8714
Epoch 7/20
13s - loss: 0.6772 - val_loss: 0.8754
Epoch 8/20
13s - loss: 0.6766 - val_loss: 0.8891
Epoch 00007: early stopping
Theta 699 [ 0.36795424  0.28437234]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6851 - val_loss: 0.9044
Epoch 2/20
13s - loss: 0.6809 - val_loss: 0.8623
Epoch 3/20
13s - loss: 0.6800 - val_loss: 0.8569
Epoch 4/20
13s - loss: 0.6796 - val_loss: 0.9002
Epoch 5/20
13s - loss: 0.6794 - val_loss: 0.8861
Epoch 6/20
13s - loss: 0.6795 - val_loss: 0.8594
Epoch 7/20
13s - loss: 0.6795 - val_loss: 0.8716
Epoch 00006: early stopping
Theta 820 [ 0.60259509 -0.25412776]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6639 - val_loss: 0.8492
Epoch 2/20
13s - loss: 0.6558 - val_loss: 0.8096
Epoch 3/20
13s - loss: 0.6541 - val_loss: 0.8242
Epoch 4/20
13s - loss: 0.6527 - val_loss: 0.8251
Epoch 5/20
13s - loss: 0.6522 - val_loss: 0.8975
Epoch 6/20
13s - loss: 0.6514 - val_loss: 0.8293
Epoch 00005: early stopping
Theta 203 [-0.61645122 -0.16986252]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6564 - val_loss: 0.7669
Epoch 2/20
13s - loss: 0.6483 - val_loss: 0.8130
Epoch 3/20
13s - loss: 0.6463 - val_loss: 0.7968
Epoch 4/20
13s - loss: 0.6450 - val_loss: 0.8302
Epoch 5/20
13s - loss: 0.6434 - val_loss: 0.8516
Epoch 00004: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6582 - val_loss: 0.8751
Epoch 2/20
13s - loss: 0.6503 - val_loss: 0.8773
Epoch 3/20
13s - loss: 0.6486 - val_loss: 0.8212
Epoch 4/20
13s - loss: 0.6473 - val_loss: 0.8104
Epoch 5/20
13s - loss: 0.6463 - val_loss: 0.8960
Epoch 6/20
13s - loss: 0.6449 - val_loss: 0.8193
Epoch 7/20
13s - loss: 0.6439 - val_loss: 0.8885
Epoch 8/20
13s - loss: 0.6425 - val_loss: 0.7911
Epoch 9/20
13s - loss: 0.6411 - val_loss: 0.8196
Epoch 10/20
13s - loss: 0.6394 - val_loss: 0.8615
Epoch 11/20
13s - loss: 0.6382 - val_loss: 0.8075
Epoch 12/20
13s - loss: 0.6364 - val_loss: 0.8057
Epoch 00011: early stopping
Theta 634 [ 0.24693496 -0.77942393]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6564 - val_loss: 0.7575
Epoch 2/20
13s - loss: 0.6455 - val_loss: 0.8512
Epoch 3/20
13s - loss: 0.6429 - val_loss: 0.8411
Epoch 4/20
13s - loss: 0.6412 - val_loss: 0.8138
Epoch 5/20
13s - loss: 0.6399 - val_loss: 0.7692
Epoch 00004: early stopping
Theta 371 [-0.2996083   0.60243551]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6705 - val_loss: 0.8246
Epoch 2/20
13s - loss: 0.6642 - val_loss: 0.8262
Epoch 3/20
13s - loss: 0.6619 - val_loss: 0.8518
Epoch 4/20
13s - loss: 0.6603 - val_loss: 0.8937
Epoch 5/20
13s - loss: 0.6586 - val_loss: 0.8887
Epoch 00004: early stopping
Theta 973 [ 0.93200575 -0.74254176]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6268 - val_loss: 0.7375
Epoch 2/20
13s - loss: 0.6153 - val_loss: 0.7317
Epoch 3/20
13s - loss: 0.6136 - val_loss: 0.7328
Epoch 4/20
13s - loss: 0.6121 - val_loss: 0.7803
Epoch 5/20
13s - loss: 0.6107 - val_loss: 0.7415
Epoch 6/20
13s - loss: 0.6090 - val_loss: 0.7884
Epoch 00005: early stopping
Theta 742 [ 0.45658682 -0.71556256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6516 - val_loss: 0.8488
Epoch 2/20
13s - loss: 0.6390 - val_loss: 0.8457
Epoch 3/20
13s - loss: 0.6366 - val_loss: 0.8239
Epoch 4/20
13s - loss: 0.6348 - val_loss: 0.8569
Epoch 5/20
13s - loss: 0.6336 - val_loss: 0.8167
Epoch 6/20
13s - loss: 0.6323 - val_loss: 0.8591
Epoch 7/20
13s - loss: 0.6305 - val_loss: 0.8132
Epoch 8/20
13s - loss: 0.6297 - val_loss: 0.7796
Epoch 9/20
13s - loss: 0.6274 - val_loss: 0.8359
Epoch 10/20
13s - loss: 0.6263 - val_loss: 0.8480
Epoch 11/20
13s - loss: 0.6244 - val_loss: 0.8555
Epoch 12/20
13s - loss: 0.6226 - val_loss: 0.8394
Epoch 00011: early stopping
Theta 901 [ 0.76761916  0.18918917]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6735 - val_loss: 0.8863
Epoch 2/20
13s - loss: 0.6688 - val_loss: 0.8639
Epoch 3/20
13s - loss: 0.6683 - val_loss: 0.8684
Epoch 4/20
13s - loss: 0.6675 - val_loss: 0.8641
Epoch 5/20
13s - loss: 0.6668 - val_loss: 0.8447
Epoch 6/20
13s - loss: 0.6662 - val_loss: 0.9256
Epoch 7/20
13s - loss: 0.6654 - val_loss: 0.8823
Epoch 8/20
13s - loss: 0.6641 - val_loss: 0.8521
Epoch 9/20
13s - loss: 0.6630 - val_loss: 0.8587
Epoch 00008: early stopping
Theta 181 [-0.67220747  0.99327244]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6482 - val_loss: 0.8061
Epoch 2/20
13s - loss: 0.6358 - val_loss: 0.8503
Epoch 3/20
13s - loss: 0.6315 - val_loss: 0.8241
Epoch 4/20
13s - loss: 0.6291 - val_loss: 0.7667
Epoch 5/20
13s - loss: 0.6269 - val_loss: 0.7876
Epoch 6/20
13s - loss: 0.6244 - val_loss: 0.8640
Epoch 7/20
13s - loss: 0.6227 - val_loss: 0.7953
Epoch 8/20
13s - loss: 0.6204 - val_loss: 0.7719
Epoch 00007: early stopping
Theta 82 [-0.86582211  0.18873229]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6541 - val_loss: 0.8184
Epoch 2/20
13s - loss: 0.6445 - val_loss: 0.8091
Epoch 3/20
13s - loss: 0.6415 - val_loss: 0.8406
Epoch 4/20
13s - loss: 0.6400 - val_loss: 0.7850
Epoch 5/20
13s - loss: 0.6381 - val_loss: 0.8243
Epoch 6/20
13s - loss: 0.6364 - val_loss: 0.8660
Epoch 7/20
13s - loss: 0.6350 - val_loss: 0.7850
Epoch 8/20
13s - loss: 0.6332 - val_loss: 0.7929
Epoch 9/20
13s - loss: 0.6314 - val_loss: 0.8632
Epoch 10/20
13s - loss: 0.6299 - val_loss: 0.7984
Epoch 11/20
13s - loss: 0.6277 - val_loss: 0.8484
Epoch 00010: early stopping
Theta 937 [ 0.84175328  0.06646314]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6663 - val_loss: 0.7880
Epoch 2/20
13s - loss: 0.6604 - val_loss: 0.8192
Epoch 3/20
13s - loss: 0.6597 - val_loss: 0.8597
Epoch 4/20
13s - loss: 0.6588 - val_loss: 0.8025
Epoch 5/20
13s - loss: 0.6577 - val_loss: 0.8883
Epoch 00004: early stopping
Theta 510 [-0.02257083 -0.17754257]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6668 - val_loss: 0.8490
Epoch 2/20
13s - loss: 0.6616 - val_loss: 0.8512
Epoch 3/20
13s - loss: 0.6600 - val_loss: 0.8387
Epoch 4/20
13s - loss: 0.6588 - val_loss: 0.8490
Epoch 5/20
13s - loss: 0.6581 - val_loss: 0.8577
Epoch 6/20
13s - loss: 0.6572 - val_loss: 0.8044
Epoch 7/20
13s - loss: 0.6561 - val_loss: 0.8359
Epoch 8/20
13s - loss: 0.6552 - val_loss: 0.8296
Epoch 9/20
13s - loss: 0.6539 - val_loss: 0.8529
Epoch 10/20
13s - loss: 0.6529 - val_loss: 0.7972
Epoch 11/20
13s - loss: 0.6512 - val_loss: 0.8853
Epoch 12/20
13s - loss: 0.6496 - val_loss: 0.8868
Epoch 13/20
13s - loss: 0.6476 - val_loss: 0.8824
Epoch 14/20
13s - loss: 0.6455 - val_loss: 0.8423
Epoch 00013: early stopping
Theta 919 [ 0.80563564 -0.3828255 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6505 - val_loss: 0.7582
Epoch 2/20
13s - loss: 0.6424 - val_loss: 0.7256
Epoch 3/20
13s - loss: 0.6408 - val_loss: 0.8297
Epoch 4/20
13s - loss: 0.6391 - val_loss: 0.7753
Epoch 5/20
13s - loss: 0.6377 - val_loss: 0.8489
Epoch 6/20
13s - loss: 0.6365 - val_loss: 0.8423
Epoch 00005: early stopping
Theta 745 [ 0.45758533  0.23764021]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6845 - val_loss: 0.8458
Epoch 2/20
13s - loss: 0.6798 - val_loss: 0.8647
Epoch 3/20
13s - loss: 0.6784 - val_loss: 0.8723
Epoch 4/20
13s - loss: 0.6782 - val_loss: 0.8816
Epoch 5/20
13s - loss: 0.6781 - val_loss: 0.9395
Epoch 00004: early stopping
Theta 588 [ 0.14532057 -0.99903057]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6483 - val_loss: 0.7561
Epoch 2/20
13s - loss: 0.6357 - val_loss: 0.7582
Epoch 3/20
13s - loss: 0.6332 - val_loss: 0.8818
Epoch 4/20
13s - loss: 0.6313 - val_loss: 0.8579
Epoch 5/20
13s - loss: 0.6289 - val_loss: 0.8649
Epoch 00004: early stopping
Theta 804 [ 0.57747224  0.07115072]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6778 - val_loss: 0.8508
Epoch 2/20
13s - loss: 0.6724 - val_loss: 0.8360
Epoch 3/20
13s - loss: 0.6715 - val_loss: 0.8984
Epoch 4/20
13s - loss: 0.6709 - val_loss: 0.8855
Epoch 5/20
13s - loss: 0.6700 - val_loss: 0.8348
Epoch 6/20
13s - loss: 0.6694 - val_loss: 0.8729
Epoch 7/20
13s - loss: 0.6684 - val_loss: 0.8257
Epoch 8/20
13s - loss: 0.6675 - val_loss: 0.8764
Epoch 9/20
13s - loss: 0.6666 - val_loss: 0.8635
Epoch 10/20
13s - loss: 0.6655 - val_loss: 0.8300
Epoch 11/20
13s - loss: 0.6640 - val_loss: 0.8272
Epoch 00010: early stopping
Theta 963 [ 0.90819175 -0.62237577]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6337 - val_loss: 0.8132
Epoch 2/20
13s - loss: 0.6223 - val_loss: 0.8774
Epoch 3/20
13s - loss: 0.6203 - val_loss: 0.7616
Epoch 4/20
13s - loss: 0.6190 - val_loss: 0.8107
Epoch 5/20
13s - loss: 0.6174 - val_loss: 0.8441
Epoch 6/20
13s - loss: 0.6163 - val_loss: 0.7428
Epoch 7/20
13s - loss: 0.6150 - val_loss: 0.7860
Epoch 8/20
13s - loss: 0.6129 - val_loss: 0.8090
Epoch 9/20
13s - loss: 0.6110 - val_loss: 0.7883
Epoch 10/20
13s - loss: 0.6088 - val_loss: 0.8003
Epoch 00009: early stopping
Theta 396 [-0.24354882  0.89907487]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6670 - val_loss: 0.8390
Epoch 2/20
13s - loss: 0.6583 - val_loss: 0.7816
Epoch 3/20
13s - loss: 0.6553 - val_loss: 0.9174
Epoch 4/20
13s - loss: 0.6532 - val_loss: 0.9190
Epoch 5/20
13s - loss: 0.6518 - val_loss: 0.8428
Epoch 6/20
13s - loss: 0.6504 - val_loss: 0.8968
Epoch 00005: early stopping
Theta 62 [-0.91016569  0.09832916]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
13s - loss: 0.6482 - val_loss: 0.9297
Epoch 2/20
13s - loss: 0.6378 - val_loss: 0.7619
Epoch 3/20
13s - loss: 0.6348 - val_loss: 0.7884
Epoch 4/20
13s - loss: 0.6331 - val_loss: 0.8587
Epoch 5/20
13s - loss: 0.6319 - val_loss: 0.8318
Epoch 6/20
13s - loss: 0.6298 - val_loss: 0.7990
Epoch 00005: early stopping
Theta 401 [-0.23817276  0.51270026]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6727 - val_loss: 0.8515
Epoch 2/20
13s - loss: 0.6663 - val_loss: 0.8304
Epoch 3/20
13s - loss: 0.6647 - val_loss: 0.8497
Epoch 4/20
13s - loss: 0.6634 - val_loss: 0.8629
Epoch 5/20
13s - loss: 0.6618 - val_loss: 0.8465
Epoch 6/20
13s - loss: 0.6609 - val_loss: 0.8521
Epoch 00005: early stopping
Theta 925 [ 0.81840142 -0.15652572]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6604 - val_loss: 0.8587
Epoch 2/20
13s - loss: 0.6531 - val_loss: 0.8746
Epoch 3/20
13s - loss: 0.6514 - val_loss: 0.9238
Epoch 4/20
13s - loss: 0.6506 - val_loss: 0.8306
Epoch 5/20
13s - loss: 0.6498 - val_loss: 0.8546
Epoch 6/20
13s - loss: 0.6486 - val_loss: 0.9161
Epoch 7/20
13s - loss: 0.6479 - val_loss: 0.8282
Epoch 8/20
13s - loss: 0.6465 - val_loss: 0.8492
Epoch 9/20
13s - loss: 0.6451 - val_loss: 0.7845
Epoch 10/20
13s - loss: 0.6435 - val_loss: 0.8150
Epoch 11/20
13s - loss: 0.6420 - val_loss: 0.8285
Epoch 12/20
13s - loss: 0.6405 - val_loss: 0.8677
Epoch 13/20
13s - loss: 0.6385 - val_loss: 0.8301
Epoch 00012: early stopping
Theta 874 [ 0.70345114 -0.82047772]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6339 - val_loss: 0.8407
Epoch 2/20
13s - loss: 0.6233 - val_loss: 0.7945
Epoch 3/20
13s - loss: 0.6211 - val_loss: 0.8281
Epoch 4/20
13s - loss: 0.6200 - val_loss: 0.8488
Epoch 5/20
13s - loss: 0.6183 - val_loss: 0.7562
Epoch 6/20
13s - loss: 0.6167 - val_loss: 0.7187
Epoch 7/20
13s - loss: 0.6160 - val_loss: 0.8085
Epoch 8/20
13s - loss: 0.6143 - val_loss: 0.7424
Epoch 9/20
13s - loss: 0.6128 - val_loss: 0.7795
Epoch 10/20
13s - loss: 0.6111 - val_loss: 0.7920
Epoch 00009: early stopping
Theta 770 [ 0.51044067 -0.52312918]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6586 - val_loss: 0.8471
Epoch 2/20
13s - loss: 0.6494 - val_loss: 0.8041
Epoch 3/20
13s - loss: 0.6467 - val_loss: 0.8328
Epoch 4/20
13s - loss: 0.6457 - val_loss: 0.8153
Epoch 5/20
13s - loss: 0.6448 - val_loss: 0.8520
Epoch 6/20
13s - loss: 0.6433 - val_loss: 0.8773
Epoch 00005: early stopping
Theta 108 [-0.81715907  0.17467073]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6541 - val_loss: 0.8114
Epoch 2/20
13s - loss: 0.6454 - val_loss: 0.8242
Epoch 3/20
13s - loss: 0.6431 - val_loss: 0.7456
Epoch 4/20
13s - loss: 0.6408 - val_loss: 0.8277
Epoch 5/20
13s - loss: 0.6390 - val_loss: 0.8104
Epoch 6/20
13s - loss: 0.6374 - val_loss: 0.8127
Epoch 7/20
13s - loss: 0.6357 - val_loss: 0.8936
Epoch 00006: early stopping
Theta 179 [-0.67350217  0.25822043]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6617 - val_loss: 0.8623
Epoch 2/20
13s - loss: 0.6530 - val_loss: 0.8466
Epoch 3/20
13s - loss: 0.6504 - val_loss: 0.8052
Epoch 4/20
13s - loss: 0.6481 - val_loss: 0.9116
Epoch 5/20
13s - loss: 0.6473 - val_loss: 0.8813
Epoch 6/20
13s - loss: 0.6455 - val_loss: 0.8196
Epoch 7/20
13s - loss: 0.6440 - val_loss: 0.8039
Epoch 8/20
13s - loss: 0.6426 - val_loss: 0.8519
Epoch 9/20
13s - loss: 0.6403 - val_loss: 0.7893
Epoch 10/20
13s - loss: 0.6385 - val_loss: 0.8552
Epoch 11/20
13s - loss: 0.6362 - val_loss: 0.8622
Epoch 12/20
13s - loss: 0.6344 - val_loss: 0.8358
Epoch 13/20
13s - loss: 0.6320 - val_loss: 0.8936
Epoch 00012: early stopping
Theta 669 [ 0.31134279 -0.91513634]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6497 - val_loss: 0.8311
Epoch 2/20
13s - loss: 0.6387 - val_loss: 0.8432
Epoch 3/20
13s - loss: 0.6356 - val_loss: 0.8516
Epoch 4/20
13s - loss: 0.6335 - val_loss: 0.7513
Epoch 5/20
13s - loss: 0.6311 - val_loss: 0.8212
Epoch 6/20
13s - loss: 0.6295 - val_loss: 0.8088
Epoch 7/20
13s - loss: 0.6279 - val_loss: 0.7688
Epoch 8/20
13s - loss: 0.6267 - val_loss: 0.7914
Epoch 00007: early stopping
Theta 758 [ 0.48555393  0.60272842]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6843 - val_loss: 0.8713
Epoch 2/20
13s - loss: 0.6802 - val_loss: 0.8425
Epoch 3/20
13s - loss: 0.6792 - val_loss: 0.8546
Epoch 4/20
13s - loss: 0.6790 - val_loss: 0.8691
Epoch 5/20
13s - loss: 0.6792 - val_loss: 0.8504
Epoch 6/20
13s - loss: 0.6790 - val_loss: 0.8351
Epoch 7/20
13s - loss: 0.6789 - val_loss: 0.8848
Epoch 8/20
13s - loss: 0.6789 - val_loss: 0.8898
Epoch 9/20
13s - loss: 0.6788 - val_loss: 0.8442
Epoch 10/20
13s - loss: 0.6787 - val_loss: 0.8900
Epoch 00009: early stopping
Theta 113 [-0.81090693 -0.35089443]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6473 - val_loss: 0.8762
Epoch 2/20
13s - loss: 0.6374 - val_loss: 0.8416
Epoch 3/20
13s - loss: 0.6359 - val_loss: 0.7785
Epoch 4/20
13s - loss: 0.6342 - val_loss: 0.8601
Epoch 5/20
13s - loss: 0.6329 - val_loss: 0.8001
Epoch 6/20
13s - loss: 0.6310 - val_loss: 0.7772
Epoch 7/20
13s - loss: 0.6292 - val_loss: 0.8665
Epoch 8/20
13s - loss: 0.6287 - val_loss: 0.8129
Epoch 9/20
13s - loss: 0.6274 - val_loss: 0.7829
Epoch 10/20
13s - loss: 0.6257 - val_loss: 0.8325
Epoch 00009: early stopping
Theta 587 [ 0.14343539 -0.40035765]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6674 - val_loss: 0.8358
Epoch 2/20
13s - loss: 0.6596 - val_loss: 0.8096
Epoch 3/20
13s - loss: 0.6583 - val_loss: 0.8561
Epoch 4/20
13s - loss: 0.6575 - val_loss: 0.8712
Epoch 5/20
13s - loss: 0.6562 - val_loss: 0.8608
Epoch 6/20
13s - loss: 0.6556 - val_loss: 0.8777
Epoch 00005: early stopping
Theta 600 [ 0.16780437 -0.66065983]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6600 - val_loss: 0.8848
Epoch 2/20
13s - loss: 0.6510 - val_loss: 0.8728
Epoch 3/20
13s - loss: 0.6486 - val_loss: 0.8090
Epoch 4/20
13s - loss: 0.6468 - val_loss: 0.8007
Epoch 5/20
13s - loss: 0.6454 - val_loss: 0.8631
Epoch 6/20
13s - loss: 0.6442 - val_loss: 0.8600
Epoch 7/20
13s - loss: 0.6424 - val_loss: 0.8784
Epoch 8/20
13s - loss: 0.6407 - val_loss: 0.7921
Epoch 9/20
13s - loss: 0.6391 - val_loss: 0.7966
Epoch 10/20
13s - loss: 0.6374 - val_loss: 0.8307
Epoch 11/20
13s - loss: 0.6352 - val_loss: 0.8756
Epoch 12/20
13s - loss: 0.6332 - val_loss: 0.8316
Epoch 00011: early stopping
Theta 975 [ 0.93334999 -0.05006023]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6581 - val_loss: 0.7871
Epoch 2/20
13s - loss: 0.6515 - val_loss: 0.8222
Epoch 3/20
13s - loss: 0.6500 - val_loss: 0.8499
Epoch 4/20
13s - loss: 0.6491 - val_loss: 0.8034
Epoch 5/20
13s - loss: 0.6482 - val_loss: 0.8572
Epoch 00004: early stopping
Theta 496 [-0.05130633 -0.92036265]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6560 - val_loss: 0.8336
Epoch 2/20
13s - loss: 0.6442 - val_loss: 0.9458
Epoch 3/20
13s - loss: 0.6406 - val_loss: 0.8199
Epoch 4/20
13s - loss: 0.6388 - val_loss: 0.8938
Epoch 5/20
13s - loss: 0.6370 - val_loss: 0.7743
Epoch 6/20
13s - loss: 0.6354 - val_loss: 0.8353
Epoch 7/20
13s - loss: 0.6338 - val_loss: 0.7977
Epoch 8/20
13s - loss: 0.6320 - val_loss: 0.7706
Epoch 9/20
13s - loss: 0.6303 - val_loss: 0.8583
Epoch 10/20
13s - loss: 0.6283 - val_loss: 0.7866
Epoch 11/20
13s - loss: 0.6263 - val_loss: 0.8624
Epoch 12/20
13s - loss: 0.6239 - val_loss: 0.8778
Epoch 00011: early stopping
Theta 66 [-0.89913448 -0.075021  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6490 - val_loss: 0.7856
Epoch 2/20
13s - loss: 0.6400 - val_loss: 0.8439
Epoch 3/20
13s - loss: 0.6374 - val_loss: 0.8574
Epoch 4/20
13s - loss: 0.6361 - val_loss: 0.8345
Epoch 5/20
13s - loss: 0.6342 - val_loss: 0.7577
Epoch 6/20
13s - loss: 0.6324 - val_loss: 0.8077
Epoch 7/20
13s - loss: 0.6308 - val_loss: 0.7935
Epoch 8/20
13s - loss: 0.6289 - val_loss: 0.8354
Epoch 9/20
13s - loss: 0.6273 - val_loss: 0.8430
Epoch 00008: early stopping
Theta 467 [-0.09097912  0.32569428]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6735 - val_loss: 0.8521
Epoch 2/20
13s - loss: 0.6699 - val_loss: 0.8816
Epoch 3/20
13s - loss: 0.6689 - val_loss: 0.8912
Epoch 4/20
13s - loss: 0.6682 - val_loss: 0.8081
Epoch 5/20
13s - loss: 0.6676 - val_loss: 0.8741
Epoch 6/20
13s - loss: 0.6670 - val_loss: 0.8062
Epoch 7/20
13s - loss: 0.6658 - val_loss: 0.8741
Epoch 8/20
13s - loss: 0.6647 - val_loss: 0.8479
Epoch 9/20
13s - loss: 0.6634 - val_loss: 0.8418
Epoch 10/20
13s - loss: 0.6613 - val_loss: 0.8526
Epoch 00009: early stopping
Theta 412 [-0.21229369  0.15277015]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6656 - val_loss: 0.8299
Epoch 2/20
13s - loss: 0.6624 - val_loss: 0.8591
Epoch 3/20
13s - loss: 0.6612 - val_loss: 0.8864
Epoch 4/20
13s - loss: 0.6603 - val_loss: 0.8756
Epoch 5/20
13s - loss: 0.6594 - val_loss: 0.8650
Epoch 00004: early stopping
Theta 701 [ 0.37293732  0.80702849]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6812 - val_loss: 0.9093
Epoch 2/20
13s - loss: 0.6766 - val_loss: 0.8913
Epoch 3/20
13s - loss: 0.6757 - val_loss: 0.8881
Epoch 4/20
13s - loss: 0.6752 - val_loss: 0.8608
Epoch 5/20
13s - loss: 0.6749 - val_loss: 0.8381
Epoch 6/20
13s - loss: 0.6744 - val_loss: 0.8777
Epoch 7/20
13s - loss: 0.6738 - val_loss: 0.8708
Epoch 8/20
13s - loss: 0.6734 - val_loss: 0.8799
Epoch 9/20
13s - loss: 0.6724 - val_loss: 0.8828
Epoch 00008: early stopping
Theta 986 [ 0.95088094  0.05214484]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6612 - val_loss: 0.8415
Epoch 2/20
13s - loss: 0.6553 - val_loss: 0.8117
Epoch 3/20
13s - loss: 0.6541 - val_loss: 0.8377
Epoch 4/20
13s - loss: 0.6535 - val_loss: 0.8636
Epoch 5/20
13s - loss: 0.6528 - val_loss: 0.8687
Epoch 6/20
13s - loss: 0.6516 - val_loss: 0.8568
Epoch 00005: early stopping
Theta 598 [ 0.16578311 -0.09655258]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6755 - val_loss: 0.8282
Epoch 2/20
13s - loss: 0.6695 - val_loss: 0.8335
Epoch 3/20
13s - loss: 0.6681 - val_loss: 0.9011
Epoch 4/20
13s - loss: 0.6673 - val_loss: 0.8693
Epoch 5/20
13s - loss: 0.6668 - val_loss: 0.8803
Epoch 00004: early stopping
Theta 810 [ 0.58481973 -0.20571565]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6669 - val_loss: 0.7969
Epoch 2/20
13s - loss: 0.6602 - val_loss: 0.8223
Epoch 3/20
14s - loss: 0.6589 - val_loss: 0.8925
Epoch 4/20
13s - loss: 0.6582 - val_loss: 0.8957
Epoch 5/20
13s - loss: 0.6573 - val_loss: 0.8678
Epoch 00004: early stopping
Theta 97 [-0.83949827 -0.85622854]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6484 - val_loss: 0.8173
Epoch 2/20
14s - loss: 0.6369 - val_loss: 0.8016
Epoch 3/20
14s - loss: 0.6333 - val_loss: 0.7807
Epoch 4/20
13s - loss: 0.6311 - val_loss: 0.8292
Epoch 5/20
14s - loss: 0.6285 - val_loss: 0.8534
Epoch 6/20
14s - loss: 0.6270 - val_loss: 0.8336
Epoch 7/20
14s - loss: 0.6253 - val_loss: 0.8466
Epoch 00006: early stopping
Theta 18 [-0.99849038  0.13674514]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6467 - val_loss: 0.8687
Epoch 2/20
13s - loss: 0.6340 - val_loss: 0.8330
Epoch 3/20
14s - loss: 0.6317 - val_loss: 0.8071
Epoch 4/20
14s - loss: 0.6293 - val_loss: 0.8239
Epoch 5/20
14s - loss: 0.6273 - val_loss: 0.8550
Epoch 6/20
14s - loss: 0.6252 - val_loss: 0.7850
Epoch 7/20
14s - loss: 0.6237 - val_loss: 0.8635
Epoch 8/20
14s - loss: 0.6220 - val_loss: 0.8472
Epoch 9/20
13s - loss: 0.6198 - val_loss: 0.8367
Epoch 10/20
14s - loss: 0.6167 - val_loss: 0.8548
Epoch 00009: early stopping
Theta 723 [ 0.42313754  0.04817991]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6814 - val_loss: 0.8669
Epoch 2/20
14s - loss: 0.6748 - val_loss: 0.8612
Epoch 3/20
14s - loss: 0.6742 - val_loss: 0.8617
Epoch 4/20
13s - loss: 0.6736 - val_loss: 0.8978
Epoch 5/20
14s - loss: 0.6735 - val_loss: 0.8546
Epoch 6/20
14s - loss: 0.6725 - val_loss: 0.8589
Epoch 7/20
14s - loss: 0.6717 - val_loss: 0.8236
Epoch 8/20
14s - loss: 0.6712 - val_loss: 0.8815
Epoch 9/20
14s - loss: 0.6701 - val_loss: 0.8703
Epoch 10/20
14s - loss: 0.6686 - val_loss: 0.8410
Epoch 11/20
14s - loss: 0.6670 - val_loss: 0.8841
Epoch 00010: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6619 - val_loss: 0.8582
Epoch 2/20
14s - loss: 0.6536 - val_loss: 0.8811
Epoch 3/20
14s - loss: 0.6512 - val_loss: 0.8420
Epoch 4/20
14s - loss: 0.6488 - val_loss: 0.8055
Epoch 5/20
14s - loss: 0.6478 - val_loss: 0.8659
Epoch 6/20
14s - loss: 0.6457 - val_loss: 0.8278
Epoch 7/20
14s - loss: 0.6443 - val_loss: 0.8480
Epoch 8/20
14s - loss: 0.6424 - val_loss: 0.8090
Epoch 00007: early stopping
Theta 320 [-0.39025216  0.89762413]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6623 - val_loss: 0.8193
Epoch 2/20
14s - loss: 0.6509 - val_loss: 0.8777
Epoch 3/20
14s - loss: 0.6478 - val_loss: 0.8590
Epoch 4/20
14s - loss: 0.6457 - val_loss: 0.8146
Epoch 5/20
14s - loss: 0.6439 - val_loss: 0.7840
Epoch 6/20
14s - loss: 0.6419 - val_loss: 0.8423
Epoch 7/20
14s - loss: 0.6402 - val_loss: 0.8579
Epoch 8/20
14s - loss: 0.6381 - val_loss: 0.8165
Epoch 9/20
14s - loss: 0.6365 - val_loss: 0.8230
Epoch 00008: early stopping
Theta 301 [-0.42496479 -0.29929615]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
14s - loss: 0.6579 - val_loss: 0.8426
Epoch 2/20
14s - loss: 0.6511 - val_loss: 0.7960
Epoch 3/20
14s - loss: 0.6491 - val_loss: 0.8523
Epoch 4/20
14s - loss: 0.6478 - val_loss: 0.7821
Epoch 5/20
14s - loss: 0.6466 - val_loss: 0.8009
Epoch 6/20
14s - loss: 0.6460 - val_loss: 0.8864
Epoch 7/20
14s - loss: 0.6445 - val_loss: 0.8089
Epoch 8/20
14s - loss: 0.6434 - val_loss: 0.8690
Epoch 00007: early stopping
Theta 352 [-0.33117606 -0.06437794]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6597 - val_loss: 0.7787
Epoch 2/20
14s - loss: 0.6541 - val_loss: 0.8593
Epoch 3/20
14s - loss: 0.6528 - val_loss: 0.8172
Epoch 4/20
14s - loss: 0.6517 - val_loss: 0.8845
Epoch 5/20
14s - loss: 0.6505 - val_loss: 0.8319
Epoch 00004: early stopping
Theta 159 [-0.72275143  0.26484372]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6624 - val_loss: 0.8837
Epoch 2/20
14s - loss: 0.6537 - val_loss: 0.8669
Epoch 3/20
14s - loss: 0.6509 - val_loss: 0.8785
Epoch 4/20
14s - loss: 0.6488 - val_loss: 0.8978
Epoch 5/20
14s - loss: 0.6473 - val_loss: 0.8475
Epoch 6/20
14s - loss: 0.6453 - val_loss: 0.8293
Epoch 7/20
14s - loss: 0.6441 - val_loss: 0.7845
Epoch 8/20
14s - loss: 0.6423 - val_loss: 0.8100
Epoch 9/20
14s - loss: 0.6409 - val_loss: 0.8752
Epoch 10/20
14s - loss: 0.6387 - val_loss: 0.8449
Epoch 11/20
14s - loss: 0.6371 - val_loss: 0.7752
Epoch 12/20
14s - loss: 0.6347 - val_loss: 0.7798
Epoch 13/20
14s - loss: 0.6322 - val_loss: 0.8205
Epoch 14/20
14s - loss: 0.6300 - val_loss: 0.8084
Epoch 15/20
14s - loss: 0.6271 - val_loss: 0.8452
Epoch 00014: early stopping
Theta 89 [-0.852803    0.39758022]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6561 - val_loss: 0.8037
Epoch 2/20
14s - loss: 0.6444 - val_loss: 0.8727
Epoch 3/20
14s - loss: 0.6408 - val_loss: 0.8110
Epoch 4/20
14s - loss: 0.6380 - val_loss: 0.8346
Epoch 5/20
14s - loss: 0.6370 - val_loss: 0.8374
Epoch 00004: early stopping
Theta 421 [-0.19372397 -0.5487683 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6612 - val_loss: 0.8032
Epoch 2/20
14s - loss: 0.6524 - val_loss: 0.9114
Epoch 3/20
14s - loss: 0.6502 - val_loss: 0.8636
Epoch 4/20
14s - loss: 0.6489 - val_loss: 0.7893
Epoch 5/20
14s - loss: 0.6475 - val_loss: 0.7945
Epoch 6/20
14s - loss: 0.6463 - val_loss: 0.8329
Epoch 7/20
14s - loss: 0.6449 - val_loss: 0.8272
Epoch 8/20
14s - loss: 0.6433 - val_loss: 0.8197
Epoch 00007: early stopping
Theta 574 [ 0.12059293  0.25501418]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6799 - val_loss: 0.8567
Epoch 2/20
14s - loss: 0.6753 - val_loss: 0.8136
Epoch 3/20
14s - loss: 0.6749 - val_loss: 0.8577
Epoch 4/20
14s - loss: 0.6747 - val_loss: 0.8795
Epoch 5/20
14s - loss: 0.6745 - val_loss: 0.8491
Epoch 6/20
14s - loss: 0.6738 - val_loss: 0.8324
Epoch 00005: early stopping
Theta 923 [ 0.81364542  0.67663973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6774 - val_loss: 0.8499
Epoch 2/20
14s - loss: 0.6727 - val_loss: 0.8686
Epoch 3/20
14s - loss: 0.6721 - val_loss: 0.8841
Epoch 4/20
14s - loss: 0.6714 - val_loss: 0.8661
Epoch 5/20
14s - loss: 0.6710 - val_loss: 0.8524
Epoch 00004: early stopping
Theta 849 [ 0.6583114   0.73535462]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6808 - val_loss: 0.8557
Epoch 2/20
14s - loss: 0.6760 - val_loss: 0.8544
Epoch 3/20
14s - loss: 0.6753 - val_loss: 0.8680
Epoch 4/20
14s - loss: 0.6748 - val_loss: 0.8537
Epoch 5/20
14s - loss: 0.6746 - val_loss: 0.8302
Epoch 6/20
14s - loss: 0.6741 - val_loss: 0.8617
Epoch 7/20
14s - loss: 0.6739 - val_loss: 0.8571
Epoch 8/20
14s - loss: 0.6735 - val_loss: 0.8617
Epoch 9/20
14s - loss: 0.6728 - val_loss: 0.8571
Epoch 00008: early stopping
Theta 299 [-0.43548471  0.24506174]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6677 - val_loss: 0.8330
Epoch 2/20
14s - loss: 0.6619 - val_loss: 0.8498
Epoch 3/20
14s - loss: 0.6602 - val_loss: 0.8365
Epoch 4/20
14s - loss: 0.6590 - val_loss: 0.8753
Epoch 5/20
14s - loss: 0.6580 - val_loss: 0.8363
Epoch 00004: early stopping
Theta 119 [-0.80217018 -0.19137665]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6522 - val_loss: 0.8271
Epoch 2/20
14s - loss: 0.6434 - val_loss: 0.7632
Epoch 3/20
14s - loss: 0.6417 - val_loss: 0.8457
Epoch 4/20
14s - loss: 0.6396 - val_loss: 0.7674
Epoch 5/20
14s - loss: 0.6387 - val_loss: 0.8624
Epoch 6/20
14s - loss: 0.6370 - val_loss: 0.8687
Epoch 00005: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6559 - val_loss: 0.7681
Epoch 2/20
14s - loss: 0.6472 - val_loss: 0.8725
Epoch 3/20
14s - loss: 0.6450 - val_loss: 0.8188
Epoch 4/20
14s - loss: 0.6437 - val_loss: 0.8399
Epoch 5/20
14s - loss: 0.6419 - val_loss: 0.7677
Epoch 6/20
14s - loss: 0.6407 - val_loss: 0.8114
Epoch 7/20
14s - loss: 0.6395 - val_loss: 0.8685
Epoch 8/20
14s - loss: 0.6382 - val_loss: 0.8180
Epoch 9/20
14s - loss: 0.6367 - val_loss: 0.7699
Epoch 00008: early stopping
Theta 939 [ 0.84561864 -0.65874341]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6362 - val_loss: 0.7217
Epoch 2/20
14s - loss: 0.6263 - val_loss: 0.8732
Epoch 3/20
14s - loss: 0.6246 - val_loss: 0.8004
Epoch 4/20
14s - loss: 0.6227 - val_loss: 0.7833
Epoch 5/20
14s - loss: 0.6217 - val_loss: 0.7857
Epoch 00004: early stopping
Theta 402 [-0.23381329 -0.74778958]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6596 - val_loss: 0.8148
Epoch 2/20
14s - loss: 0.6498 - val_loss: 0.8373
Epoch 3/20
14s - loss: 0.6465 - val_loss: 0.8307
Epoch 4/20
14s - loss: 0.6444 - val_loss: 0.8550
Epoch 5/20
14s - loss: 0.6426 - val_loss: 0.8792
Epoch 00004: early stopping
Theta 52 [-0.92568077  0.24722516]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6527 - val_loss: 0.7983
Epoch 2/20
14s - loss: 0.6419 - val_loss: 0.7353
Epoch 3/20
14s - loss: 0.6378 - val_loss: 0.8185
Epoch 4/20
14s - loss: 0.6352 - val_loss: 0.7885
Epoch 5/20
14s - loss: 0.6328 - val_loss: 0.7909
Epoch 6/20
14s - loss: 0.6311 - val_loss: 0.7592
Epoch 00005: early stopping
Theta 787 [ 0.54418497  0.30320758]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6838 - val_loss: 0.8847
Epoch 2/20
14s - loss: 0.6799 - val_loss: 0.8582
Epoch 3/20
14s - loss: 0.6785 - val_loss: 0.8417
Epoch 4/20
14s - loss: 0.6782 - val_loss: 0.9146
Epoch 5/20
14s - loss: 0.6781 - val_loss: 0.9106
Epoch 6/20
14s - loss: 0.6781 - val_loss: 0.8612
Epoch 7/20
14s - loss: 0.6777 - val_loss: 0.8637
Epoch 00006: early stopping
Theta 978 [ 0.9400757   0.37123973]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6703 - val_loss: 0.8603
Epoch 2/20
14s - loss: 0.6656 - val_loss: 0.8397
Epoch 3/20
14s - loss: 0.6648 - val_loss: 0.8809
Epoch 4/20
14s - loss: 0.6645 - val_loss: 0.8202
Epoch 5/20
14s - loss: 0.6635 - val_loss: 0.8829
Epoch 6/20
14s - loss: 0.6632 - val_loss: 0.8706
Epoch 7/20
14s - loss: 0.6622 - val_loss: 0.8486
Epoch 8/20
14s - loss: 0.6612 - val_loss: 0.8814
Epoch 00007: early stopping
Theta 41 [-0.9466884  -0.84207419]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6417 - val_loss: 0.8120
Epoch 2/20
14s - loss: 0.6289 - val_loss: 0.7136
Epoch 3/20
14s - loss: 0.6249 - val_loss: 0.8360
Epoch 4/20
14s - loss: 0.6227 - val_loss: 0.8726
Epoch 5/20
14s - loss: 0.6210 - val_loss: 0.8406
Epoch 6/20
14s - loss: 0.6202 - val_loss: 0.7713
Epoch 00005: early stopping
Theta 873 [ 0.70219015 -0.19960724]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6646 - val_loss: 0.8275
Epoch 2/20
14s - loss: 0.6569 - val_loss: 0.8792
Epoch 3/20
14s - loss: 0.6562 - val_loss: 0.7937
Epoch 4/20
14s - loss: 0.6550 - val_loss: 0.7820
Epoch 5/20
14s - loss: 0.6539 - val_loss: 0.8246
Epoch 6/20
14s - loss: 0.6525 - val_loss: 0.8178
Epoch 7/20
14s - loss: 0.6513 - val_loss: 0.8539
Epoch 8/20
14s - loss: 0.6498 - val_loss: 0.7781
Epoch 9/20
14s - loss: 0.6486 - val_loss: 0.8302
Epoch 10/20
14s - loss: 0.6466 - val_loss: 0.8146
Epoch 11/20
14s - loss: 0.6447 - val_loss: 0.8610
Epoch 12/20
14s - loss: 0.6423 - val_loss: 0.8104
Epoch 00011: early stopping
Theta 533 [ 0.0176752  0.4110256]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6780 - val_loss: 0.9007
Epoch 2/20
14s - loss: 0.6737 - val_loss: 0.8404
Epoch 3/20
14s - loss: 0.6727 - val_loss: 0.8574
Epoch 4/20
14s - loss: 0.6723 - val_loss: 0.8750
Epoch 5/20
14s - loss: 0.6718 - val_loss: 0.8497
Epoch 6/20
14s - loss: 0.6712 - val_loss: 0.8261
Epoch 7/20
14s - loss: 0.6703 - val_loss: 0.8717
Epoch 8/20
14s - loss: 0.6694 - val_loss: 0.8474
Epoch 9/20
14s - loss: 0.6685 - val_loss: 0.8794
Epoch 10/20
14s - loss: 0.6676 - val_loss: 0.8937
Epoch 00009: early stopping
Theta 827 [ 0.62406481 -0.33833102]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6610 - val_loss: 0.9018
Epoch 2/20
14s - loss: 0.6521 - val_loss: 0.7586
Epoch 3/20
14s - loss: 0.6503 - val_loss: 0.8475
Epoch 4/20
14s - loss: 0.6490 - val_loss: 0.8678
Epoch 5/20
14s - loss: 0.6483 - val_loss: 0.8613
Epoch 6/20
14s - loss: 0.6469 - val_loss: 0.8296
Epoch 00005: early stopping
Theta 304 [-0.42112069 -0.83328775]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6595 - val_loss: 0.8911
Epoch 2/20
14s - loss: 0.6494 - val_loss: 0.8124
Epoch 3/20
14s - loss: 0.6460 - val_loss: 0.8563
Epoch 4/20
14s - loss: 0.6438 - val_loss: 0.8023
Epoch 5/20
14s - loss: 0.6417 - val_loss: 0.8211
Epoch 6/20
14s - loss: 0.6399 - val_loss: 0.8144
Epoch 7/20
14s - loss: 0.6378 - val_loss: 0.8339
Epoch 8/20
14s - loss: 0.6360 - val_loss: 0.7225
Epoch 9/20
14s - loss: 0.6339 - val_loss: 0.8403
Epoch 10/20
14s - loss: 0.6324 - val_loss: 0.8586
Epoch 11/20
14s - loss: 0.6300 - val_loss: 0.7897
Epoch 12/20
14s - loss: 0.6278 - val_loss: 0.8648
Epoch 00011: early stopping
Theta 294 [-0.44383773  0.33528586]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6691 - val_loss: 0.8605
Epoch 2/20
14s - loss: 0.6624 - val_loss: 0.8301
Epoch 3/20
14s - loss: 0.6599 - val_loss: 0.8102
Epoch 4/20
14s - loss: 0.6588 - val_loss: 0.8564
Epoch 5/20
14s - loss: 0.6576 - val_loss: 0.8447
Epoch 6/20
14s - loss: 0.6557 - val_loss: 0.8393
Epoch 7/20
14s - loss: 0.6540 - val_loss: 0.8935
Epoch 00006: early stopping
Theta 760 [ 0.49108963 -0.17051546]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6721 - val_loss: 0.8537
Epoch 2/20
14s - loss: 0.6654 - val_loss: 0.8313
Epoch 3/20
14s - loss: 0.6641 - val_loss: 0.8811
Epoch 4/20
14s - loss: 0.6637 - val_loss: 0.8446
Epoch 5/20
14s - loss: 0.6623 - val_loss: 0.8224
Epoch 6/20
14s - loss: 0.6615 - val_loss: 0.8368
Epoch 7/20
14s - loss: 0.6603 - val_loss: 0.8468
Epoch 8/20
14s - loss: 0.6590 - val_loss: 0.8955
Epoch 9/20
14s - loss: 0.6572 - val_loss: 0.8871
Epoch 00008: early stopping
Theta 890 [ 0.74368597  0.764742  ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6787 - val_loss: 0.8860
Epoch 2/20
14s - loss: 0.6743 - val_loss: 0.8590
Epoch 3/20
14s - loss: 0.6732 - val_loss: 0.8541
Epoch 4/20
14s - loss: 0.6728 - val_loss: 0.8710
Epoch 5/20
14s - loss: 0.6725 - val_loss: 0.8435
Epoch 6/20
14s - loss: 0.6720 - val_loss: 0.8514
Epoch 7/20
14s - loss: 0.6715 - val_loss: 0.8770
Epoch 8/20
14s - loss: 0.6709 - val_loss: 0.9033
Epoch 9/20
14s - loss: 0.6704 - val_loss: 0.8834
Epoch 00008: early stopping
Theta 539 [ 0.02611736  0.48536552]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6773 - val_loss: 0.8538
Epoch 2/20
14s - loss: 0.6732 - val_loss: 0.9272
Epoch 3/20
14s - loss: 0.6723 - val_loss: 0.8522
Epoch 4/20
14s - loss: 0.6716 - val_loss: 0.8891
Epoch 5/20
14s - loss: 0.6707 - val_loss: 0.8729
Epoch 6/20
14s - loss: 0.6702 - val_loss: 0.9012
Epoch 7/20
14s - loss: 0.6694 - val_loss: 0.8791
Epoch 00006: early stopping
Theta 1000 [ 0.97310957 -0.81263698]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6199 - val_loss: 0.7467
Epoch 2/20
14s - loss: 0.6091 - val_loss: 0.8111
Epoch 3/20
14s - loss: 0.6065 - val_loss: 0.7518
Epoch 4/20
14s - loss: 0.6053 - val_loss: 0.7755
Epoch 5/20
14s - loss: 0.6039 - val_loss: 0.7655
Epoch 00004: early stopping
Theta 291 [-0.44794652 -0.29910012]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6586 - val_loss: 0.8806
Epoch 2/20
14s - loss: 0.6507 - val_loss: 0.8157
Epoch 3/20
14s - loss: 0.6489 - val_loss: 0.9083
Epoch 4/20
14s - loss: 0.6471 - val_loss: 0.8981
Epoch 5/20
14s - loss: 0.6463 - val_loss: 0.7895
Epoch 6/20
14s - loss: 0.6447 - val_loss: 0.8213
Epoch 7/20
14s - loss: 0.6437 - val_loss: 0.9092
Epoch 8/20
14s - loss: 0.6430 - val_loss: 0.8374
Epoch 9/20
14s - loss: 0.6417 - val_loss: 0.7922
Epoch 00008: early stopping
Theta 740 [ 0.45098284 -0.09648431]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
15s - loss: 0.6743 - val_loss: 0.8041
Epoch 2/20
14s - loss: 0.6684 - val_loss: 0.8000
Epoch 3/20
14s - loss: 0.6671 - val_loss: 0.8386
Epoch 4/20
14s - loss: 0.6665 - val_loss: 0.8616
Epoch 5/20
14s - loss: 0.6658 - val_loss: 0.8449
Epoch 6/20
14s - loss: 0.6651 - val_loss: 0.8504
Epoch 00005: early stopping
Theta 276 [-0.4640355  -0.39998652]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6558 - val_loss: 0.8653
Epoch 2/20
14s - loss: 0.6482 - val_loss: 0.8558
Epoch 3/20
14s - loss: 0.6459 - val_loss: 0.8191
Epoch 4/20
14s - loss: 0.6449 - val_loss: 0.8607
Epoch 5/20
14s - loss: 0.6435 - val_loss: 0.7858
Epoch 6/20
14s - loss: 0.6422 - val_loss: 0.9018
Epoch 7/20
14s - loss: 0.6412 - val_loss: 0.8634
Epoch 8/20
14s - loss: 0.6401 - val_loss: 0.8611
Epoch 9/20
14s - loss: 0.6389 - val_loss: 0.8493
Epoch 00008: early stopping
Theta 679 [ 0.33068993 -0.75125927]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6542 - val_loss: 0.9182
Epoch 2/20
14s - loss: 0.6437 - val_loss: 0.8210
Epoch 3/20
14s - loss: 0.6413 - val_loss: 0.7822
Epoch 4/20
14s - loss: 0.6399 - val_loss: 0.7863
Epoch 5/20
14s - loss: 0.6379 - val_loss: 0.8645
Epoch 6/20
14s - loss: 0.6364 - val_loss: 0.8248
Epoch 7/20
14s - loss: 0.6348 - val_loss: 0.8327
Epoch 00006: early stopping
Theta 167 [-0.70631846 -0.18913046]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6558 - val_loss: 0.7927
Epoch 2/20
14s - loss: 0.6474 - val_loss: 0.8530
Epoch 3/20
14s - loss: 0.6454 - val_loss: 0.9276
Epoch 4/20
14s - loss: 0.6438 - val_loss: 0.8566
Epoch 5/20
14s - loss: 0.6421 - val_loss: 0.8813
Epoch 00004: early stopping
Theta 125 [-0.7910712  -0.98769884]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6496 - val_loss: 0.8756
Epoch 2/20
14s - loss: 0.6378 - val_loss: 0.7275
Epoch 3/20
14s - loss: 0.6339 - val_loss: 0.8082
Epoch 4/20
14s - loss: 0.6310 - val_loss: 0.7762
Epoch 5/20
14s - loss: 0.6288 - val_loss: 0.7856
Epoch 6/20
14s - loss: 0.6273 - val_loss: 0.8252
Epoch 00005: early stopping
Theta 429 [-0.17418656 -0.37102219]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6600 - val_loss: 0.8267
Epoch 2/20
14s - loss: 0.6533 - val_loss: 0.8554
Epoch 3/20
14s - loss: 0.6514 - val_loss: 0.9180
Epoch 4/20
14s - loss: 0.6501 - val_loss: 0.8879
Epoch 5/20
14s - loss: 0.6491 - val_loss: 0.8818
Epoch 00004: early stopping
Theta 149 [-0.73726809 -0.38348788]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6517 - val_loss: 0.8060
Epoch 2/20
14s - loss: 0.6435 - val_loss: 0.8561
Epoch 3/20
14s - loss: 0.6400 - val_loss: 0.8843
Epoch 4/20
14s - loss: 0.6384 - val_loss: 0.7863
Epoch 5/20
14s - loss: 0.6366 - val_loss: 0.8025
Epoch 6/20
14s - loss: 0.6354 - val_loss: 0.8632
Epoch 7/20
14s - loss: 0.6340 - val_loss: 0.7889
Epoch 8/20
14s - loss: 0.6326 - val_loss: 0.9099
Epoch 00007: early stopping
Theta 430 [-0.16930044  0.22814164]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6708 - val_loss: 0.8277
Epoch 2/20
14s - loss: 0.6658 - val_loss: 0.8441
Epoch 3/20
14s - loss: 0.6650 - val_loss: 0.8783
Epoch 4/20
14s - loss: 0.6642 - val_loss: 0.8613
Epoch 5/20
14s - loss: 0.6637 - val_loss: 0.8543
Epoch 00004: early stopping
Theta 720 [ 0.41602256 -0.1168588 ]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6749 - val_loss: 0.8948
Epoch 2/20
14s - loss: 0.6689 - val_loss: 0.8854
Epoch 3/20
14s - loss: 0.6680 - val_loss: 0.8152
Epoch 4/20
14s - loss: 0.6673 - val_loss: 0.8464
Epoch 5/20
14s - loss: 0.6665 - val_loss: 0.8870
Epoch 6/20
14s - loss: 0.6655 - val_loss: 0.8553
Epoch 7/20
14s - loss: 0.6644 - val_loss: 0.8200
Epoch 00006: early stopping
Theta 123 [-0.79179407  0.72243203]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6546 - val_loss: 0.8413
Epoch 2/20
14s - loss: 0.6398 - val_loss: 0.8529
Epoch 3/20
14s - loss: 0.6360 - val_loss: 0.7947
Epoch 4/20
14s - loss: 0.6337 - val_loss: 0.8039
Epoch 5/20
14s - loss: 0.6319 - val_loss: 0.8117
Epoch 6/20
14s - loss: 0.6301 - val_loss: 0.8425
Epoch 7/20
14s - loss: 0.6270 - val_loss: 0.8449
Epoch 00006: early stopping
Theta 908 [ 0.77844761  0.32603028]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6751 - val_loss: 0.8843
Epoch 2/20
14s - loss: 0.6714 - val_loss: 0.9371
Epoch 3/20
14s - loss: 0.6707 - val_loss: 0.8826
Epoch 4/20
14s - loss: 0.6704 - val_loss: 0.8514
Epoch 5/20
14s - loss: 0.6698 - val_loss: 0.8471
Epoch 6/20
14s - loss: 0.6693 - val_loss: 0.8346
Epoch 7/20
14s - loss: 0.6686 - val_loss: 0.8543
Epoch 8/20
14s - loss: 0.6679 - val_loss: 0.8536
Epoch 9/20
14s - loss: 0.6668 - val_loss: 0.8611
Epoch 10/20
14s - loss: 0.6657 - val_loss: 0.8601
Epoch 00009: early stopping
Theta 256 [-0.50703066 -0.72121867]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6585 - val_loss: 0.9262
Epoch 2/20
14s - loss: 0.6484 - val_loss: 0.8100
Epoch 3/20
14s - loss: 0.6452 - val_loss: 0.8948
Epoch 4/20
14s - loss: 0.6438 - val_loss: 0.8509
Epoch 5/20
14s - loss: 0.6424 - val_loss: 0.8851
Epoch 6/20
14s - loss: 0.6412 - val_loss: 0.7943
Epoch 7/20
14s - loss: 0.6404 - val_loss: 0.8659
Epoch 8/20
14s - loss: 0.6385 - val_loss: 0.8853
Epoch 9/20
14s - loss: 0.6372 - val_loss: 0.8578
Epoch 10/20
14s - loss: 0.6358 - val_loss: 0.8040
Epoch 00009: early stopping
Theta 777 [ 0.52377237  0.01987936]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6776 - val_loss: 0.8284
Epoch 2/20
14s - loss: 0.6718 - val_loss: 0.8922
Epoch 3/20
14s - loss: 0.6708 - val_loss: 0.8707
Epoch 4/20
14s - loss: 0.6702 - val_loss: 0.9215
Epoch 5/20
14s - loss: 0.6694 - val_loss: 0.8635
Epoch 00004: early stopping
Theta 809 [ 0.58338739 -0.68531326]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6478 - val_loss: 0.8307
Epoch 2/20
14s - loss: 0.6370 - val_loss: 0.8105
Epoch 3/20
14s - loss: 0.6345 - val_loss: 0.7960
Epoch 4/20
14s - loss: 0.6333 - val_loss: 0.8089
Epoch 5/20
14s - loss: 0.6319 - val_loss: 0.8403
Epoch 6/20
14s - loss: 0.6308 - val_loss: 0.9020
Epoch 7/20
14s - loss: 0.6291 - val_loss: 0.8287
Epoch 00006: early stopping
Theta 269 [-0.48969042 -0.23040933]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6569 - val_loss: 0.7466
Epoch 2/20
14s - loss: 0.6499 - val_loss: 0.8466
Epoch 3/20
14s - loss: 0.6478 - val_loss: 0.8477
Epoch 4/20
14s - loss: 0.6464 - val_loss: 0.8287
Epoch 5/20
14s - loss: 0.6451 - val_loss: 0.8251
Epoch 00004: early stopping
Theta 851 [ 0.66684741 -0.33464755]
Train on 85714 samples, validate on 14286 samples
Epoch 1/20
16s - loss: 0.6600 - val_loss: 0.8168
Epoch 2/20
14s - loss: 0.6521 - val_loss: 0.8002
Epoch 3/20
14s - loss: 0.6496 - val_loss: 0.8977
Epoch 4/20
14s - loss: 0.6490 - val_loss: 0.8722
Epoch 5/20
15s - loss: 0.6477 - val_loss: 0.8446
Epoch 6/20
15s - loss: 0.6467 - val_loss: 0.9050
Epoch 00005: early stopping

Interpolation
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.49972730e+08,  -5.74038603e+03]), 'nit': 3, 'funcalls': 87}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  4.29496730e+09,  -0.00000000e+00]), 'nit': 2, 'funcalls': 47}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 315.24881184,   64.3671779 ]), 'nit': 1, 'funcalls': 45}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ 634.74510747,  324.48579027]), 'nit': 17, 'funcalls': 110}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -3.35544260e+007,  -3.21855467e-159]), 'nit': 1, 'funcalls': 26}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([  5.99979783e+00,  -1.08149167e-17]), 'nit': 3, 'funcalls': 35}
  " state: %s" % convergence_dict)
/share/apps/scikit-learn/0.18.1/intel/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.py:427: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([ -1.67772100e+07,  -1.52026749e-24]), 'nit': 3, 'funcalls': 57}
  " state: %s" % convergence_dict)
